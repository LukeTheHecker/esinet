{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet import forward\n",
    "\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    1.2s remaining:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    1.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "info = forward.get_info()\n",
    "info['sfreq'] = 100\n",
    "fwd = forward.create_forward_model(info=info)\n",
    "fwd_free = forward.create_forward_model(info=info, fixed_ori=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_standard = util.load_net('models/LSTM Medium_1-1000points_standard-cosine_0')\n",
    "dense_standard = util.load_net('models/Dense Medium_1-1000points_standard-cosine_0')\n",
    "convdip_standard = util.load_net('models/ConvDip Medium_1-1000points_standard-cosine_0')\n",
    "\n",
    "models = [lstm_standard, dense_standard, convdip_standard]\n",
    "model_names = ['LSTM', 'Fully-Connected', 'ConvDip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Evaluation Set and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'simulations\\\\sim_test_1000_1-200points_standard.pkl', 'rb') as f:\n",
    "    sim_test = pkl.load(f)\n",
    "\n",
    "with open(f'results\\\\metrics_101947_1-200points_standard.pkl', 'rb') as f:\n",
    "    [metrics, simulation_info] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\pandas\\core\\apply.py:821: RuntimeWarning: Mean of empty slice\n",
      "  results[i] = self.f(v)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_localization_errors</th>\n",
       "      <th>aucs_combined</th>\n",
       "      <th>aucs_far</th>\n",
       "      <th>aucs_close</th>\n",
       "      <th>nmses</th>\n",
       "      <th>mses</th>\n",
       "      <th>method</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.219618</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.942479</td>\n",
       "      <td>0.794107</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>4.666444e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.719351</td>\n",
       "      <td>0.822743</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.769886</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>1.222845e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.562478</td>\n",
       "      <td>0.843674</td>\n",
       "      <td>0.921228</td>\n",
       "      <td>0.766119</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>2.504530e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.684041</td>\n",
       "      <td>0.887201</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>0.808311</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>1.005835e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.647893</td>\n",
       "      <td>0.828699</td>\n",
       "      <td>0.875775</td>\n",
       "      <td>0.781622</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>2.464672e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_localization_errors  aucs_combined  aucs_far  aucs_close     nmses  \\\n",
       "0                 23.219618       0.868293  0.942479    0.794107  0.012646   \n",
       "1                 11.719351       0.822743  0.875600    0.769886  0.008011   \n",
       "2                 14.562478       0.843674  0.921228    0.766119  0.013500   \n",
       "3                 19.684041       0.887201  0.966092    0.808311  0.012914   \n",
       "4                 19.647893       0.828699  0.875775    0.781622  0.010828   \n",
       "\n",
       "           mses method  sample_id  \n",
       "0  4.666444e-19   LSTM          0  \n",
       "1  1.222845e-19   LSTM          1  \n",
       "2  2.504530e-19   LSTM          2  \n",
       "3  1.005835e-19   LSTM          3  \n",
       "4  2.464672e-19   LSTM          4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durs_in_samples = [round(dur*100) for dur in sim_test.simulation_info.duration_of_trials.values]\n",
    "\n",
    "idx = 0\n",
    "indices = []\n",
    "for dur in durs_in_samples:\n",
    "    idc = [idx, dur+idx]\n",
    "    indices.append(idc)\n",
    "    idx += dur\n",
    "metrics_short = dict()\n",
    "\n",
    "\n",
    "for method in metrics.keys():\n",
    "    metrics_short[method] = pd.DataFrame(columns=metrics[method].columns)\n",
    "    for id, idc in enumerate(indices):\n",
    "        sample_summary = metrics[method].iloc[idc[0]:idc[1]].apply(np.nanmean, axis=0)\n",
    "        sample_summary.sample_id = id\n",
    "        metrics_short[method] = metrics_short[method].append(sample_summary, ignore_index=True)\n",
    "    metrics_short[method].method = method\n",
    "    # metrics_short[method].iloc[:, 0:6].values = np.real(metrics_short[method].iloc[:, 0:6])\n",
    "\n",
    "dfs = [df[1] for df in list(metrics_short.items())]\n",
    "\n",
    "for i, (key, df) in enumerate(metrics_short.items()):\n",
    "    dfs[i]['method'] = [key]*df.shape[0]\n",
    "    dfs[i]['sample_id'] = np.arange(df.shape[0])\n",
    "df_aio = pd.concat(dfs)\n",
    "df_aio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot single ground truth and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 1284 vertices, subject : fsaverage, tmin : 0.0 (ms), tmax : 850.0 (ms), tstep : 10.0 (ms), data shape : (1284, 86), ~873 kB>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_test.source_data[best_idx]#.data.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x169fcf95e50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_params = dict(surface='white', hemi='split', size=(800*2,400*2), verbose=0, time_viewer=False,\n",
    "    background='w', colorbar=False,\n",
    "    views=['lat', 'med'], colormap=colormap, initial_time=0.0)\n",
    "\n",
    "sim.source_data[0].plot(**plot_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48953488372093024"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(df_aio[df_aio.method=='LSTM'].aucs_combined.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3       True\n",
       "4      False\n",
       "       ...  \n",
       "995    False\n",
       "996    False\n",
       "997    False\n",
       "998    False\n",
       "999    False\n",
       "Name: number_of_sources, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_localization_errors</th>\n",
       "      <th>aucs_combined</th>\n",
       "      <th>aucs_far</th>\n",
       "      <th>aucs_close</th>\n",
       "      <th>nmses</th>\n",
       "      <th>mses</th>\n",
       "      <th>method</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.219618</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.942479</td>\n",
       "      <td>0.794107</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>4.666444e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.719351</td>\n",
       "      <td>0.822743</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.769886</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>1.222845e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.562478</td>\n",
       "      <td>0.843674</td>\n",
       "      <td>0.921228</td>\n",
       "      <td>0.766119</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>2.504530e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.684041</td>\n",
       "      <td>0.887201</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>0.808311</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>1.005835e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.647893</td>\n",
       "      <td>0.828699</td>\n",
       "      <td>0.875775</td>\n",
       "      <td>0.781622</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>2.464672e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>25.356679</td>\n",
       "      <td>0.464930</td>\n",
       "      <td>0.477803</td>\n",
       "      <td>0.452057</td>\n",
       "      <td>0.026314</td>\n",
       "      <td>4.479224e-19</td>\n",
       "      <td>LCMV</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24.598093</td>\n",
       "      <td>0.557767</td>\n",
       "      <td>0.531220</td>\n",
       "      <td>0.584315</td>\n",
       "      <td>0.050748</td>\n",
       "      <td>7.401235e-21</td>\n",
       "      <td>LCMV</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>24.471249</td>\n",
       "      <td>0.602101</td>\n",
       "      <td>0.681807</td>\n",
       "      <td>0.522396</td>\n",
       "      <td>0.041049</td>\n",
       "      <td>1.591045e-18</td>\n",
       "      <td>LCMV</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>18.847806</td>\n",
       "      <td>0.617973</td>\n",
       "      <td>0.662383</td>\n",
       "      <td>0.573563</td>\n",
       "      <td>0.038285</td>\n",
       "      <td>2.770887e-18</td>\n",
       "      <td>LCMV</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>28.258426</td>\n",
       "      <td>0.631339</td>\n",
       "      <td>0.704844</td>\n",
       "      <td>0.557834</td>\n",
       "      <td>0.057237</td>\n",
       "      <td>4.532308e-19</td>\n",
       "      <td>LCMV</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_localization_errors  aucs_combined  aucs_far  aucs_close     nmses  \\\n",
       "0                   23.219618       0.868293  0.942479    0.794107  0.012646   \n",
       "1                   11.719351       0.822743  0.875600    0.769886  0.008011   \n",
       "2                   14.562478       0.843674  0.921228    0.766119  0.013500   \n",
       "3                   19.684041       0.887201  0.966092    0.808311  0.012914   \n",
       "4                   19.647893       0.828699  0.875775    0.781622  0.010828   \n",
       "..                        ...            ...       ...         ...       ...   \n",
       "995                 25.356679       0.464930  0.477803    0.452057  0.026314   \n",
       "996                 24.598093       0.557767  0.531220    0.584315  0.050748   \n",
       "997                 24.471249       0.602101  0.681807    0.522396  0.041049   \n",
       "998                 18.847806       0.617973  0.662383    0.573563  0.038285   \n",
       "999                 28.258426       0.631339  0.704844    0.557834  0.057237   \n",
       "\n",
       "             mses method  sample_id  \n",
       "0    4.666444e-19   LSTM          0  \n",
       "1    1.222845e-19   LSTM          1  \n",
       "2    2.504530e-19   LSTM          2  \n",
       "3    1.005835e-19   LSTM          3  \n",
       "4    2.464672e-19   LSTM          4  \n",
       "..            ...    ...        ...  \n",
       "995  4.479224e-19   LCMV        995  \n",
       "996  7.401235e-21   LCMV        996  \n",
       "997  1.591045e-18   LCMV        997  \n",
       "998  2.770887e-18   LCMV        998  \n",
       "999  4.532308e-19   LCMV        999  \n",
       "\n",
       "[6000 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 190.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 114.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 200) (1284, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 43.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.62it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538f0cb6a9a54e5f880d92e3c5bc1ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:390: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:390: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a65636a89af413eb76727d54381950a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:390: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:390: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e19cfc651141d9953c9257310d31aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:390: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:422: RuntimeWarning: Too few samples (required : 310 got : 200), covariance estimate may be unreliable\n",
      "  data_cov = mne.compute_raw_covariance(raw, tmin=tmin,\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:390: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:422: RuntimeWarning: Too few samples (required : 310 got : 200), covariance estimate may be unreliable\n",
      "  data_cov = mne.compute_raw_covariance(raw, tmin=tmin,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "Fully-Connected\n",
      "ConvDip\n",
      "eLORETA\n",
      "MNE\n",
      "LCMV\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib qt\n",
    "sns.reset_orig()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "model_names_tmp = deepcopy(model_names)\n",
    "colormap = 'RdBu_r'\n",
    "plot_params = dict(surface='white', hemi='split', size=(800*2,400*2), verbose=0, time_viewer=False, \n",
    "    background='w', colorbar=False, views=['lat', 'med'], \n",
    "    colormap=colormap, initial_time=0.0, transparent=True\n",
    ")\n",
    "fractions = [0., 0.2, 0.99]\n",
    "\n",
    "settings_eval = dict(\n",
    "    method='standard', \n",
    "    number_of_sources=3,\n",
    "    duration_of_trial=2.0)\n",
    "\n",
    "# Simulate new data\n",
    "sim = Simulation(fwd, info, settings=settings_eval).simulate(2)\n",
    "# best_idx = np.argmin(df_aio[df_aio.method=='LSTM'].nmses.values)\n",
    "best_idx = np.argsort(df_aio[df_aio.method=='LSTM'].nmses.values)[500]\n",
    "# best_idx = df_aio[(df_aio.method=='LSTM')][simulation_info.number_of_sources==2].sort_values('nmses', ascending=True).sample_id.values[0]\n",
    "\n",
    "# sim.source_data[0] = sim_test.source_data[best_idx]\n",
    "# sim.eeg_data[0] = sim_test.eeg_data[best_idx]\n",
    "\n",
    "idx = 0\n",
    "# snr = sim.simulation_info['target_snr'].values[0]\n",
    "snr = None\n",
    "# print(sim.simulation_info)\n",
    "# Predict sources using the esinet models\n",
    "predictions = [model.predict(sim) for model in models]\n",
    "\n",
    "# Predict sources with classical methods\n",
    "# eLORETA\n",
    "prediction_elor_data = util.wrap_mne_inverse(fwd, sim, method='eLORETA', \n",
    "    add_baseline=True, n_baseline=400)[idx].data.astype(np.float32)\n",
    "prediction_elor = deepcopy(predictions[0][0])\n",
    "prediction_elor.data = prediction_elor_data / np.abs(np.max(prediction_elor_data))\n",
    "# MNE\n",
    "prediction_mne_data = util.wrap_mne_inverse(fwd, sim, method='MNE', \n",
    "    add_baseline=True, n_baseline=400)[idx].data.astype(np.float32)\n",
    "prediction_mne = deepcopy(predictions[0][0])\n",
    "prediction_mne.data = prediction_mne_data / np.abs(np.max(prediction_mne_data))\n",
    "# Beamformer\n",
    "prediction_lcmv_data = util.wrap_mne_inverse(fwd, sim, method='lcmv', \n",
    "    add_baseline=True, n_baseline=400, parallel=False)[idx].data.astype(np.float32)\n",
    "prediction_lcmv = deepcopy(predictions[0][0])\n",
    "prediction_lcmv.data = prediction_lcmv_data / np.max(np.abs(prediction_lcmv_data))\n",
    "\n",
    "# Get predictions and names in order\n",
    "predictions.append([prediction_elor])\n",
    "predictions.append([prediction_mne])\n",
    "predictions.append([prediction_lcmv])\n",
    "\n",
    "model_names_tmp.append('eLORETA')\n",
    "model_names_tmp.append('MNE')\n",
    "model_names_tmp.append('LCMV')\n",
    "\n",
    "# Plot True Source\n",
    "pos_lims = [np.max(np.abs(sim.source_data[idx].data[:, 0]))*frac for frac in fractions]\n",
    "brain = sim.source_data[idx].plot(**plot_params, clim=dict(kind='value', pos_lims=pos_lims))\n",
    "brain.add_text(0.1, 0.9, f'Ground Truth', 'title')\n",
    "# brain = sim.source_data[idx].plot()\n",
    "\n",
    "model_selection = model_names_tmp\n",
    "# Plot predicted sources\n",
    "for model_name, prediction in zip(model_names_tmp, predictions):\n",
    "    \n",
    "    # if not any([model_name.lower() in model_select.lower() for model_select in model_selection]):\n",
    "    #     continue\n",
    "    # error = util.batch_nmse(sim.source_data[idx].data, prediction[idx].data)\n",
    "    # r = util.batch_corr(sim.source_data[idx].data, prediction[idx].data)\n",
    "    pos_lims = [np.max(np.abs(prediction[idx].data[:, 0]))*frac for frac in fractions]\n",
    "    brain = prediction[idx].plot(**plot_params, clim=dict(kind='value', pos_lims=pos_lims))\n",
    "    title = f'{model_name}'\n",
    "    print(title)\n",
    "    brain.add_text(0.1, 0.9, title, 'title')\n",
    "    # brain = prediction[idx].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot Overview \n",
    "### All Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid', font_scale=1.6, font='helvetica')\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "df_aio[\"aucs_combined\"] *= 100\n",
    "cols = ['mean_localization_errors', 'aucs_combined', 'nmses']\n",
    "metric_names = [\"Mean Localization Error [mm]\", \"Area Under the Curve [%]\", \"Normalized Mean Squared Error\"]\n",
    "ylims = [[0, None], [0, None], [0, 0.15]]\n",
    "for y, metric_name, ylim in zip(cols, metric_names, ylims):\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    sns.boxplot(data=df_aio, x='method', y=y)\n",
    "    plt.title(metric_name)\n",
    "    plt.xlabel(\"Inverse Solution\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.ylim(ylim)\n",
    "util.multipage(r'C:\\Users\\lukas\\Sync\\lstm_inverse_problem\\figures\\results\\boxplot_overview_allsources.pdf', png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid', font_scale=1.6, font='helvetica')\n",
    "%matplotlib qt\n",
    "\n",
    "idc_single_source = np.argwhere(simulation_info.number_of_sources.values==1)[:, 0]\n",
    "df_single = df_aio[df_aio.sample_id.isin(idc_single_source)]\n",
    "# df_single[\"aucs_combined\"] *= 100\n",
    "cols = ['mean_localization_errors', 'aucs_combined', 'nmses']  # df_single.iloc[:, 0:6].columns\n",
    "metric_names = [\"Mean Localization Error [mm]\", \"Area Under the Curve [%]\", \"Normalized Mean Squared Error\"]\n",
    "ylims = [[0, None], [0, None], [0, 0.15]]\n",
    "for y, metric_name, ylim in zip(cols, metric_names, ylims):\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    sns.boxplot(data=df_single, x='method', y=y)\n",
    "    # sns.swarmplot(data=df_single, x='method', y=y)\n",
    "    plt.title(metric_name)\n",
    "    plt.xlabel(\"Inverse Solution\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.ylim(ylim)\n",
    "util.multipage(r'C:\\Users\\lukas\\Sync\\lstm_inverse_problem\\figures\\results\\boxplot_overview_singlesource.pdf', png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_of_interest = df_aio\n",
    "\n",
    "methods = set(df_of_interest.method.values)\n",
    "columns = ['method', 'mean_localization_errors', 'aucs_combined', 'nmses']  # df_aio.iloc[:, 0:6].columns\n",
    "column_names = [\"Inverse Solution\", \"MLE [mm] (SD)\", \"AUC [%] (SD)\", \"nMSE (SD)\"]\n",
    "decimals = [None, 2, 2, 4]\n",
    "scalers = [None, 1, 100, 1]\n",
    "table = pd.DataFrame(columns=column_names)\n",
    "for i, method in enumerate(methods):\n",
    "    row_dict = {column_names[0]:method}\n",
    "    for j, (column, column_name, decimal, scaler) in enumerate(zip(columns[1:], column_names[1:], decimals[1:], scalers[1:])):\n",
    "        values = df_of_interest[df_of_interest.method==method][column].values\n",
    "        row_dict[column_name] = str(round(np.nanmedian(values)*scaler, decimal)) + ' (' + str(round(np.nanstd(values)*scaler, decimal)) + ')'\n",
    "    table = table.append(row_dict, ignore_index=True)\n",
    "table = table.sort_values(\"AUC [%] (SD)\", ascending=False)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single = df_aio[df_aio.sample_id.isin(idc_single_source)]\n",
    "\n",
    "df_of_interest = df_single\n",
    "\n",
    "methods = set(df_of_interest.method.values)\n",
    "columns = ['method', 'mean_localization_errors', 'aucs_combined', 'nmses']  # df_aio.iloc[:, 0:6].columns\n",
    "column_names = [\"Inverse Solution\", \"MLE [mm] (SD)\", \"AUC [%] (SD)\", \"nMSE (SD)\"]\n",
    "decimals = [None, 2, 2, 4]\n",
    "scalers = [None, 1, 100, 1]\n",
    "\n",
    "table = pd.DataFrame(columns=column_names)\n",
    "for i, method in enumerate(methods):\n",
    "    row_dict = {column_names[0]:method}\n",
    "    for j, (column, column_name, decimal, scaler) in enumerate(zip(columns[1:], column_names[1:], decimals[1:], scalers[1:])):\n",
    "        values = df_of_interest[df_of_interest.method==method][column].values\n",
    "        row_dict[column_name] = str(round(np.nanmedian(values)*scaler, decimal)) + ' (' + str(round(np.nanstd(values)*scaler, decimal)) + ')'\n",
    "    table = table.append(row_dict, ignore_index=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid', font_scale=1.2, font='helvetica')\n",
    "%matplotlib qt\n",
    "methods_of_interest = ['LSTM Standard', 'Dense Standard']\n",
    "# df_select = df_aio[df_aio['method'].str.contains('|'.join(methods_of_interest))]\n",
    "\n",
    "cols = df_aio.iloc[:, 0:6].columns\n",
    "for method_name in cols:\n",
    "\n",
    "    vals_A = df_aio[df_aio['method'].str.contains(methods_of_interest[0])][method_name].values\n",
    "    vals_B = df_aio[df_aio['method'].str.contains(methods_of_interest[1])][method_name].values\n",
    "    d = {methods_of_interest[0]: vals_A, methods_of_interest[1]: vals_B,} \n",
    "    df_tmp = pd.DataFrame(d)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = sns.scatterplot(data=df_tmp, x=methods_of_interest[0], y=methods_of_interest[1])\n",
    "\n",
    "\n",
    "    xlim, ylim = (plt.xlim(), plt.ylim())\n",
    "    plt.plot(xlim, ylim, '--k')\n",
    "    xlim = (xlim[0]*0.95, xlim[1]*1.05)\n",
    "    ylim = (ylim[0]*0.95, ylim[1]*1.05)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    # Title\n",
    "    prop_higher = np.sum(vals_B > vals_A) / len(vals_A)\n",
    "    cohens_d = (np.nanmean(vals_A) - np.nanmean(vals_B)) / np.mean([np.nanstd(vals_A), np.nanstd(vals_B)])\n",
    "    median_diff = np.abs(np.nanmedian(vals_A-vals_B))\n",
    "    method_name_title = method_name.replace('_', ' ').title()\n",
    "    title = f'{method_name_title} ({methods_of_interest[1]} higher in {100*prop_higher:.1f} %)\\nmedian_difference: {median_diff}\\ncohens d: {abs(cohens_d):.2f}'\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    del d, df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependence on Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "sns.set(font_scale=1.4, font='helvetica', style='whitegrid')\n",
    "# pd.DataFrame( metrics , index=model_names)\n",
    "target_column = 'target_snr'\n",
    "binning = True\n",
    "n_bins = 6\n",
    "\n",
    "\n",
    "df = sim_test.simulation_info\n",
    "if binning:\n",
    "    minimum = np.min([np.min(arr) for arr in df[target_column].values])\n",
    "    maximum = np.max([np.max(arr) for arr in df[target_column].values])\n",
    "    \n",
    "    bins = np.linspace(minimum, maximum*1.01, num=n_bins)\n",
    "    bin_labels = [str(int(round(bins[i], 0))) + ' - ' + str(int(round(bins[i+1], 0))) for i in range(len(bins)-1)]\n",
    "    new_target_column = 'bins ' + target_column\n",
    "    df[new_target_column] = np.digitize(df[target_column].values, bins=bins)\n",
    "    target_column = new_target_column\n",
    "    \n",
    "else:\n",
    "    bins = list(set(df[target_column].values))\n",
    "    bins[-1] *= 1.01\n",
    "    bin_labels = [str(bins[i]) for i in range(len(bins))]\n",
    "\n",
    "\n",
    "for i, model_name in enumerate(list(set(df_aio.method.values))):\n",
    "    cols = df_aio[df_aio.method==model_name].iloc[:, 0:6].columns\n",
    "    values = df_aio[df_aio.method==model_name].iloc[:, 0:6].values\n",
    "\n",
    "    for metric_name, metric in zip(cols, values.T):\n",
    "        col_name = model_name.replace(' ', '_') + '_' + metric_name.replace(' ', '_')\n",
    "        df[col_name] = metric\n",
    "dep_var_regex = target_column\n",
    "dep_var_label = target_column.replace('_', ' ').title()\n",
    "metric_names_nice = [\"Mean Localization Error [mm]\", \"Area Under the Curve [%]\", \"Normalized Mean Squared Error\"]\n",
    "metric_names = ['mean_localization_errors', 'aucs_combined', 'nmses']\n",
    "scalers = [1, 100, 1]\n",
    "for metric_name, metric_name_nice, scaler in zip(metric_names,  metric_names_nice, scalers):\n",
    "    df_temp = pd.concat((df.filter(regex=dep_var_regex), df.filter(regex='_'+metric_name)), axis=1).melt(dep_var_regex, var_name='cols', value_name='vals')\n",
    "    df_temp.cols = [val.split('_')[0] for val in df_temp.cols.values]\n",
    "    # df_temp.vals*=scaler\n",
    "    g = sns.catplot(x=dep_var_regex, y='vals', hue='cols', capsize=.2, kind='point', data=df_temp, height=6, aspect=1.5)\n",
    "    g.set(xticklabels=bin_labels, ylabel=metric_name_nice, xlabel=dep_var_label)\n",
    "    g._legend.remove()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.tight_layout()\n",
    "    plt.title(metric_name_nice)\n",
    "\n",
    "    # break\n",
    "g = sns.catplot(x=dep_var_regex, y='vals', hue='cols', capsize=.2, kind='point', data=df_temp, height=6, aspect=1.5)\n",
    "g.set(xticklabels=bin_labels, ylabel=metric_name_nice, xlabel=dep_var_label)\n",
    "g._legend.remove()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylim(plt.ylim()[0], plt.ylim()[1]/8)\n",
    "plt.tight_layout()\n",
    "plt.title(metric_name_nice)\n",
    "util.multipage(f'C:/Users/lukas/Sync/lstm_inverse_problem/figures/results/dependence_{target_column}.pdf', png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependence on Eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "sns.set(font_scale=1.4, font='helvetica', style='whitegrid')\n",
    "# pd.DataFrame( metrics , index=model_names)\n",
    "target_column = 'eccentricity'\n",
    "binning = True\n",
    "n_bins = 4\n",
    "\n",
    "eccentricity = np.zeros(df.shape[0])\n",
    "for i, positions in enumerate(df.positions.values):\n",
    "    eccentricity[i] = np.mean(np.sqrt((positions**2).sum(axis=1)))\n",
    "df[\"eccentricity\"] = eccentricity\n",
    "\n",
    "\n",
    "df = sim_test.simulation_info\n",
    "if binning:\n",
    "    minimum = np.min([np.min(arr) for arr in df[target_column].values])\n",
    "    maximum = np.max([np.max(arr) for arr in df[target_column].values])\n",
    "    \n",
    "    bins = np.linspace(minimum, maximum*1.01, num=n_bins)\n",
    "    bin_labels = [str(int(round(bins[i], 0))) + ' - ' + str(int(round(bins[i+1], 0))) for i in range(len(bins)-1)]\n",
    "    new_target_column = 'bins ' + target_column\n",
    "    df[new_target_column] = np.digitize(df[target_column].values, bins=bins)\n",
    "    target_column = new_target_column\n",
    "    \n",
    "else:\n",
    "    bins = list(set(df[target_column].values))\n",
    "    bins[-1] *= 1.01\n",
    "    bin_labels = [str(bins[i]) for i in range(len(bins))]\n",
    "\n",
    "\n",
    "for i, model_name in enumerate(list(set(df_aio.method.values))):\n",
    "    cols = df_aio[df_aio.method==model_name].iloc[:, 0:6].columns\n",
    "    values = df_aio[df_aio.method==model_name].iloc[:, 0:6].values\n",
    "\n",
    "    for metric_name, metric in zip(cols, values.T):\n",
    "        col_name = model_name.replace(' ', '_') + '_' + metric_name.replace(' ', '_')\n",
    "        df[col_name] = metric\n",
    "dep_var_regex = target_column\n",
    "dep_var_label = target_column.replace('_', ' ').title()\n",
    "metric_names_nice = [\"Mean Localization Error [mm]\", \"Area Under the Curve [%]\", \"Normalized Mean Squared Error\"]\n",
    "metric_names = ['mean_localization_errors', 'aucs_combined', 'nmses']\n",
    "scalers = [1, 100, 1]\n",
    "for metric_name, metric_name_nice, scaler in zip(metric_names,  metric_names_nice, scalers):\n",
    "    df_temp = pd.concat((df.filter(regex=dep_var_regex), df.filter(regex='_'+metric_name)), axis=1).melt(dep_var_regex, var_name='cols', value_name='vals')\n",
    "    df_temp.cols = [val.split('_')[0] for val in df_temp.cols.values]\n",
    "    # df_temp.vals*=scaler\n",
    "    g = sns.catplot(x=dep_var_regex, y='vals', hue='cols', capsize=.2, kind='point', data=df_temp, height=6, aspect=1.5)\n",
    "    g.set(xticklabels=bin_labels, ylabel=metric_name_nice, xlabel=dep_var_label)\n",
    "    g._legend.remove()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.tight_layout()\n",
    "    plt.title(metric_name_nice)\n",
    "\n",
    "    # break\n",
    "g = sns.catplot(x=dep_var_regex, y='vals', hue='cols', capsize=.2, kind='point', data=df_temp, height=6, aspect=1.5)\n",
    "g.set(xticklabels=bin_labels, ylabel=metric_name_nice, xlabel=dep_var_label)\n",
    "g._legend.remove()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylim(plt.ylim()[0], plt.ylim()[1]/8)\n",
    "plt.tight_layout()\n",
    "plt.title(metric_name_nice)\n",
    "# util.multipage(f'C:/Users/lukas/Sync/lstm_inverse_problem/figures/results/dependence_{target_column}.pdf', png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependence on Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dependence on Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results\\\\metrics_duration.pkl', 'rb') as f:\n",
    "    [params, param_names] = pkl.load(f)\n",
    "\n",
    "mles, nmses, mses, aucs_combined, aucs_close, aucs_far = params\n",
    "params = [mles, nmses, aucs_combined]\n",
    "param_names = ['mles', 'nmses', 'aucs_combined']\n",
    "param_names_nice = [\"Mean Localization Error [mm]\", \"Normalized Mean Squared Error\", \"Area Under the Curve [%]\"]\n",
    "params[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Dependence On Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "sns.set(style='white', font_scale=1.6, font='helvetica')\n",
    "\n",
    "ylims = [[None, None], [None, None], [None, None]]\n",
    "scalers = [1, 1, 100]\n",
    "linewidth = 2.5\n",
    "x = np.arange(0, 201)[::5][::-1]\n",
    "for param, name, name_nice, ylim, scaler in zip(params, param_names, param_names_nice, ylims, scalers):\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    for model_name in params[0].keys():\n",
    "        if len(param[model_name])==1:\n",
    "            plt.plot(x, np.array(param[model_name]*len(x))*scaler, label=model_name, linewidth=linewidth)\n",
    "        else:\n",
    "            plt.plot(x, np.array(param[model_name])*scaler, label=model_name, linewidth=linewidth)\n",
    "\n",
    "\n",
    "    plt.xlabel('Number of available data points')\n",
    "    plt.ylabel(name_nice)\n",
    "    plt.ylim(ylim)\n",
    "    plt.title(name_nice)\n",
    "    plt.legend(loc=2, bbox_to_anchor=(1.05,1), borderaxespad=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "util.multipage(r'C:\\Users\\lukas\\Sync\\lstm_inverse_problem\\figures\\results\\dependence_duration.pdf', png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get interpolated Topomap for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.viz.topomap import (_setup_interp, _make_head_outlines, _check_sphere, \n",
    "    _check_extrapolate)\n",
    "from mne.channels.layout import _find_topomap_coords\n",
    "\n",
    "model = models[0]\n",
    "eeg, src = model._handle_data_input((sim,))\n",
    "eeg_prep = np.swapaxes(eeg[0].get_data(), 1,2)\n",
    "elec_pos = _find_topomap_coords(model.info, model.info.ch_names)\n",
    "interpolator = model.make_interpolator(elec_pos, res=model.interp_channel_shape[0])\n",
    "eeg_prep_interp = deepcopy(eeg_prep)\n",
    "for i, sample in tqdm(enumerate(eeg_prep)):\n",
    "    list_of_time_slices = []\n",
    "    for time_slice in sample:\n",
    "        time_slice_interp = interpolator.set_values(time_slice)()[::-1]\n",
    "        list_of_time_slices.append(time_slice_interp)\n",
    "\n",
    "sns.set(style='white')\n",
    "tick_font_size = 50\n",
    "plt.figure()\n",
    "plt.imshow(np.mean(list_of_time_slices, axis=0)*8e6, cmap='RdBu_r')\n",
    "plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "                labelbottom = False, bottom = False)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=tick_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def new_sim_params(sr=100, packages_per_second=20):\n",
    "    package_size = int( round( sr / packages_per_second  ) )\n",
    "    package_interval = package_size/sr\n",
    "\n",
    "    n_chan = len(sim_test.eeg_data.ch_names)\n",
    "    data_package = np.random.randn(n_chan, package_size)\n",
    "\n",
    "    sim_data_package = Simulation(fwd, info, settings=dict(duration_of_trial=0.01*package_size)).simulate(1)\n",
    "    print(f'performing predictions {packages_per_second} times per second')\n",
    "\n",
    "    return sim_data_package, package_interval\n",
    "\n",
    "packages_per_second = 50\n",
    "sim_data_package, package_interval = new_sim_params(packages_per_second=packages_per_second)\n",
    "\n",
    "while True:\n",
    "    start = time.time()\n",
    "    # stc = net_dense.predict(sim_data_package)\n",
    "    stc = models[0].predict(sim_data_package)\n",
    "\n",
    "    stop = time.time()\n",
    "    diff = stop-start\n",
    "    if stop-start > package_interval:\n",
    "        print(f\"took longer than expected: {diff} (instead of {package_interval})\")\n",
    "        print(f'decreasing package interval by one')\n",
    "        packages_per_second -= 1\n",
    "        sim_data_package, package_interval = new_sim_params(packages_per_second=packages_per_second)\n",
    "        print(f'packages_per_second={packages_per_second}\\n')\n",
    "        continue\n",
    "    time.sleep(package_interval-diff)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

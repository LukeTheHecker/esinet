{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../')\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import mne\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet import forward\n",
    "\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    2.1s remaining:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    2.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "info = forward.get_info()\n",
    "info['sfreq'] = 100\n",
    "fwd = forward.create_forward_model(info=info)\n",
    "fwd_free = forward.create_forward_model(info=info, fixed_ori=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_standard = util.load_net('models/LSTM Medium_1-1000points_standard-cosine_0')\n",
    "dense_standard = util.load_net('models/Dense Medium_1-1000points_standard-cosine_0')\n",
    "convdip_standard = util.load_net('models/ConvDip Medium_1-1000points_standard-cosine_0')\n",
    "\n",
    "models = [lstm_standard, dense_standard, convdip_standard]\n",
    "model_names = ['LSTM', 'Fully-Connected', 'ConvDip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot single ground truth and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 4466.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 100) (1284, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [00:00<00:00, 105.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 13.03it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d05df1588645e188dab1a50d7b1703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:388: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:388: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83c6bbc2d6343b0a5cf11935c2022c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:388: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:388: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82b3c0deb5844f0aa4f79825d92856b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:388: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:420: RuntimeWarning: Too few samples (required : 310 got : 100), covariance estimate may be unreliable\n",
      "  data_cov = mne.compute_raw_covariance(raw, tmin=tmin,\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:388: RuntimeWarning: An average reference projection was already added. The data has been left untouched.\n",
      "  epochs.set_eeg_reference(projection=True, verbose=verbose)#.apply_baseline(baseline=baseline)\n",
      "c:\\Users\\lukas\\Dokumente\\projects\\esinet\\evaluate\\..\\esinet\\util\\util.py:420: RuntimeWarning: Too few samples (required : 310 got : 100), covariance estimate may be unreliable\n",
      "  data_cov = mne.compute_raw_covariance(raw, tmin=tmin,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawArray | 61 x 500 (5.0 s), ~325 kB, data loaded> 4.0 info empirical\n",
      "<RawArray | 61 x 500 (5.0 s), ~325 kB, data loaded> 4.0 info empirical\n",
      "LSTM, error: 0.009551, r: 0.7136614161906574\n",
      "Fully-Connected, error: 0.01353, r: 0.5887072193723496\n",
      "ConvDip, error: 0.01734, r: 0.5246880901425557\n",
      "eLORETA, error: 0.1012, r: 0.1614547572011845\n",
      "MNE, error: 0.05877, r: 0.12983144421458173\n",
      "LCMV, error: 0.03435, r: 0.08681544504562365\n",
      "Using control points [2.01647748e-10 2.71510836e-10 1.23118085e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [2.01647748e-10 2.71510836e-10 1.23118085e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [7.47266520e-10 1.72226714e-09 8.31365150e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.07800510e-09 2.88319091e-09 9.75376176e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [7.47266520e-10 1.72226714e-09 8.31365150e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n",
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [7.19298552e-10 9.88622884e-10 2.39252744e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Encountered issue in callback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\mne\\viz\\_brain\\_brain.py\", line 1348, in _on_button_release\n",
      "    self.picked_renderer = self.plotter.iren.FindPokedRenderer(x, y)\n",
      "AttributeError: 'RenderWindowInteractor' object has no attribute 'FindPokedRenderer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [6.89443689e-10 9.57919761e-10 5.66304863e-09]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib qt\n",
    "sns.reset_orig()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "model_names_tmp = deepcopy(model_names)\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0, \n",
    "    clim=dict(kind='percent', pos_lims=[20, 30, 100]))\n",
    "\n",
    "settings_eval = dict(method='standard')\n",
    "# settings_eval = dict( method='standard')\n",
    "\n",
    "# Simulate new data\n",
    "sim = Simulation(fwd, info, settings=settings_eval).simulate(2)\n",
    "# snr = sim.simulation_info['target_snr'].values[0]\n",
    "snr = None\n",
    "# print(sim.simulation_info)\n",
    "idx = 0\n",
    "# Predict sources using the esinet models\n",
    "predictions = [model.predict(sim) for model in models]\n",
    "\n",
    "# Predict sources with classical methods\n",
    "# eLORETA\n",
    "prediction_elor_data = util.wrap_mne_inverse(fwd, sim, method='eLORETA', \n",
    "    add_baseline=True, n_baseline=400)[idx].data.astype(np.float32)\n",
    "prediction_elor = deepcopy(predictions[0][0])\n",
    "prediction_elor.data = prediction_elor_data / np.abs(np.max(prediction_elor_data))\n",
    "# MNE\n",
    "prediction_mne_data = util.wrap_mne_inverse(fwd, sim, method='MNE', \n",
    "    add_baseline=True, n_baseline=400)[idx].data.astype(np.float32)\n",
    "prediction_mne = deepcopy(predictions[0][0])\n",
    "prediction_mne.data = prediction_mne_data / np.abs(np.max(prediction_mne_data))\n",
    "# Beamformer\n",
    "prediction_lcmv_data = util.wrap_mne_inverse(fwd, sim, method='lcmv', \n",
    "    add_baseline=True, n_baseline=400, parallel=False)[idx].data.astype(np.float32)\n",
    "prediction_lcmv = deepcopy(predictions[0][0])\n",
    "prediction_lcmv.data = prediction_lcmv_data / np.max(np.abs(prediction_lcmv_data))\n",
    "\n",
    "# Get predictions and names in order\n",
    "predictions.append([prediction_elor])\n",
    "predictions.append([prediction_mne])\n",
    "predictions.append([prediction_lcmv])\n",
    "\n",
    "model_names_tmp.append('eLORETA')\n",
    "model_names_tmp.append('MNE')\n",
    "model_names_tmp.append('LCMV')\n",
    "\n",
    "# Plot True Source\n",
    "brain = sim.source_data[idx].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, f'Ground Truth {sim.simulation_info.number_of_sources.values[0]} sources', 'title')\n",
    "# Plot True EEG\n",
    "evoked = sim.eeg_data[idx].average()\n",
    "# evoked.plot()\n",
    "evoked.plot_topomap(title='Ground Truth')\n",
    "# evoked = util.get_eeg_from_source(sim.source_data[idx], fwd, info, tmin=0.)\n",
    "# evoked.plot_topomap(title='Ground Truth Noiseless')\n",
    "\n",
    "model_selection = model_names_tmp#['LCMV',]\n",
    "# Plot predicted sources\n",
    "for model_name, prediction in zip(model_names_tmp, predictions):\n",
    "    \n",
    "    if not any([model_name.lower() in model_select.lower() for model_select in model_selection]):\n",
    "        continue\n",
    "    error = util.batch_nmse(sim.source_data[idx].data, prediction[idx].data)\n",
    "    r = util.batch_corr(sim.source_data[idx].data, prediction[idx].data)\n",
    "    \n",
    "    brain = prediction[idx].plot(**plot_params)\n",
    "\n",
    "    title = f'{model_name}, error: {error:.4}, r: {r}'\n",
    "    print(title)\n",
    "    brain.add_text(0.1, 0.9, title, 'title')\n",
    "    # Plot predicted EEG\n",
    "    # evoked_esi = util.get_eeg_from_source(prediction[idx], fwd, info, tmin=0.)\n",
    "    # evoked_esi.plot_topomap(title=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Load Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 1000\n",
    "# duration_of_trial = (0.01, 2)\n",
    "# method = 'standard'\n",
    "# settings = dict(duration_of_trial=duration_of_trial, method=method)\n",
    "# sim_test = Simulation(fwd, info, verbose=False, settings=settings).simulate(n_samples=n_samples)\n",
    "# if type(duration_of_trial) == tuple:\n",
    "#     sim_test.save(f'simulations\\\\sim_test_{n_samples}_{int(duration_of_trial[0]*100)}-{int(duration_of_trial[1]*100)}points_{method}.pkl')\n",
    "# else:\n",
    "#     sim_test.save(f'simulations\\\\sim_test_{n_samples}_{int(duration_of_trial*100)}points_{method}.pkl')\n",
    "\n",
    "# or Load\n",
    "with open(f'simulations\\\\sim_test_1000_1-200points_standard.pkl', 'rb') as f:\n",
    "    sim_test = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from esinet.evaluate import eval_mean_localization_error, eval_nmse, eval_auc, eval_mse\n",
    "from esinet.util import wrap_mne_inverse\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "model_names_tmp = deepcopy(model_names)\n",
    "# Predict\n",
    "print('predict esinets...')\n",
    "predictions = [model.predict(sim_test) for model in models]\n",
    "\n",
    "print('predict elor')\n",
    "pred_elor = wrap_mne_inverse(fwd, sim_test, method='eLORETA', add_baseline=True, \n",
    "    n_baseline=400)\n",
    "model_names_tmp.append('eLORETA')\n",
    "predictions.append(pred_elor)\n",
    "\n",
    "print('predict MNE')\n",
    "pred_mne = wrap_mne_inverse(fwd, sim_test, method='MNE', add_baseline=True, \n",
    "    n_baseline=400)\n",
    "model_names_tmp.append('MNE')\n",
    "predictions.append(pred_mne)\n",
    "\n",
    "print('predict LCMV')\n",
    "pred_lcmv = wrap_mne_inverse(fwd, sim_test, method='lcmv', \n",
    "    parallel=False, add_baseline=True, n_baseline=400)\n",
    "model_names_tmp.append('LCMV')\n",
    "predictions.append(pred_lcmv)\n",
    "\n",
    "pos = util.unpack_fwd(fwd)[2]\n",
    "argsorted_distance_matrix = np.argsort(cdist(pos, pos), axis=-1)\n",
    "\n",
    "metrics = dict()\n",
    "true_sources = np.concatenate([src.data for src in sim_test.source_data], axis=1).T\n",
    "\n",
    "for prediction, model_name in tqdm(zip(predictions, model_names_tmp)):\n",
    "    print('\\n', model_name, ':\\n')\n",
    "     \n",
    "    predicted_sources = np.concatenate([src.data for src in prediction], axis=1).T\n",
    "\n",
    "    print('mle calculation....')\n",
    "    mean_localization_errors = [eval_mean_localization_error(true_source, predicted_source, pos, argsorted_distance_matrix=argsorted_distance_matrix) for true_source, predicted_source in tqdm(zip(true_sources, predicted_sources))]\n",
    "    print(len(mean_localization_errors), len(true_sources), len(predicted_sources))\n",
    "    print('auc calculation....')\n",
    "    # aucs_combined = [eval_auc(true_source, predicted_source, pos, epsilon=0.25, n_redraw=5) for true_source, predicted_source in tqdm(zip(true_sources, predicted_sources))]\n",
    "    aucs_combined = Parallel(n_jobs=-1, backend='loky') \\\n",
    "        (delayed(eval_auc)(true_source, predicted_source, pos, epsilon=0.25, n_redraw=5)\n",
    "        for true_source, predicted_source in tqdm(zip(true_sources, predicted_sources)))\n",
    "    print('nmse calculation....')\n",
    "    nmses = [eval_nmse(true_source, predicted_source) for true_source, predicted_source in tqdm(zip(true_sources, predicted_sources))]\n",
    "    print('mse calculation....')\n",
    "    mses = [eval_mse(true_source, predicted_source) for true_source, predicted_source in tqdm(zip(true_sources, predicted_sources))]\n",
    "\n",
    "    aucs_far = [auc[1] for auc in np.array(aucs_combined)]\n",
    "    aucs_close = [auc[0] for auc in np.array(aucs_combined)]\n",
    "    aucs_combined = [np.nanmean([auc[0], auc[1]]) for auc in np.array(aucs_combined)]\n",
    "\n",
    "    metric = pd.DataFrame(dict(\n",
    "        mean_localization_errors=mean_localization_errors,\n",
    "        aucs_combined=aucs_combined,\n",
    "        aucs_far=aucs_far,\n",
    "        aucs_close=aucs_close,\n",
    "        nmses=nmses,\n",
    "        mses=mses\n",
    "        )\n",
    "    )\n",
    "    metric.name = model_name\n",
    "    metrics[model_name] = metric\n",
    "    \n",
    "\n",
    "with open(f'results\\\\metrics_{len(true_sources)}_1-200points_standard.pkl', 'wb') as f:\n",
    "    pkl.dump([metrics, sim_test.simulation_info], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results\\\\metrics_101947_1-200points_standard.pkl', 'rb') as f:\n",
    "    [metrics, simulation_info] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\pandas\\core\\apply.py:821: RuntimeWarning: Mean of empty slice\n",
      "  results[i] = self.f(v)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_localization_errors</th>\n",
       "      <th>aucs_combined</th>\n",
       "      <th>aucs_far</th>\n",
       "      <th>aucs_close</th>\n",
       "      <th>nmses</th>\n",
       "      <th>mses</th>\n",
       "      <th>method</th>\n",
       "      <th>sample_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.219618</td>\n",
       "      <td>0.868293</td>\n",
       "      <td>0.942479</td>\n",
       "      <td>0.794107</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>4.666444e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.719351</td>\n",
       "      <td>0.822743</td>\n",
       "      <td>0.875600</td>\n",
       "      <td>0.769886</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>1.222845e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.562478</td>\n",
       "      <td>0.843674</td>\n",
       "      <td>0.921228</td>\n",
       "      <td>0.766119</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>2.504530e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.684041</td>\n",
       "      <td>0.887201</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>0.808311</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>1.005835e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.647893</td>\n",
       "      <td>0.828699</td>\n",
       "      <td>0.875775</td>\n",
       "      <td>0.781622</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>2.464672e-19</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_localization_errors  aucs_combined  aucs_far  aucs_close     nmses  \\\n",
       "0                 23.219618       0.868293  0.942479    0.794107  0.012646   \n",
       "1                 11.719351       0.822743  0.875600    0.769886  0.008011   \n",
       "2                 14.562478       0.843674  0.921228    0.766119  0.013500   \n",
       "3                 19.684041       0.887201  0.966092    0.808311  0.012914   \n",
       "4                 19.647893       0.828699  0.875775    0.781622  0.010828   \n",
       "\n",
       "           mses method  sample_id  \n",
       "0  4.666444e-19   LSTM          0  \n",
       "1  1.222845e-19   LSTM          1  \n",
       "2  2.504530e-19   LSTM          2  \n",
       "3  1.005835e-19   LSTM          3  \n",
       "4  2.464672e-19   LSTM          4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durs_in_samples = [round(dur*100) for dur in sim_test.simulation_info.duration_of_trials.values]\n",
    "\n",
    "idx = 0\n",
    "indices = []\n",
    "for dur in durs_in_samples:\n",
    "    idc = [idx, dur+idx]\n",
    "    indices.append(idc)\n",
    "    idx += dur\n",
    "metrics_short = dict()\n",
    "\n",
    "\n",
    "for method in metrics.keys():\n",
    "    metrics_short[method] = pd.DataFrame(columns=metrics[method].columns)\n",
    "    for id, idc in enumerate(indices):\n",
    "        sample_summary = metrics[method].iloc[idc[0]:idc[1]].apply(np.nanmean, axis=0)\n",
    "        sample_summary.sample_id = id\n",
    "        metrics_short[method] = metrics_short[method].append(sample_summary, ignore_index=True)\n",
    "    metrics_short[method].method = method\n",
    "    # metrics_short[method].iloc[:, 0:6].values = np.real(metrics_short[method].iloc[:, 0:6])\n",
    "\n",
    "dfs = [df[1] for df in list(metrics_short.items())]\n",
    "\n",
    "for i, (key, df) in enumerate(metrics_short.items()):\n",
    "    dfs[i]['method'] = [key]*df.shape[0]\n",
    "    dfs[i]['sample_id'] = np.arange(df.shape[0])\n",
    "df_aio = pd.concat(dfs)\n",
    "df_aio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot Overview \n",
    "### All Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mean_localization_errors  aucs_combined     aucs_far   aucs_close  \\\n",
      "count               5991.000000    5997.000000  5997.000000  5997.000000   \n",
      "mean                  18.291031       0.774498     0.831871     0.717124   \n",
      "std                    5.242296       0.124975     0.125013     0.133415   \n",
      "min                    0.000000       0.147200     0.141287     0.153114   \n",
      "25%                   15.181946       0.694053     0.768795     0.615655   \n",
      "50%                   18.794063       0.785411     0.858439     0.712460   \n",
      "75%                   21.760584       0.864222     0.924865     0.811050   \n",
      "max                   38.030185       1.000000     1.000000     1.000000   \n",
      "\n",
      "             nmses          mses   sample_id  \n",
      "count  5997.000000  6.000000e+03  6000.00000  \n",
      "mean      0.035624  2.433638e-15   499.50000  \n",
      "std       0.044970  7.350359e-14   288.69905  \n",
      "min       0.000658  1.265231e-23     0.00000  \n",
      "25%       0.010361  3.070457e-20   249.75000  \n",
      "50%       0.017352  8.683084e-20   499.50000  \n",
      "75%       0.051540  1.868503e-19   749.25000  \n",
      "max       1.011566  3.310751e-12   999.00000  \n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid', font_scale=1.6, font='helvetica')\n",
    "%matplotlib qt\n",
    "\n",
    "cols = ['mean_localization_errors', 'aucs_combined', 'nmses']  # df_aio.iloc[:, 0:6].columns\n",
    "metric_names = [\"Mean Localization Error [mm]\", \"Area Under the Curve\", \"Normalized Mean Squared Error\"]\n",
    "for y, metric_name in zip(cols, metric_names):\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    sns.boxplot(data=df_aio, x='method', y=y)\n",
    "    plt.title(metric_name)\n",
    "    plt.xlabel(\"Inverse Solution\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.ylim(0, None)\n",
    "# util.multipage(r'C:\\Users\\lukas\\Sync\\lstm_inverse_problem\\figures\\results\\boxplot_overview_allsims.pdf', png=True)\n",
    "print(df_aio.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid', font_scale=1.6, font='helvetica')\n",
    "%matplotlib qt\n",
    "\n",
    "idc_single_source = np.argwhere(simulation_info.number_of_sources.values==1)[:, 0]\n",
    "df_single = df_aio[df_aio.sample_id.isin(idc_single_source)]\n",
    "\n",
    "cols = ['mean_localization_errors', 'aucs_combined', 'nmses']  # df_single.iloc[:, 0:6].columns\n",
    "metric_names = [\"Mean Localization Error [mm]\", \"Area Under the Curve\", \"Normalized Mean Squared Error\"]\n",
    "for y, metric_name in zip(cols, metric_names):\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    sns.boxplot(data=df_single, x='method', y=y)\n",
    "    # sns.swarmplot(data=df_single, x='method', y=y)\n",
    "    plt.title(metric_name)\n",
    "    plt.xlabel(\"Inverse Solution\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.ylim(0, None)\n",
    "# util.multipage(r'C:\\Users\\lukas\\Sync\\lstm_inverse_problem\\figures\\results\\boxplot_overview_singlesource.pdf', png=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inverse Solution</th>\n",
       "      <th>MLE [mm] (SD)</th>\n",
       "      <th>AUC [%] (SD)</th>\n",
       "      <th>nMSE (SD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>15.85 (4.27)</td>\n",
       "      <td>0.86 (0.08)</td>\n",
       "      <td>0.0089 (0.0032)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fully-Connected</td>\n",
       "      <td>16.55 (3.87)</td>\n",
       "      <td>0.85 (0.07)</td>\n",
       "      <td>0.0109 (0.0036)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvDip</td>\n",
       "      <td>17.24 (3.96)</td>\n",
       "      <td>0.81 (0.08)</td>\n",
       "      <td>0.0124 (0.0038)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eLORETA</td>\n",
       "      <td>20.32 (5.45)</td>\n",
       "      <td>0.74 (0.1)</td>\n",
       "      <td>0.0832 (0.0752)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNE</td>\n",
       "      <td>22.48 (4.84)</td>\n",
       "      <td>0.72 (0.11)</td>\n",
       "      <td>0.0447 (0.0206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCMV</td>\n",
       "      <td>20.67 (5.7)</td>\n",
       "      <td>0.61 (0.13)</td>\n",
       "      <td>0.0348 (0.0193)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Inverse Solution MLE [mm] (SD) AUC [%] (SD)        nMSE (SD)\n",
       "5             LSTM  15.85 (4.27)  0.86 (0.08)  0.0089 (0.0032)\n",
       "3  Fully-Connected  16.55 (3.87)  0.85 (0.07)  0.0109 (0.0036)\n",
       "1          ConvDip  17.24 (3.96)  0.81 (0.08)  0.0124 (0.0038)\n",
       "2          eLORETA  20.32 (5.45)   0.74 (0.1)  0.0832 (0.0752)\n",
       "0              MNE  22.48 (4.84)  0.72 (0.11)  0.0447 (0.0206)\n",
       "4             LCMV   20.67 (5.7)  0.61 (0.13)  0.0348 (0.0193)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_of_interest = df_aio\n",
    "\n",
    "methods = set(df_of_interest.method.values)\n",
    "columns = ['method', 'mean_localization_errors', 'aucs_combined', 'nmses']  # df_aio.iloc[:, 0:6].columns\n",
    "column_names = [\"Inverse Solution\", \"MLE [mm] (SD)\", \"AUC [%] (SD)\", \"nMSE (SD)\"]\n",
    "decimals = [None, 2, 2, 4]\n",
    "\n",
    "table = pd.DataFrame(columns=column_names)\n",
    "for i, method in enumerate(methods):\n",
    "    row_dict = {column_names[0]:method}\n",
    "    for j, (column, column_name, decimal) in enumerate(zip(columns[1:], column_names[1:], decimals[1:])):\n",
    "        values = df_of_interest[df_of_interest.method==method][column].values\n",
    "        row_dict[column_name] = str(round(np.nanmedian(values), decimal)) + ' (' + str(round(np.nanstd(values), decimal)) + ')'\n",
    "    table = table.append(row_dict, ignore_index=True)\n",
    "table = table.sort_values(\"AUC [%] (SD)\", ascending=False)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inverse Solution</th>\n",
       "      <th>MLE [mm] (SD)</th>\n",
       "      <th>AUC [%] (SD)</th>\n",
       "      <th>nMSE (SD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNE</td>\n",
       "      <td>20.33 (8.43)</td>\n",
       "      <td>0.89 (0.16)</td>\n",
       "      <td>0.0372 (0.0248)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConvDip</td>\n",
       "      <td>14.13 (5.63)</td>\n",
       "      <td>0.96 (0.06)</td>\n",
       "      <td>0.0108 (0.0042)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eLORETA</td>\n",
       "      <td>10.87 (8.01)</td>\n",
       "      <td>0.91 (0.15)</td>\n",
       "      <td>0.0677 (0.0696)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fully-Connected</td>\n",
       "      <td>13.32 (5.51)</td>\n",
       "      <td>0.96 (0.08)</td>\n",
       "      <td>0.0109 (0.0044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCMV</td>\n",
       "      <td>17.73 (9.54)</td>\n",
       "      <td>0.66 (0.21)</td>\n",
       "      <td>0.0292 (0.0242)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>12.08 (5.53)</td>\n",
       "      <td>0.99 (0.07)</td>\n",
       "      <td>0.0073 (0.0031)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Inverse Solution MLE [mm] (SD) AUC [%] (SD)        nMSE (SD)\n",
       "0              MNE  20.33 (8.43)  0.89 (0.16)  0.0372 (0.0248)\n",
       "1          ConvDip  14.13 (5.63)  0.96 (0.06)  0.0108 (0.0042)\n",
       "2          eLORETA  10.87 (8.01)  0.91 (0.15)  0.0677 (0.0696)\n",
       "3  Fully-Connected  13.32 (5.51)  0.96 (0.08)  0.0109 (0.0044)\n",
       "4             LCMV  17.73 (9.54)  0.66 (0.21)  0.0292 (0.0242)\n",
       "5             LSTM  12.08 (5.53)  0.99 (0.07)  0.0073 (0.0031)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_single = df_aio[df_aio.sample_id.isin(idc_single_source)]\n",
    "\n",
    "df_of_interest = df_single\n",
    "\n",
    "methods = set(df_of_interest.method.values)\n",
    "columns = ['method', 'mean_localization_errors', 'aucs_combined', 'nmses']  # df_aio.iloc[:, 0:6].columns\n",
    "column_names = [\"Inverse Solution\", \"MLE [mm] (SD)\", \"AUC [%] (SD)\", \"nMSE (SD)\"]\n",
    "decimals = [None, 2, 2, 4]\n",
    "\n",
    "table = pd.DataFrame(columns=column_names)\n",
    "for i, method in enumerate(methods):\n",
    "    row_dict = {column_names[0]:method}\n",
    "    for j, (column, column_name, decimal) in enumerate(zip(columns[1:], column_names[1:], decimals[1:])):\n",
    "        values = df_of_interest[df_of_interest.method==method][column].values\n",
    "        row_dict[column_name] = str(round(np.nanmedian(values), decimal)) + ' (' + str(round(np.nanstd(values), decimal)) + ')'\n",
    "    table = table.append(row_dict, ignore_index=True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='whitegrid', font_scale=1.2, font='helvetica')\n",
    "%matplotlib qt\n",
    "methods_of_interest = ['LSTM Standard', 'Dense Standard']\n",
    "# df_select = df_aio[df_aio['method'].str.contains('|'.join(methods_of_interest))]\n",
    "\n",
    "cols = df_aio.iloc[:, 0:6].columns\n",
    "for method_name in cols:\n",
    "\n",
    "    vals_A = df_aio[df_aio['method'].str.contains(methods_of_interest[0])][method_name].values\n",
    "    vals_B = df_aio[df_aio['method'].str.contains(methods_of_interest[1])][method_name].values\n",
    "    d = {methods_of_interest[0]: vals_A, methods_of_interest[1]: vals_B,} \n",
    "    df_tmp = pd.DataFrame(d)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    ax = sns.scatterplot(data=df_tmp, x=methods_of_interest[0], y=methods_of_interest[1])\n",
    "\n",
    "\n",
    "    xlim, ylim = (plt.xlim(), plt.ylim())\n",
    "    plt.plot(xlim, ylim, '--k')\n",
    "    xlim = (xlim[0]*0.95, xlim[1]*1.05)\n",
    "    ylim = (ylim[0]*0.95, ylim[1]*1.05)\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    # Title\n",
    "    prop_higher = np.sum(vals_B > vals_A) / len(vals_A)\n",
    "    cohens_d = (np.nanmean(vals_A) - np.nanmean(vals_B)) / np.mean([np.nanstd(vals_A), np.nanstd(vals_B)])\n",
    "    median_diff = np.abs(np.nanmedian(vals_A-vals_B))\n",
    "    method_name_title = method_name.replace('_', ' ').title()\n",
    "    title = f'{method_name_title} ({methods_of_interest[1]} higher in {100*prop_higher:.1f} %)\\nmedian_difference: {median_diff}\\ncohens d: {abs(cohens_d):.2f}'\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    del d, df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependence on anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "sns.set(font_scale=1.2, font='helvetica')\n",
    "# pd.DataFrame( metrics , index=model_names)\n",
    "target_column = 'target_snr'\n",
    "binning = True\n",
    "n_bins = 6\n",
    "\n",
    "\n",
    "df = sim_test.simulation_info\n",
    "if binning:\n",
    "    minimum = np.min([np.min(arr) for arr in df[target_column].values])\n",
    "    maximum = np.max([np.max(arr) for arr in df[target_column].values])\n",
    "    \n",
    "    bins = np.linspace(minimum, maximum*1.01, num=n_bins)\n",
    "    bin_labels = [str(round(bins[i], 1)) + ' - ' + str(round(bins[i+1], 1)) for i in range(len(bins)-1)]\n",
    "    new_target_column = 'bins ' + target_column\n",
    "    df[new_target_column] = np.digitize(df[target_column].values, bins=bins)\n",
    "    target_column = new_target_column\n",
    "    \n",
    "else:\n",
    "    bins = list(set(df[target_column].values))\n",
    "    bins[-1] *= 1.01\n",
    "    bin_labels = [str(bins[i]) for i in range(len(bins))]\n",
    "\n",
    "\n",
    "for i, model_name in enumerate(list(set(df_aio.method.values))):\n",
    "    cols = df_aio[df_aio.method==model_name].iloc[:, 0:6].columns\n",
    "    values = df_aio[df_aio.method==model_name].iloc[:, 0:6].values\n",
    "\n",
    "    for metric_name, metric in zip(cols, values.T):\n",
    "        col_name = model_name.replace(' ', '_') + '_' + metric_name.replace(' ', '_')\n",
    "        df[col_name] = metric\n",
    "\n",
    "dep_var_regex = target_column\n",
    "dep_var_label = target_column.replace('_', ' ').title()\n",
    "metric_names_nice = [col.replace('_', ' ').title() for col in df_aio.iloc[:, :6].columns]\n",
    "for metric_name, metric_name_nice in zip(df_aio.iloc[:, :6].columns,  metric_names_nice):\n",
    "    df_temp = pd.concat((df.filter(regex=dep_var_regex), df.filter(regex='_'+metric_name)), axis=1).melt(dep_var_regex, var_name='cols', value_name='vals')\n",
    "    g = sns.catplot(x=dep_var_regex, y='vals', hue='cols', capsize=.2, kind='point', data=df_temp)\n",
    "    g.set(xticklabels=bin_labels, ylabel=metric_name_nice, xlabel=dep_var_label)\n",
    "    g._legend.remove()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependence on Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 88.67it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 643.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 500) (1284, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:52<00:00, 18.88it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60875d7cae045a2aece6c7d2a9e5a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:53,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:52,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:49,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:49,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:49,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:48,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:51,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:50,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:46,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:46,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:47,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:52,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:46,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:48,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:55,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:46,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:48,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:48,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:47,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:49,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:47,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:44,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:44,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:44,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:41,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:39,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:40,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:40,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:40,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:41,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:37,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:36,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:33,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:37,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:31,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:35,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:30,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:30,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:32,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:31,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:33,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:30,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:27,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:26,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:27,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:24,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:28,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:22,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:22,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:23,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:24,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:21,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:25,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:21,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:19,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:22,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:19,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:18,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:18,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:15,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:14,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:14,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:12,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:18,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:15,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:15,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpolating for convdip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:17,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from esinet import evaluate\n",
    "\n",
    "n_simulations = 1000\n",
    "settings = dict(duration_of_trial=5.0,)\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_simulations)\n",
    "\n",
    "times = sim.source_data[0].times\n",
    "\n",
    "pos = util.unpack_fwd(fwd)[2]\n",
    "argsorted_distance_matrix = np.argsort(cdist(pos, pos), axis=-1)\n",
    "\n",
    "mles = dict()\n",
    "nmses = dict()\n",
    "mses = dict()\n",
    "aucs_combined = dict()\n",
    "aucs_close = dict()\n",
    "aucs_far = dict()\n",
    "\n",
    "points = dict()\n",
    "for i, time in tqdm(enumerate(times[:-1][::1])):\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        if not model_name in mles.keys():\n",
    "            mles[model_name] = []    \n",
    "            nmses[model_name] = []\n",
    "            mses[model_name] = []    \n",
    "            aucs_combined[model_name] = []\n",
    "            aucs_close[model_name] = []\n",
    "            aucs_far[model_name] = []\n",
    "            points[model_name] = []\n",
    "\n",
    "        mle = []\n",
    "        nmse = []\n",
    "        mse = []\n",
    "        auc = []\n",
    "        new_sim = deepcopy(sim).crop(tmin=time)\n",
    "        y_pred = model.predict(new_sim)\n",
    "        \n",
    "        for idx in range(n_simulations):\n",
    "            y_true = sim.source_data[idx].data[:, -1][:, np.newaxis]\n",
    "            y_est = y_pred[idx].data[:, -1][:, np.newaxis]\n",
    "            mle.append( evaluate.eval_mean_localization_error(y_true, y_est, pos, \n",
    "                argsorted_distance_matrix=argsorted_distance_matrix) )\n",
    "            nmse.append( evaluate.eval_nmse(y_true, y_est) )\n",
    "            mse.append( evaluate.eval_mse(y_true, y_est) )\n",
    "            auc.append( evaluate.eval_auc(y_true, y_est, pos, n_redraw=5, epsilon=0.25) )\n",
    "\n",
    "        auc_combined = [(a[0]+a[1])/2 for a in auc]\n",
    "        auc_close = [a[0] for a in auc]\n",
    "        auc_far = [a[1] for a in auc]\n",
    "            \n",
    "\n",
    "        \n",
    "        mles[model_name].append(np.nanmean(mle))\n",
    "        nmses[model_name].append(np.nanmean(nmse))\n",
    "        mses[model_name].append(np.nanmean(mse))\n",
    "        aucs_combined[model_name].append(np.nanmean(auc_combined))\n",
    "        aucs_close[model_name].append(np.nanmean(auc_close))\n",
    "        aucs_far[model_name].append(np.nanmean(auc_far))\n",
    "        points[model_name].append(new_sim.source_data[idx].shape[1])\n",
    "\n",
    "params = [mles, nmses, mses, aucs_combined, aucs_close, aucs_far]\n",
    "param_names = ['mles', 'nmses', 'mses', 'aucs_combined', 'aucs_close', 'aucs_far']\n",
    "\n",
    "with open(f'results\\\\metrics_duration.pkl', 'wb') as f:\n",
    "    pkl.dump([params, param_names], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [mles, nmses, mses, aucs_combined, aucs_close, aucs_far]\n",
    "param_names = ['mles', 'nmses', 'mses', 'aucs_combined', 'aucs_close', 'aucs_far']\n",
    "for param, name in zip(params, param_names):\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    for model_name in model_names:\n",
    "        plt.plot(points[model_name], param[model_name], label=model_name)\n",
    "\n",
    "    plt.xlabel('Number of available data points')\n",
    "    plt.title(f'{name} ground truth vs prediction')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get interpolated Topomap for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f4b64aa7f54a53a2314d822bd48ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mne.viz.topomap import (_setup_interp, _make_head_outlines, _check_sphere, \n",
    "    _check_extrapolate)\n",
    "from mne.channels.layout import _find_topomap_coords\n",
    "\n",
    "model = models[0]\n",
    "eeg, src = model._handle_data_input((sim,))\n",
    "eeg_prep = np.swapaxes(eeg[0].get_data(), 1,2)\n",
    "elec_pos = _find_topomap_coords(model.info, model.info.ch_names)\n",
    "interpolator = model.make_interpolator(elec_pos, res=model.interp_channel_shape[0])\n",
    "eeg_prep_interp = deepcopy(eeg_prep)\n",
    "for i, sample in tqdm(enumerate(eeg_prep)):\n",
    "    list_of_time_slices = []\n",
    "    for time_slice in sample:\n",
    "        time_slice_interp = interpolator.set_values(time_slice)()[::-1]\n",
    "        list_of_time_slices.append(time_slice_interp)\n",
    "\n",
    "sns.set(style='white')\n",
    "tick_font_size = 50\n",
    "plt.figure()\n",
    "plt.imshow(np.mean(list_of_time_slices, axis=0)*8e6, cmap='RdBu_r')\n",
    "plt.tick_params(left = False, right = False , labelleft = False ,\n",
    "                labelbottom = False, bottom = False)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.tick_params(labelsize=tick_font_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def new_sim_params(sr=100, packages_per_second=20):\n",
    "    package_size = int( round( sr / packages_per_second  ) )\n",
    "    package_interval = package_size/sr\n",
    "\n",
    "    n_chan = len(sim_test.eeg_data.ch_names)\n",
    "    data_package = np.random.randn(n_chan, package_size)\n",
    "\n",
    "    sim_data_package = Simulation(fwd, info, settings=dict(duration_of_trial=0.01*package_size)).simulate(1)\n",
    "    print(f'performing predictions {packages_per_second} times per second')\n",
    "\n",
    "    return sim_data_package, package_interval\n",
    "\n",
    "packages_per_second = 50\n",
    "sim_data_package, package_interval = new_sim_params(packages_per_second=packages_per_second)\n",
    "\n",
    "while True:\n",
    "    start = time.time()\n",
    "    # stc = net_dense.predict(sim_data_package)\n",
    "    stc = models[0].predict(sim_data_package)\n",
    "\n",
    "    stop = time.time()\n",
    "    diff = stop-start\n",
    "    if stop-start > package_interval:\n",
    "        print(f\"took longer than expected: {diff} (instead of {package_interval})\")\n",
    "        print(f'decreasing package interval by one')\n",
    "        packages_per_second -= 1\n",
    "        sim_data_package, package_interval = new_sim_params(packages_per_second=packages_per_second)\n",
    "        print(f'packages_per_second={packages_per_second}\\n')\n",
    "        continue\n",
    "    time.sleep(package_interval-diff)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import mne\r\n",
    "import numpy as np\r\n",
    "from copy import deepcopy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys; sys.path.insert(0, '../')\r\n",
    "from esinet import util\r\n",
    "from esinet import Simulation\r\n",
    "from esinet import Net\r\n",
    "from esinet.forward import create_forward_model, get_info\r\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forward Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "info = get_info()\r\n",
    "info['sfreq'] = 100\r\n",
    "fwd = create_forward_model(info=info)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    1.4s remaining:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    1.5s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simulate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "n_samples = 10000\r\n",
    "settings = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "sim_lstm = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=n_samples)\r\n",
    "sim_dense = util.convert_simulation_temporal_to_single(sim_lstm)\r\n",
    "\r\n",
    "sim_lstm_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=1000)\r\n",
    "sim_dense_test = util.convert_simulation_temporal_to_single(sim_lstm_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "103cb74de187447a9fd56ab93a1a04c3"
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Source Data to mne.SourceEstimate object\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6f20d02a7a6403aa5c7b6b63838aab7"
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Project sources to EEG...\n",
      "\n",
      "Create EEG trials with noise...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f146366b471a41adbf7b298b147262f3"
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Convert EEG matrices to a single instance of mne.Epochs...\n",
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b561161645f420195618e614cb173cf"
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Keras-Tuner"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import keras_tuner as kt\r\n",
    "import tensorflow as tf\r\n",
    "from esinet.net import build_nas_lstm\r\n",
    "\r\n",
    "# tuner = kt.BayesianOptimization(\r\n",
    "#     build_nas_lstm,\r\n",
    "#     objective='val_loss',\r\n",
    "#     max_trials=450, \r\n",
    "#     directory='keras-tuner',\r\n",
    "#     project_name=f'holiday_run',\r\n",
    "#     # max_model_size=int(2e6),  # Maximum 700k parameters per model\r\n",
    "#     beta=2.6*2,  # exploration parameter\r\n",
    "#     )    \r\n",
    "tuner = kt.RandomSearch(\r\n",
    "    build_nas_lstm,\r\n",
    "    objective='val_loss',\r\n",
    "    max_trials=450, \r\n",
    "    directory='keras-tuner',\r\n",
    "    project_name=f'holiday_run',\r\n",
    "    )\r\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=15, min_delta=0.0001)]\r\n",
    "net = Net(fwd)\r\n",
    "x_train, y_train = net.prep_data(sim_lstm)\r\n",
    "x_val, y_val = net.prep_data(sim_lstm_test)\r\n",
    "tuner.search(x_train, y_train, epochs=150, validation_data=(x_val, y_val), \r\n",
    "    batch_size=8, callbacks=callbacks, shuffle=True)\r\n",
    "\r\n",
    "best_model = tuner.get_best_models()[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lstm_layers       |2                 |?                 \n",
      "dense_layers      |2                 |?                 \n",
      "activation_out    |sigmoid           |?                 \n",
      "actvation_all     |elu               |?                 \n",
      "learning_rate     |0.018376          |?                 \n",
      "Clip Value        |0.31386           |?                 \n",
      "\n",
      "Epoch 1/150\n",
      "1250/1250 [==============================] - 16s 10ms/step - loss: 0.1794 - mse: 1.0194 - mae: 0.2337 - val_loss: 0.1814 - val_mse: 1.0186 - val_mae: 0.2357\n",
      "Epoch 2/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1790 - mse: 1.0184 - mae: 0.2316 - val_loss: 0.1814 - val_mse: 1.0186 - val_mae: 0.2357\n",
      "Epoch 3/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1790 - mse: 1.0184 - mae: 0.2317 - val_loss: 0.1813 - val_mse: 1.0185 - val_mae: 0.2363\n",
      "Epoch 4/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1790 - mse: 1.0183 - mae: 0.2322 - val_loss: 0.1813 - val_mse: 1.0184 - val_mae: 0.2362\n",
      "Epoch 5/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1790 - mse: 1.0179 - mae: 0.2328 - val_loss: 0.1812 - val_mse: 1.0175 - val_mae: 0.2372\n",
      "Epoch 6/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1788 - mse: 1.0168 - mae: 0.2348 - val_loss: 0.1811 - val_mse: 1.0167 - val_mae: 0.2389\n",
      "Epoch 7/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1788 - mse: 1.0160 - mae: 0.2362 - val_loss: 0.1811 - val_mse: 1.0165 - val_mae: 0.2399\n",
      "Epoch 8/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1788 - mse: 1.0164 - mae: 0.2351 - val_loss: 0.1813 - val_mse: 1.0180 - val_mae: 0.2375\n",
      "Epoch 9/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1790 - mse: 1.0180 - mae: 0.2326 - val_loss: 0.1812 - val_mse: 1.0171 - val_mae: 0.2386\n",
      "Epoch 10/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1788 - mse: 1.0166 - mae: 0.2353 - val_loss: 0.1812 - val_mse: 1.0165 - val_mae: 0.2410\n",
      "Epoch 11/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1789 - mse: 1.0169 - mae: 0.2356 - val_loss: 0.1812 - val_mse: 1.0171 - val_mae: 0.2396\n",
      "Epoch 12/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1788 - mse: 1.0165 - mae: 0.2361 - val_loss: 0.1812 - val_mse: 1.0170 - val_mae: 0.2395\n",
      "Epoch 13/150\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1788 - mse: 1.0167 - mae: 0.2352 - val_loss: 0.1812 - val_mse: 1.0177 - val_mae: 0.2372\n",
      "Epoch 14/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1788 - mse: 1.0163 - mae: 0.2355 - val_loss: 0.1811 - val_mse: 1.0163 - val_mae: 0.2395\n",
      "Epoch 15/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1787 - mse: 1.0151 - mae: 0.2366 - val_loss: 0.1810 - val_mse: 1.0151 - val_mae: 0.2399\n",
      "Epoch 16/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1786 - mse: 1.0139 - mae: 0.2369 - val_loss: 0.1809 - val_mse: 1.0137 - val_mae: 0.2416\n",
      "Epoch 17/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1785 - mse: 1.0129 - mae: 0.2368 - val_loss: 0.1811 - val_mse: 1.0126 - val_mae: 0.2438\n",
      "Epoch 18/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1784 - mse: 1.0123 - mae: 0.2367 - val_loss: 0.1808 - val_mse: 1.0128 - val_mae: 0.2404\n",
      "Epoch 19/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1784 - mse: 1.0120 - mae: 0.2367 - val_loss: 0.1808 - val_mse: 1.0123 - val_mae: 0.2403\n",
      "Epoch 20/150\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1784 - mse: 1.0116 - mae: 0.2366 - val_loss: 0.1807 - val_mse: 1.0122 - val_mae: 0.2414\n",
      "Epoch 21/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1783 - mse: 1.0109 - mae: 0.2365 - val_loss: 0.1807 - val_mse: 1.0109 - val_mae: 0.2410\n",
      "Epoch 22/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1783 - mse: 1.0105 - mae: 0.2363 - val_loss: 0.1807 - val_mse: 1.0114 - val_mae: 0.2405\n",
      "Epoch 23/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1782 - mse: 1.0104 - mae: 0.2362 - val_loss: 0.1807 - val_mse: 1.0124 - val_mae: 0.2401\n",
      "Epoch 24/150\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 0.1782 - mse: 1.0103 - mae: 0.2362 - val_loss: 0.1807 - val_mse: 1.0108 - val_mae: 0.2405\n",
      "Epoch 25/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1782 - mse: 1.0099 - mae: 0.2363 - val_loss: 0.1806 - val_mse: 1.0110 - val_mae: 0.2399\n",
      "Epoch 26/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1782 - mse: 1.0096 - mae: 0.2362 - val_loss: 0.1808 - val_mse: 1.0118 - val_mae: 0.2407\n",
      "Epoch 27/150\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1781 - mse: 1.0093 - mae: 0.2361 - val_loss: 0.1807 - val_mse: 1.0103 - val_mae: 0.2407\n",
      "Epoch 28/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1781 - mse: 1.0088 - mae: 0.2361 - val_loss: 0.1806 - val_mse: 1.0114 - val_mae: 0.2386\n",
      "Epoch 29/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1781 - mse: 1.0084 - mae: 0.2360 - val_loss: 0.1806 - val_mse: 1.0091 - val_mae: 0.2401\n",
      "Epoch 30/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1780 - mse: 1.0080 - mae: 0.2359 - val_loss: 0.1805 - val_mse: 1.0094 - val_mae: 0.2397\n",
      "Epoch 31/150\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1780 - mse: 1.0079 - mae: 0.2357 - val_loss: 0.1805 - val_mse: 1.0086 - val_mae: 0.2406\n",
      "Epoch 32/150\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 0.1780 - mse: 1.0078 - mae: 0.2358 - val_loss: 0.1806 - val_mse: 1.0107 - val_mae: 0.2389\n",
      "Epoch 33/150\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.1780 - mse: 1.0078 - mae: 0.2357"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x000001A94757BDC0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 545, in __del__\n",
      "    gen_dataset_ops.delete_iterator(\n",
      "  File \"C:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1262, in delete_iterator\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1250/1250 [==============================] - 12s 10ms/step - loss: 0.1780 - mse: 1.0078 - mae: 0.2357 - val_loss: 0.1805 - val_mse: 1.0097 - val_mae: 0.2389\n",
      "Epoch 34/150\n",
      " 681/1250 [===============>..............] - ETA: 5s - loss: 0.1782 - mse: 1.0077 - mae: 0.2359"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize Keras Tuner results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import json\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "base_path = 'keras-tuner/holiday_run'\r\n",
    "folders = os.listdir(base_path)\r\n",
    "folders = [folder for folder in folders if folder.startswith('trial_')]\r\n",
    "hyperparams = []\r\n",
    "scores = []\r\n",
    "for folder in folders:\r\n",
    "    # Load trial data\r\n",
    "    with open(base_path + '/' + folder + '/trial.json') as json_file:\r\n",
    "        data = json.load(json_file)\r\n",
    "    try:\r\n",
    "        # extract score\r\n",
    "        scores.append( data['metrics']['metrics']['val_loss']['observations'][0]['value'][0] )\r\n",
    "        # extract hyperparameters\r\n",
    "        hyperparams.append( data['hyperparameters']['values'] )\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "\r\n",
    "dfs = []\r\n",
    "for i, (score, hyper) in enumerate(zip(scores, hyperparams)):\r\n",
    "    df = pd.DataFrame.from_dict(hyper, orient='index').T\r\n",
    "    df['score'] = score\r\n",
    "    dfs.append(df)\r\n",
    "\r\n",
    "df = pd.concat(dfs).sort_values('score')\r\n",
    "df\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>activation_out</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>Clip Value</th>\n",
       "      <th>lstm_units_l-0</th>\n",
       "      <th>dropout_lstm_l-0</th>\n",
       "      <th>activation_LSTM_l-0</th>\n",
       "      <th>dense_units_l-0</th>\n",
       "      <th>dropout_dense_l-0</th>\n",
       "      <th>...</th>\n",
       "      <th>dense_units_l-1</th>\n",
       "      <th>dropout_dense_l-1</th>\n",
       "      <th>activation_dense_l-1</th>\n",
       "      <th>dense_units_l-2</th>\n",
       "      <th>dropout_dense_l-2</th>\n",
       "      <th>activation_dense_l-2</th>\n",
       "      <th>lstm_units_l-2</th>\n",
       "      <th>dropout_lstm_l-2</th>\n",
       "      <th>activation_LSTM_l-2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.487891</td>\n",
       "      <td>53</td>\n",
       "      <td>0.504278</td>\n",
       "      <td>relu</td>\n",
       "      <td>232</td>\n",
       "      <td>0.746615</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.819406</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>130</td>\n",
       "      <td>0.433292</td>\n",
       "      <td>linear</td>\n",
       "      <td>177</td>\n",
       "      <td>0.265627</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.178093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.083285</td>\n",
       "      <td>0.174854</td>\n",
       "      <td>28</td>\n",
       "      <td>0.605605</td>\n",
       "      <td>swish</td>\n",
       "      <td>195</td>\n",
       "      <td>0.407561</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>0.746919</td>\n",
       "      <td>elu</td>\n",
       "      <td>208</td>\n",
       "      <td>0.226192</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>168</td>\n",
       "      <td>0.820055</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.178508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.395787</td>\n",
       "      <td>110</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>0.430766</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>0.821892</td>\n",
       "      <td>elu</td>\n",
       "      <td>60</td>\n",
       "      <td>0.152578</td>\n",
       "      <td>swish</td>\n",
       "      <td>64</td>\n",
       "      <td>0.289586</td>\n",
       "      <td>swish</td>\n",
       "      <td>0.178809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.743046</td>\n",
       "      <td>168</td>\n",
       "      <td>0.817094</td>\n",
       "      <td>linear</td>\n",
       "      <td>292</td>\n",
       "      <td>0.556742</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>0.178425</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>204</td>\n",
       "      <td>0.509599</td>\n",
       "      <td>elu</td>\n",
       "      <td>134</td>\n",
       "      <td>0.498293</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.178881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>0.875491</td>\n",
       "      <td>60</td>\n",
       "      <td>0.716961</td>\n",
       "      <td>relu</td>\n",
       "      <td>160</td>\n",
       "      <td>0.065718</td>\n",
       "      <td>...</td>\n",
       "      <td>187</td>\n",
       "      <td>0.623566</td>\n",
       "      <td>linear</td>\n",
       "      <td>164</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>29</td>\n",
       "      <td>0.448039</td>\n",
       "      <td>swish</td>\n",
       "      <td>0.179182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.062547</td>\n",
       "      <td>0.162525</td>\n",
       "      <td>186</td>\n",
       "      <td>0.632301</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>66</td>\n",
       "      <td>0.60209</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0.829584</td>\n",
       "      <td>swish</td>\n",
       "      <td>290</td>\n",
       "      <td>0.733773</td>\n",
       "      <td>elu</td>\n",
       "      <td>147</td>\n",
       "      <td>0.715338</td>\n",
       "      <td>swish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.086794</td>\n",
       "      <td>0.382668</td>\n",
       "      <td>53</td>\n",
       "      <td>0.487244</td>\n",
       "      <td>elu</td>\n",
       "      <td>237</td>\n",
       "      <td>0.808963</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>0.474454</td>\n",
       "      <td>relu</td>\n",
       "      <td>213</td>\n",
       "      <td>0.070639</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>147</td>\n",
       "      <td>0.449501</td>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.085382</td>\n",
       "      <td>0.820841</td>\n",
       "      <td>130</td>\n",
       "      <td>0.196546</td>\n",
       "      <td>relu</td>\n",
       "      <td>92</td>\n",
       "      <td>0.123056</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.400367</td>\n",
       "      <td>177</td>\n",
       "      <td>0.419022</td>\n",
       "      <td>elu</td>\n",
       "      <td>180</td>\n",
       "      <td>0.371258</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.824206</td>\n",
       "      <td>linear</td>\n",
       "      <td>63</td>\n",
       "      <td>0.300334</td>\n",
       "      <td>swish</td>\n",
       "      <td>114</td>\n",
       "      <td>0.228853</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.060045</td>\n",
       "      <td>0.968164</td>\n",
       "      <td>69</td>\n",
       "      <td>0.234618</td>\n",
       "      <td>elu</td>\n",
       "      <td>75</td>\n",
       "      <td>0.443944</td>\n",
       "      <td>...</td>\n",
       "      <td>126</td>\n",
       "      <td>0.42745</td>\n",
       "      <td>linear</td>\n",
       "      <td>89</td>\n",
       "      <td>0.321715</td>\n",
       "      <td>linear</td>\n",
       "      <td>173</td>\n",
       "      <td>0.60417</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lstm_layers dense_layers activation_out learning_rate Clip Value  \\\n",
       "0            0            0        sigmoid      0.009764   0.487891   \n",
       "0            0            1         linear      0.083285   0.174854   \n",
       "0            1            2           tanh      0.002344   0.395787   \n",
       "0            1            0           tanh      0.002429   0.743046   \n",
       "0            1            1         linear      0.003782   0.875491   \n",
       "..         ...          ...            ...           ...        ...   \n",
       "0            3            1        sigmoid      0.062547   0.162525   \n",
       "0            1            2         linear      0.086794   0.382668   \n",
       "0            2            2         linear      0.085382   0.820841   \n",
       "0            2            2         linear      0.078846   0.400367   \n",
       "0            3            3        sigmoid      0.060045   0.968164   \n",
       "\n",
       "   lstm_units_l-0 dropout_lstm_l-0 activation_LSTM_l-0 dense_units_l-0  \\\n",
       "0              53         0.504278                relu             232   \n",
       "0              28         0.605605               swish             195   \n",
       "0             110         0.611545              linear              30   \n",
       "0             168         0.817094              linear             292   \n",
       "0              60         0.716961                relu             160   \n",
       "..            ...              ...                 ...             ...   \n",
       "0             186         0.632301             sigmoid              66   \n",
       "0              53         0.487244                 elu             237   \n",
       "0             130         0.196546                relu              92   \n",
       "0             177         0.419022                 elu             180   \n",
       "0              69         0.234618                 elu              75   \n",
       "\n",
       "   dropout_dense_l-0  ... dense_units_l-1 dropout_dense_l-1  \\\n",
       "0           0.746615  ...              30          0.819406   \n",
       "0           0.407561  ...              58          0.746919   \n",
       "0           0.430766  ...             213          0.821892   \n",
       "0           0.556742  ...              94          0.178425   \n",
       "0           0.065718  ...             187          0.623566   \n",
       "..               ...  ...             ...               ...   \n",
       "0            0.60209  ...              45          0.829584   \n",
       "0           0.808963  ...             118          0.474454   \n",
       "0           0.123056  ...              25               0.0   \n",
       "0           0.371258  ...              49          0.824206   \n",
       "0           0.443944  ...             126           0.42745   \n",
       "\n",
       "   activation_dense_l-1 dense_units_l-2 dropout_dense_l-2  \\\n",
       "0               sigmoid             130          0.433292   \n",
       "0                   elu             208          0.226192   \n",
       "0                   elu              60          0.152578   \n",
       "0               sigmoid             204          0.509599   \n",
       "0                linear             164          0.006458   \n",
       "..                  ...             ...               ...   \n",
       "0                 swish             290          0.733773   \n",
       "0                  relu             213          0.070639   \n",
       "0               sigmoid             NaN               NaN   \n",
       "0                linear              63          0.300334   \n",
       "0                linear              89          0.321715   \n",
       "\n",
       "   activation_dense_l-2 lstm_units_l-2 dropout_lstm_l-2 activation_LSTM_l-2  \\\n",
       "0                linear            177         0.265627             sigmoid   \n",
       "0               sigmoid            168         0.820055             sigmoid   \n",
       "0                 swish             64         0.289586               swish   \n",
       "0                   elu            134         0.498293              linear   \n",
       "0               sigmoid             29         0.448039               swish   \n",
       "..                  ...            ...              ...                 ...   \n",
       "0                   elu            147         0.715338               swish   \n",
       "0               sigmoid            147         0.449501                relu   \n",
       "0                   NaN            NaN              NaN                 NaN   \n",
       "0                 swish            114         0.228853              linear   \n",
       "0                linear            173          0.60417              linear   \n",
       "\n",
       "       score  \n",
       "0   0.178093  \n",
       "0   0.178508  \n",
       "0   0.178809  \n",
       "0   0.178881  \n",
       "0   0.179182  \n",
       "..       ...  \n",
       "0        NaN  \n",
       "0        NaN  \n",
       "0        NaN  \n",
       "0        NaN  \n",
       "0        NaN  \n",
       "\n",
       "[87 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.to_excel(r'C:\\Users\\lukas\\Dokumente\\projects\\esinet\\keras-tuner\\holidayrun.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build & train LSTM network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = 200\r\n",
    "patience = 20\r\n",
    "activation_funcion = 'relu'\r\n",
    "loss = 'huber'\r\n",
    "dropout = 0.2\r\n",
    "# Train\r\n",
    "# model_params = dict(activation_function=activation_funcion, n_dense_layers=2, \r\n",
    "#     n_dense_units=200)\r\n",
    "# train_params = dict(epochs=epochs, patience=patience, tensorboard=True, \r\n",
    "#     dropout=dropout, loss=loss, optimizer='adam', return_history=True)\r\n",
    "# net_dense = Net(fwd, **model_params)\r\n",
    "# _, history_dense = net_dense.fit(sim_dense, **train_params)\r\n",
    "\r\n",
    "# LSTM v2\r\n",
    "model_params = dict(activation_function=activation_funcion, n_lstm_layers=2, \r\n",
    "    n_lstm_units=75, model_type='v2')\r\n",
    "train_params = dict(epochs=epochs, patience=patience, tensorboard=True, \r\n",
    "    dropout=dropout, loss=loss, optimizer=None, return_history=True, \r\n",
    "    batch_size=8)\r\n",
    "\r\n",
    "net_lstm_v2 = Net(fwd, **model_params)\r\n",
    "_, history_lstm = net_lstm_v2.fit(sim_lstm, **train_params)\r\n",
    "\r\n",
    "# LSTM v3\r\n",
    "# model_params = dict(activation_function=activation_funcion, n_lstm_layers=2, \r\n",
    "#     n_lstm_units=75, model_type='v3')\r\n",
    "# train_params = dict(epochs=epochs, patience=patience, tensorboard=True, \r\n",
    "#     dropout=dropout, loss=loss, optimizer=None, return_history=True, \r\n",
    "#     batch_size=8)\r\n",
    "\r\n",
    "# net_lstm_v3 = Net(fwd, **model_params)\r\n",
    "# _, history_lstm = net_lstm_v3.fit(sim_lstm, **train_params)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt\r\n",
    "settings_eval = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "# Simulate new data\r\n",
    "sim_test = Simulation(fwd, info, settings=settings_eval).simulate(1)\r\n",
    "idx = 0\r\n",
    "# Predict sources\r\n",
    "prediction_dense = net_dense.predict(sim_test)\r\n",
    "prediction_lstm = net_lstm_v2.predict(sim_test)\r\n",
    "\r\n",
    "\r\n",
    "# Plot True Source\r\n",
    "brain = sim_test.source_data[idx].plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title')\r\n",
    "\r\n",
    "# Plot True EEG\r\n",
    "evoked = sim_test.eeg_data[idx].average()\r\n",
    "evoked.plot()\r\n",
    "evoked.plot_topomap(title='Ground Truth')\r\n",
    "evoked = util.get_eeg_from_source(sim_test.source_data[idx], fwd, info, tmin=0.)\r\n",
    "evoked.plot_topomap(title='Ground Truth Noiseless')\r\n",
    "\r\n",
    "\r\n",
    "# Plot predicted source Dense\r\n",
    "brain = prediction_dense.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Dense', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_dense, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='Dense')\r\n",
    "\r\n",
    "# Plot predicted source LSTM\r\n",
    "brain = prediction_lstm.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_lstm, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='LSTM')\r\n",
    "\r\n",
    "error_dense = ((prediction_dense.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "error_lstm = ((prediction_lstm.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "\r\n",
    "diff = error_dense - error_lstm\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm'\r\n",
    "print(title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perform predictions on test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "settings = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "sim_lstm_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=20)\r\n",
    "sim_dense_test = util.convert_simulation_temporal_to_single(sim_lstm_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# predict\r\n",
    "models = [net_dense, net_lstm_v2, net_lstm_v3]\r\n",
    "model_names = [model.model.name for model in models]\r\n",
    "predictions = [model.predict(sim_lstm_test) for model in models]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calc Mean Localization Error"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from esinet.evaluate import eval_mean_localization_error, eval_nmse, eval_auc, eval_mse\r\n",
    "from scipy.spatial.distance import cdist\r\n",
    "size = 30\r\n",
    "pos = util.unpack_fwd(fwd)[2]\r\n",
    "distance_matrix = cdist(pos, pos)\r\n",
    "\r\n",
    "mean_localization_errors = []\r\n",
    "aucs = []\r\n",
    "nmses = []\r\n",
    "mses = []\r\n",
    "true_sources = np.stack([src.data for src in sim_lstm_test.source_data], axis=0)\r\n",
    "true_sources = util.collapse(true_sources)\r\n",
    "choice = np.random.choice(np.arange(true_sources.shape[0]), size=size, replace=False)\r\n",
    "true_sources = true_sources[choice]\r\n",
    "for prediction in predictions:\r\n",
    "    predicted_sources = util.collapse(np.stack([src.data for src in prediction], axis=0))\r\n",
    "    \r\n",
    "    predicted_sources = predicted_sources[choice]\r\n",
    "    \r\n",
    "    print('mle calculation....')\r\n",
    "    mean_localization_error = [eval_mean_localization_error(true_source, predicted_source, pos, distance_matrix=distance_matrix) for true_source, predicted_source in zip(true_sources, predicted_sources)]\r\n",
    "    auc = [eval_auc(true_source, predicted_source, pos) for true_source, predicted_source in zip(true_sources, predicted_sources)]\r\n",
    "    nmse = [eval_nmse(true_source, predicted_source) for true_source, predicted_source in zip(true_sources, predicted_sources)]\r\n",
    "    mse = [eval_mse(true_source, predicted_source) for true_source, predicted_source in zip(true_sources, predicted_sources)]\r\n",
    "    \r\n",
    "    mean_localization_errors.append(mean_localization_error)\r\n",
    "    aucs.append(auc)\r\n",
    "    nmses.append(nmse)\r\n",
    "    mses.append(mse)\r\n",
    "\r\n",
    "aucs_far = [auc[1] for auc in aucs]\r\n",
    "aucs_close = [auc[0] for auc in aucs]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "%matplotlib qt\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "sns.boxplot(data=nmses)\r\n",
    "plt.title('Normalized Mean Squared Errors')\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "sns.boxplot(data=mses)\r\n",
    "plt.title('Mean Squared Errors')\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "sns.boxplot(data=aucs_far)\r\n",
    "plt.title('Far area under the curve')\r\n",
    "\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "sns.boxplot(data=aucs_close)\r\n",
    "plt.title('Close area under the curve')\r\n",
    "\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "sns.boxplot(data=mean_localization_errors)\r\n",
    "plt.title('Mean Localization Errors')\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\r\n",
    "ax.scatter(nmses[0], nmses[2], s=0.5)\r\n",
    "ax.plot([0, 1], [0, 1], linewidth=2, color='black')\r\n",
    "ax.set_xlim([-np.percentile(nmses[0], 5), np.percentile(nmses[0], 99)])\r\n",
    "ax.set_ylim([-np.percentile(nmses[0], 5), np.percentile(nmses[0], 99)])\r\n",
    "ax.set_xlabel('Dense')\r\n",
    "ax.set_ylabel('LSTM v3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import ttest_rel, wilcoxon\r\n",
    "print('AUC_far:', ttest_rel(aucs_far[0], aucs_far[1]))\r\n",
    "print('AUC_close:', ttest_rel(aucs_close[0], aucs_close[1]))\r\n",
    "print('MLE:', wilcoxon(mean_localization_errors[0], mean_localization_errors[1]))\r\n",
    "print('nMSE:', ttest_rel(nmses[0], nmses[1]))\r\n",
    "print('MSE:', ttest_rel(mses[0], mses[1]))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)"
  },
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
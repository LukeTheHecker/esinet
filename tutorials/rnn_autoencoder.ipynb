{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import mne\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.layers import (LSTM, SimpleRNN, GRU, Dense, Flatten, Bidirectional, \r\n",
    "    TimeDistributed, InputLayer, Activation, Reshape, concatenate, Concatenate, \r\n",
    "    Dropout, InputLayer)\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "from keras.layers.core import Lambda\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from copy import deepcopy\r\n",
    "import sys; sys.path.insert(0, '../')\r\n",
    "from esinet import util\r\n",
    "from esinet import Simulation\r\n",
    "from esinet import Net\r\n",
    "from esinet.forward import create_forward_model, get_info\r\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)\r\n",
    "\r\n",
    "def normx(X):\r\n",
    "    X_ = deepcopy(X)\r\n",
    "    for s in range(X_.shape[0]):\r\n",
    "        for t in range(X_.shape[2]):\r\n",
    "            X_[s, :, t] /= np.max(np.abs(X_[s, :, t]))\r\n",
    "    return X_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load fwd"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info = get_info()\r\n",
    "info['sfreq'] = 100\r\n",
    "fwd = create_forward_model(info=info)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "sim_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=5000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f42982ee25bc4055904efc4cb34b77f0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Source Data to mne.SourceEstimate object\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62ed363cd41a495fb83a36b0b101326e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Project sources to EEG...\n",
      "\n",
      "Create EEG trials with noise...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "249b18411cf84c3da8568df46017df75"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Convert EEG matrices to a single instance of mne.Epochs...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "n_samples = 10000\r\n",
    "settings = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "sim = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=n_samples)\r\n",
    "\r\n",
    "sim_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=1000)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad19a6e804654ec6b096bf0662af3641"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Source Data to mne.SourceEstimate object\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56a5474790e342db916bca5489c427ba"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Project sources to EEG...\n",
      "\n",
      "Create EEG trials with noise...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a98b9bb33c241fc9b0a6704334eaad5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Convert EEG matrices to a single instance of mne.Epochs...\n",
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bbdbd4905364c8bb0586f2741b5463c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Source Data to mne.SourceEstimate object\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cf711d528df241e59fc2c1110ea18e3c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Project sources to EEG...\n",
      "\n",
      "Create EEG trials with noise...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "460517f526fe4c08b35412ae42763396"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Convert EEG matrices to a single instance of mne.Epochs...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shape it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "def get_xy(sim):\r\n",
    "    # X (noisy EEG)\r\n",
    "    X = sim.eeg_data.get_data()\r\n",
    "    X = normx(X)\r\n",
    "    X = np.swapaxes(X, 1,2)\r\n",
    "    X_flat = X.reshape(int(X.shape[0]*X.shape[1]), X.shape[2])\r\n",
    "\r\n",
    "\r\n",
    "    # Y (clean EEG)\r\n",
    "    leadfield = util.unpack_fwd(fwd)[1]\r\n",
    "\r\n",
    "    Y = np.stack([np.matmul(leadfield, src.data) for src in  sim.source_data], axis=0)\r\n",
    "    Y = normx(Y)\r\n",
    "    Y = np.swapaxes(Y, 1, 2)\r\n",
    "    Y_flat = Y.reshape(int(Y.shape[0]*Y.shape[1]), Y.shape[2])\r\n",
    "    \r\n",
    "    return X, Y, X_flat, Y_flat\r\n",
    "\r\n",
    "X, Y, X_flat, Y_flat = get_xy(sim)\r\n",
    "X_test, Y_test, X_flat_test, Y_flat_test = get_xy(sim_test)\r\n",
    "\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.subplot(211)\r\n",
    "mne.viz.plot_topomap(X[2, 0, :], info)\r\n",
    "plt.title('X (input)')\r\n",
    "plt.subplot(212)\r\n",
    "mne.viz.plot_topomap(Y[2, 0, :], info)\r\n",
    "plt.title('Y (target)')\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Y (target)')"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non Temporal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = keras.Sequential()\r\n",
    "drop = 0.2\r\n",
    "n_samples, n_time, n_channels = X.shape\r\n",
    "model.add(Dense(100, name='Dense_1'))\r\n",
    "model.add(Dropout(drop, name='Drop_1'))\r\n",
    "\r\n",
    "model.add(Dense(n_channels, name='Out'))\r\n",
    "\r\n",
    "model.build(input_shape=(1,n_channels))\r\n",
    "model.summary()\r\n",
    "\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X_flat, Y_flat, epochs=25, validation_split=0.2, shuffle=True)\r\n",
    "\r\n",
    "model.evaluate(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Medium Model\r\n",
    "https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start with the single model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "drop = 0.2\r\n",
    "n_samples, n_time, n_channels = X.shape\r\n",
    "input_shape=(n_channels)\r\n",
    "\r\n",
    "# Fully connected model\r\n",
    "model_fc = keras.Sequential()\r\n",
    "model_fc.add(InputLayer(input_shape=input_shape))\r\n",
    "\r\n",
    "model_fc.add(Dense(100, name='Dense_1'))\r\n",
    "model_fc.add(Dropout(drop, name='Drop_1'))\r\n",
    "model_fc.add(Dense(n_channels, name='Out'))\r\n",
    "\r\n",
    "model_fc.build(input_shape=input_shape)\r\n",
    "model_fc.compile(optimizer='adam', loss='mse')\r\n",
    "model_fc.summary()\r\n",
    "model_fc.fit(X_flat, Y_flat, epochs=100, validation_split=0.2,\r\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\r\n",
    "    mode='min', verbose=0, patience=10, restore_best_weights=True)])\r\n",
    "\r\n",
    "# Evaluate\r\n",
    "test_loss_1 = model_fc.evaluate(X_test, Y_test)\r\n",
    "\r\n",
    "print(f'\\nTest Loss of primary net: {test_loss_1:.3f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_1 (Dense)              (None, 100)               6200      \n",
      "_________________________________________________________________\n",
      "Drop_1 (Dropout)             (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "Out (Dense)                  (None, 61)                6161      \n",
      "=================================================================\n",
      "Total params: 12,361\n",
      "Trainable params: 12,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 4s 852us/step - loss: 0.0301 - val_loss: 0.0249\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 4s 795us/step - loss: 0.0266 - val_loss: 0.0251\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 4s 778us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 4s 747us/step - loss: 0.0265 - val_loss: 0.0247\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 4s 762us/step - loss: 0.0265 - val_loss: 0.0248\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 4s 773us/step - loss: 0.0265 - val_loss: 0.0248\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 4s 752us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 4s 762us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 4s 755us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 4s 762us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 4s 787us/step - loss: 0.0265 - val_loss: 0.0248\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 4s 754us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 4s 746us/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 4s 773us/step - loss: 0.0265 - val_loss: 0.0250\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, 61), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 20, 61).\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0245\n",
      "\n",
      "Test Loss of primary net: 0.024\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine with temporal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "from tensorflow.keras import initializers\r\n",
    "n_lstm_units = 100\r\n",
    "\r\n",
    "# Freeze the single frame model\r\n",
    "for i, layer in enumerate(model_fc.layers):\r\n",
    "    model_fc.layers[i].trainable = False\r\n",
    "\r\n",
    "# Temporal learning (hopefully)\r\n",
    "model = keras.Sequential()\r\n",
    "# model.add(TimeDistributed(model_fc, input_shape=(n_time, n_channels), name='FC_temporal'))\r\n",
    "\r\n",
    "model.add(InputLayer(input_shape=(n_time, n_channels)))\r\n",
    "model.add(Bidirectional(LSTM(n_lstm_units, name='GRU', input_shape=(n_time, n_channels), \r\n",
    "    return_sequences=True, dropout=drop)))\r\n",
    "\r\n",
    "# model.add(Flatten())\r\n",
    "# Summarize\r\n",
    "model.add(TimeDistributed(Dense(n_channels)))\r\n",
    "# model.add(Reshape((n_time, n_channels)))\r\n",
    "model.build(input_shape=input_shape)\r\n",
    "\r\n",
    "model.summary()\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X, Y, epochs=100, validation_split=0.2,\r\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\r\n",
    "    mode='min', verbose=0, patience=10, restore_best_weights=True)])\r\n",
    "\r\n",
    "test_loss_2 = model.evaluate(X_test, Y_test)\r\n",
    "print(f'\\nTest Loss of total net: {test_loss_2:.3f} ({100*(1-(test_loss_2/test_loss_1)):.2f} % change)')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 20, 200)           129600    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 61)            12261     \n",
      "=================================================================\n",
      "Total params: 141,861\n",
      "Trainable params: 141,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 5s 14ms/step - loss: 0.0418 - val_loss: 0.0257\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0270 - val_loss: 0.0247\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0263 - val_loss: 0.0243\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0260 - val_loss: 0.0243\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0258 - val_loss: 0.0240\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0256 - val_loss: 0.0239\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0254 - val_loss: 0.0237\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0253 - val_loss: 0.0236\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0251 - val_loss: 0.0235\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0250 - val_loss: 0.0234\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0249 - val_loss: 0.0234\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0247 - val_loss: 0.0234\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0245 - val_loss: 0.0231\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0244 - val_loss: 0.0230\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0242 - val_loss: 0.0228\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0240 - val_loss: 0.0226\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0237 - val_loss: 0.0224\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0235 - val_loss: 0.0222\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0233 - val_loss: 0.0220\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0232 - val_loss: 0.0220\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0228 - val_loss: 0.0218\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0226 - val_loss: 0.0216\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0225 - val_loss: 0.0216\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0223 - val_loss: 0.0216\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0222 - val_loss: 0.0215\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0220 - val_loss: 0.0214\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0218 - val_loss: 0.0214\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0218 - val_loss: 0.0214\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0217 - val_loss: 0.0213\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0215 - val_loss: 0.0213\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0208 - val_loss: 0.0213\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0207 - val_loss: 0.0213\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 3s 13ms/step - loss: 0.0205 - val_loss: 0.0213\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0204 - val_loss: 0.0213\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0204 - val_loss: 0.0212\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0203 - val_loss: 0.0212\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0202 - val_loss: 0.0213\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0202 - val_loss: 0.0213\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0201 - val_loss: 0.0213\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0201 - val_loss: 0.0213\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0200 - val_loss: 0.0215\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0199 - val_loss: 0.0213\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0199 - val_loss: 0.0213\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0199 - val_loss: 0.0213\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 3s 11ms/step - loss: 0.0198 - val_loss: 0.0213\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 3s 12ms/step - loss: 0.0198 - val_loss: 0.0215\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20, 61), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 100, 61).\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 0.0146\n",
      "\n",
      "Test Loss of total net: 0.015 (40.50 % change)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# Evaluate\r\n",
    "test_loss_1 = model_fc.evaluate(X_test, Y_test)\r\n",
    "print(f'\\nTest Loss of primary net: {test_loss_1:.3f}')\r\n",
    "\r\n",
    "test_loss_2 = model.evaluate(X_test, Y_test)\r\n",
    "print(f'\\nTest Loss of total net: {test_loss_2:.3f} ({100*(1-(test_loss_2/test_loss_1)):.2f} % change)')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0235\n",
      "\n",
      "Test Loss of primary net: 0.024\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "\n",
      "Test Loss of total net: 0.020 (14.42 % change)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concat-Temporal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_samples, n_time, n_channels = X.shape\r\n",
    "\r\n",
    "drop=0.2\r\n",
    "\r\n",
    "model = keras.Sequential()\r\n",
    "input_shape = (n_time, X.shape[-1])\r\n",
    "model.add(InputLayer(input_shape=input_shape))\r\n",
    "model.add(Flatten())\r\n",
    "\r\n",
    "# model.add(Dense(50))\r\n",
    "model.add(Dense(100, name='Dense_1'))\r\n",
    "model.add(Dropout(drop, name='Drop_1'))\r\n",
    "\r\n",
    "model.add(Dense(int(n_time*n_channels)))\r\n",
    "model.add(Reshape((n_time, n_channels)))\r\n",
    "model.build(input_shape=input_shape)\r\n",
    "\r\n",
    "model.summary()\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X, Y, epochs=10, validation_split=0.1, batch_size=8)\r\n",
    "\r\n",
    "model.evaluate(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN Temporal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_lstm_units = 100\r\n",
    "n_samples, n_time, n_channels = X.shape\r\n",
    "\r\n",
    "drop=0.2\r\n",
    "\r\n",
    "model = keras.Sequential()\r\n",
    "input_shape = (n_time, X.shape[-1])\r\n",
    "\r\n",
    "# model.add(Bidirectional(GRU(n_lstm_units, return_sequences=True, input_shape=input_shape,\r\n",
    "#     dropout=drop), name='Bidir_1'))\r\n",
    "\r\n",
    "model.add(LSTM(n_lstm_units, return_sequences=False, input_shape=input_shape,\r\n",
    "    dropout=drop, name='GRU_2'))\r\n",
    "\r\n",
    "\r\n",
    "# model.add(TimeDistributed(Dense(20)))\r\n",
    "model.add(Dense(100, name='Dense_1'))\r\n",
    "model.add(Dropout(drop, name='Drop_1'))\r\n",
    "\r\n",
    "# model.add(Dense(100, name='Dense_2'))\r\n",
    "# model.add(Dropout(drop, name='Drop_2'))\r\n",
    "\r\n",
    "\r\n",
    "model.add(Dense(int(n_time*n_channels)))\r\n",
    "model.add(Reshape((n_time, n_channels)))\r\n",
    "\r\n",
    "\r\n",
    "model.build(input_shape=input_shape)\r\n",
    "model.summary()\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X, Y, epochs=10, validation_split=0.1)\r\n",
    "\r\n",
    "model.evaluate(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "%matplotlib qt\r\n",
    "n_samples = 1\r\n",
    "settings_test = dict(duration_of_trial=1, target_snr=5)\r\n",
    "leadfield = util.unpack_fwd(fwd)[1]\r\n",
    "sim_test = Simulation(fwd, info, verbose=True, settings=settings_test).simulate(n_samples=n_samples)\r\n",
    "X_test = sim_test.eeg_data.get_data()\r\n",
    "X_test = normx(X_test)\r\n",
    "\r\n",
    "X_test = np.swapaxes(X_test, 1,2)\r\n",
    "X_test_hat = model.predict(X_test)\r\n",
    "X_test_hat_fc = model_fc.predict(X_test)\r\n",
    "\r\n",
    "Y_test = np.stack([np.matmul(leadfield, src.data) for src in sim_test.source_data], axis=0)\r\n",
    "Y_test = normx(Y_test)\r\n",
    "Y_test = np.swapaxes(Y_test, 1, 2)\r\n",
    "\r\n",
    "tp = 0\r\n",
    "plt.figure()\r\n",
    "plt.subplot(411)\r\n",
    "mne.viz.plot_topomap(X_test[0, tp, :], info)\r\n",
    "plt.title('true noisy')\r\n",
    "\r\n",
    "plt.subplot(412)\r\n",
    "mne.viz.plot_topomap(Y_test[0, tp, :], info)\r\n",
    "plt.title('True clean')\r\n",
    "\r\n",
    "plt.subplot(413)\r\n",
    "error = np.mean((X_test_hat[0, :, :]-X_test[0, tp, :])**2)*10\r\n",
    "mne.viz.plot_topomap(X_test_hat[0, tp, :], info)\r\n",
    "plt.title(f'Prediction (clean) {error:.2f}')\r\n",
    "\r\n",
    "\r\n",
    "plt.subplot(414)\r\n",
    "error = np.mean((X_test_hat_fc[0, :, :]-X_test[0, tp, :])**2)*10\r\n",
    "mne.viz.plot_topomap(X_test_hat_fc[0, tp, :], info)\r\n",
    "plt.title(f'Prediction FC (clean) {error:.2f}')\r\n",
    "plt.tight_layout()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51bcbb070db04d1faa0e20cededbc2b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Source Data to mne.SourceEstimate object\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86268f9a33a042dfbcf4055f608cb727"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Project sources to EEG...\n",
      "\n",
      "Create EEG trials with noise...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c86507d4d9d4ef182f54ee3328a99de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Convert EEG matrices to a single instance of mne.Epochs...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)"
  },
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import mne\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.layers import (LSTM, SimpleRNN, GRU, Dense, Flatten, Bidirectional, \r\n",
    "    TimeDistributed, InputLayer, Activation, Reshape, concatenate, Concatenate, \r\n",
    "    Dropout, InputLayer)\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "from keras.layers.core import Lambda\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from copy import deepcopy\r\n",
    "import sys; sys.path.insert(0, '../')\r\n",
    "from esinet import util\r\n",
    "from esinet import Simulation\r\n",
    "from esinet import Net\r\n",
    "from esinet.forward import create_forward_model, get_info\r\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)\r\n",
    "\r\n",
    "def normx(X):\r\n",
    "    X_ = deepcopy(X)\r\n",
    "    for s in range(X_.shape[0]):\r\n",
    "        for t in range(X_.shape[2]):\r\n",
    "            X_[s, :, t] /= np.max(np.abs(X_[s, :, t]))\r\n",
    "    return X_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load fwd"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info = get_info()\r\n",
    "info['sfreq'] = 100\r\n",
    "fwd = create_forward_model(info=info)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sim_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=5000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_samples = 10000\r\n",
    "settings = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "sim = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=n_samples)\r\n",
    "\r\n",
    "sim_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=1000)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shape it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_xy(sim):\r\n",
    "    # X (noisy EEG)\r\n",
    "    X = sim.eeg_data.get_data()\r\n",
    "    X = normx(X)\r\n",
    "    X = np.swapaxes(X, 1,2)\r\n",
    "    X_flat = X.reshape(int(X.shape[0]*X.shape[1]), X.shape[2])\r\n",
    "\r\n",
    "\r\n",
    "    # Y (clean EEG)\r\n",
    "    leadfield = util.unpack_fwd(fwd)[1]\r\n",
    "\r\n",
    "    Y = np.stack([np.matmul(leadfield, src.data) for src in  sim.source_data], axis=0)\r\n",
    "    Y = normx(Y)\r\n",
    "    Y = np.swapaxes(Y, 1, 2)\r\n",
    "    Y_flat = Y.reshape(int(Y.shape[0]*Y.shape[1]), Y.shape[2])\r\n",
    "    \r\n",
    "    return X, Y, X_flat, Y_flat\r\n",
    "\r\n",
    "X, Y, X_flat, Y_flat = get_xy(sim)\r\n",
    "X_test, Y_test, X_flat_test, Y_flat_test = get_xy(sim_test)\r\n",
    "\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.subplot(211)\r\n",
    "mne.viz.plot_topomap(X[2, 0, :], info)\r\n",
    "plt.title('X (input)')\r\n",
    "plt.subplot(212)\r\n",
    "mne.viz.plot_topomap(Y[2, 0, :], info)\r\n",
    "plt.title('Y (target)')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Non Temporal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = keras.Sequential()\r\n",
    "drop = 0.2\r\n",
    "n_samples, n_time, n_channels = X.shape\r\n",
    "model.add(Dense(100, name='Dense_1'))\r\n",
    "model.add(Dropout(drop, name='Drop_1'))\r\n",
    "\r\n",
    "model.add(Dense(n_channels, name='Out'))\r\n",
    "\r\n",
    "model.build(input_shape=(1,n_channels))\r\n",
    "model.summary()\r\n",
    "\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X_flat, Y_flat, epochs=25, validation_split=0.2, shuffle=True)\r\n",
    "\r\n",
    "model.evaluate(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Medium Model\r\n",
    "https://medium.com/smileinnovation/training-neural-network-with-image-sequence-an-example-with-video-as-input-c3407f7a0b0f"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start with the single model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "drop = 0.2\r\n",
    "n_samples, n_time, n_channels = X.shape\r\n",
    "input_shape=(n_channels)\r\n",
    "\r\n",
    "# Fully connected model\r\n",
    "model_fc = keras.Sequential()\r\n",
    "model_fc.add(InputLayer(input_shape=input_shape))\r\n",
    "\r\n",
    "model_fc.add(Dense(100, name='Dense_1'))\r\n",
    "model_fc.add(Dropout(drop, name='Drop_1'))\r\n",
    "model_fc.add(Dense(n_channels, name='Out'))\r\n",
    "\r\n",
    "model_fc.build(input_shape=input_shape)\r\n",
    "model_fc.compile(optimizer='adam', loss='mse')\r\n",
    "model_fc.summary()\r\n",
    "model_fc.fit(X_flat, Y_flat, epochs=100, validation_split=0.2,\r\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\r\n",
    "    mode='min', verbose=0, patience=10, restore_best_weights=True)])\r\n",
    "\r\n",
    "# Evaluate\r\n",
    "test_loss_1 = model_fc.evaluate(X_test, Y_test)\r\n",
    "\r\n",
    "print(f'\\nTest Loss of primary net: {test_loss_1:.3f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine with temporal model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras import initializers\r\n",
    "n_lstm_units = 100\r\n",
    "\r\n",
    "# Freeze the single frame model\r\n",
    "for i, layer in enumerate(model_fc.layers):\r\n",
    "    model_fc.layers[i].trainable = False\r\n",
    "\r\n",
    "# Temporal learning (hopefully)\r\n",
    "model = keras.Sequential()\r\n",
    "# model.add(TimeDistributed(model_fc, input_shape=(n_time, n_channels), name='FC_temporal'))\r\n",
    "\r\n",
    "model.add(InputLayer(input_shape=(n_time, n_channels)))\r\n",
    "model.add(Bidirectional(LSTM(n_lstm_units, name='GRU', input_shape=(n_time, n_channels), \r\n",
    "    return_sequences=True, dropout=drop)))\r\n",
    "\r\n",
    "# model.add(Flatten())\r\n",
    "# Summarize\r\n",
    "model.add(TimeDistributed(Dense(n_channels)))\r\n",
    "# model.add(Reshape((n_time, n_channels)))\r\n",
    "model.build(input_shape=input_shape)\r\n",
    "\r\n",
    "model.summary()\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X, Y, epochs=100, validation_split=0.2,\r\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\r\n",
    "    mode='min', verbose=0, patience=10, restore_best_weights=True)])\r\n",
    "\r\n",
    "test_loss_2 = model.evaluate(X_test, Y_test)\r\n",
    "print(f'\\nTest Loss of total net: {test_loss_2:.3f} ({100*(1-(test_loss_2/test_loss_1)):.2f} % change)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate\r\n",
    "test_loss_1 = model_fc.evaluate(X_test, Y_test)\r\n",
    "print(f'\\nTest Loss of primary net: {test_loss_1:.3f}')\r\n",
    "\r\n",
    "test_loss_2 = model.evaluate(X_test, Y_test)\r\n",
    "print(f'\\nTest Loss of total net: {test_loss_2:.3f} ({100*(1-(test_loss_2/test_loss_1)):.2f} % change)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concat-Temporal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_samples, n_time, n_channels = X.shape\r\n",
    "\r\n",
    "drop=0.2\r\n",
    "\r\n",
    "model = keras.Sequential()\r\n",
    "input_shape = (n_time, X.shape[-1])\r\n",
    "model.add(InputLayer(input_shape=input_shape))\r\n",
    "model.add(Flatten())\r\n",
    "\r\n",
    "# model.add(Dense(50))\r\n",
    "model.add(Dense(100, name='Dense_1'))\r\n",
    "model.add(Dropout(drop, name='Drop_1'))\r\n",
    "\r\n",
    "model.add(Dense(int(n_time*n_channels)))\r\n",
    "model.add(Reshape((n_time, n_channels)))\r\n",
    "model.build(input_shape=input_shape)\r\n",
    "\r\n",
    "model.summary()\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X, Y, epochs=10, validation_split=0.1, batch_size=8)\r\n",
    "\r\n",
    "model.evaluate(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RNN Temporal Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_lstm_units = 100\r\n",
    "n_samples, n_time, n_channels = X.shape\r\n",
    "\r\n",
    "drop=0.2\r\n",
    "\r\n",
    "model = keras.Sequential()\r\n",
    "input_shape = (n_time, X.shape[-1])\r\n",
    "\r\n",
    "# model.add(Bidirectional(GRU(n_lstm_units, return_sequences=True, input_shape=input_shape,\r\n",
    "#     dropout=drop), name='Bidir_1'))\r\n",
    "\r\n",
    "model.add(LSTM(n_lstm_units, return_sequences=False, input_shape=input_shape,\r\n",
    "    dropout=drop, name='GRU_2'))\r\n",
    "\r\n",
    "\r\n",
    "# model.add(TimeDistributed(Dense(20)))\r\n",
    "model.add(Dense(100, name='Dense_1'))\r\n",
    "model.add(Dropout(drop, name='Drop_1'))\r\n",
    "\r\n",
    "# model.add(Dense(100, name='Dense_2'))\r\n",
    "# model.add(Dropout(drop, name='Drop_2'))\r\n",
    "\r\n",
    "\r\n",
    "model.add(Dense(int(n_time*n_channels)))\r\n",
    "model.add(Reshape((n_time, n_channels)))\r\n",
    "\r\n",
    "\r\n",
    "model.build(input_shape=input_shape)\r\n",
    "model.summary()\r\n",
    "model.compile(optimizer='adam', loss='mse')\r\n",
    "model.fit(X, Y, epochs=10, validation_split=0.1)\r\n",
    "\r\n",
    "model.evaluate(X_test, Y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt\r\n",
    "n_samples = 1\r\n",
    "settings_test = dict(duration_of_trial=1, target_snr=5)\r\n",
    "leadfield = util.unpack_fwd(fwd)[1]\r\n",
    "sim_test = Simulation(fwd, info, verbose=True, settings=settings_test).simulate(n_samples=n_samples)\r\n",
    "X_test = sim_test.eeg_data.get_data()\r\n",
    "X_test = normx(X_test)\r\n",
    "\r\n",
    "X_test = np.swapaxes(X_test, 1,2)\r\n",
    "X_test_hat = model.predict(X_test)\r\n",
    "X_test_hat_fc = model_fc.predict(X_test)\r\n",
    "\r\n",
    "Y_test = np.stack([np.matmul(leadfield, src.data) for src in sim_test.source_data], axis=0)\r\n",
    "Y_test = normx(Y_test)\r\n",
    "Y_test = np.swapaxes(Y_test, 1, 2)\r\n",
    "\r\n",
    "tp = 0\r\n",
    "plt.figure()\r\n",
    "plt.subplot(411)\r\n",
    "mne.viz.plot_topomap(X_test[0, tp, :], info)\r\n",
    "plt.title('true noisy')\r\n",
    "\r\n",
    "plt.subplot(412)\r\n",
    "mne.viz.plot_topomap(Y_test[0, tp, :], info)\r\n",
    "plt.title('True clean')\r\n",
    "\r\n",
    "plt.subplot(413)\r\n",
    "error = np.mean((X_test_hat[0, :, :]-X_test[0, tp, :])**2)*10\r\n",
    "mne.viz.plot_topomap(X_test_hat[0, tp, :], info)\r\n",
    "plt.title(f'Prediction (clean) {error:.2f}')\r\n",
    "\r\n",
    "\r\n",
    "plt.subplot(414)\r\n",
    "error = np.mean((X_test_hat_fc[0, :, :]-X_test[0, tp, :])**2)*10\r\n",
    "mne.viz.plot_topomap(X_test_hat_fc[0, tp, :], info)\r\n",
    "plt.title(f'Prediction FC (clean) {error:.2f}')\r\n",
    "plt.tight_layout()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)"
  },
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
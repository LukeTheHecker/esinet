{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 4: The temporal model\r\n",
    "In tutorials 1-3 we have used simple fully-connected neural networks to predict sources from single time instances of EEG data. To harness the full information within the EEG, however, we can also incorporate multiple time instances at once. \r\n",
    "\r\n",
    "For time-series data we can use recurrent neural networks (RNNs). A prominent RNN is the long-short-term memory (LSTM) network, which makes use of temporal information in a quite useful manner."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import mne\r\n",
    "import numpy as np\r\n",
    "from copy import deepcopy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys; sys.path.insert(0, '../')\r\n",
    "from esinet import util\r\n",
    "from esinet import Simulation\r\n",
    "from esinet import Net\r\n",
    "from esinet.forward import create_forward_model, get_info\r\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forward model\r\n",
    "To get started we just create some generic forward model using the esinet.forward module."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info = get_info()\r\n",
    "info['sfreq'] = 100\r\n",
    "fwd = create_forward_model(info=info)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation\r\n",
    "Next, we simulate our training data. In order to invoke the LSTM architecture we need to simulate data that have a temporal dimension. This is controlled via the *duration_of_trial* setting as shown below. We set the duration to 0.2 seconds, which together with our sampling rate of 100 Hz yields 20 time points:\r\n",
    "```\r\n",
    "100 Hz * 0.2 s = 20\r\n",
    "```\r\n",
    "\r\n",
    "Note, that for publication-ready inverse solutions you should increase the number of training samples to 100,000."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_samples = 10000\r\n",
    "settings = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "sim_lstm = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=n_samples)\r\n",
    "sim_dense = util.convert_simulation_temporal_to_single(sim_lstm)\r\n",
    "\r\n",
    "sim_lstm_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=2000)\r\n",
    "sim_dense_test = util.convert_simulation_temporal_to_single(sim_lstm_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build & train LSTM network\r\n",
    "The neural network class *Net()* is intelligent and recognizes the temporal structure in the simulations.\r\n",
    "It will automatically build the LSTM network architecture without further specification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "train_params = dict(epochs=200, patience=20, tensorboard=True, dropout=0, loss='mse', optimizer='adam')\r\n",
    "model_params = dict(n_lstm_layers=1, n_lstm_units=100, activation_function='relu')\r\n",
    "# Train \r\n",
    "# net_dense = Net(fwd, **model_params)\r\n",
    "# net_dense.fit(sim_dense, **train_params)\r\n",
    "\r\n",
    "# Train LSTM for single time points\r\n",
    "net_lstm = Net(fwd, **model_params)\r\n",
    "net_lstm.fit(sim_lstm, **train_params)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"LSTM_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FC1 (TimeDistributed)           (None, None, 100)    6200        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (Bidirectional)           (None, None, 200)    129600      Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Dropout1 (Dropout)              (None, None, 100)    0           FC1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Concat (Concatenate)            (None, None, 300)    0           LSTM1[0][0]                      \n",
      "                                                                 Dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "LSTM2 (Bidirectional)           (None, None, 200)    320800      Concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FC_Out (TimeDistributed)        (None, None, 1284)   258084      LSTM2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 714,684\n",
      "Trainable params: 714,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[<function weighted_huber_loss.<locals>.loss at 0x0000029D6EE7D550>]\n",
      "Epoch 1/200\n",
      "71/71 [==============================] - 18s 193ms/step - loss: 0.0781 - val_loss: 0.0681\n",
      "Epoch 2/200\n",
      "71/71 [==============================] - 12s 170ms/step - loss: 0.0775 - val_loss: 0.0653\n",
      "Epoch 3/200\n",
      "71/71 [==============================] - 12s 175ms/step - loss: 0.0658 - val_loss: 0.0662\n",
      "Epoch 4/200\n",
      "71/71 [==============================] - 12s 171ms/step - loss: 0.0632 - val_loss: 0.0622\n",
      "Epoch 5/200\n",
      "71/71 [==============================] - 12s 166ms/step - loss: 0.0605 - val_loss: 0.0584\n",
      "Epoch 6/200\n",
      "71/71 [==============================] - 12s 170ms/step - loss: 0.0567 - val_loss: 0.0547\n",
      "Epoch 7/200\n",
      "71/71 [==============================] - 13s 184ms/step - loss: 0.0535 - val_loss: 0.0523\n",
      "Epoch 8/200\n",
      "71/71 [==============================] - 13s 183ms/step - loss: 0.0507 - val_loss: 0.0502\n",
      "Epoch 9/200\n",
      "71/71 [==============================] - 12s 176ms/step - loss: 0.0487 - val_loss: 0.0482\n",
      "Epoch 10/200\n",
      "71/71 [==============================] - 13s 179ms/step - loss: 0.0471 - val_loss: 0.0467\n",
      "Epoch 11/200\n",
      "71/71 [==============================] - 13s 179ms/step - loss: 0.0449 - val_loss: 0.0438\n",
      "Epoch 12/200\n",
      "71/71 [==============================] - 13s 178ms/step - loss: 0.0424 - val_loss: 0.0426\n",
      "Epoch 13/200\n",
      "71/71 [==============================] - 13s 179ms/step - loss: 0.0410 - val_loss: 0.0401\n",
      "Epoch 14/200\n",
      "71/71 [==============================] - 13s 179ms/step - loss: 0.0393 - val_loss: 0.0392\n",
      "Epoch 15/200\n",
      "71/71 [==============================] - 13s 180ms/step - loss: 0.0378 - val_loss: 0.0378\n",
      "Epoch 16/200\n",
      "53/71 [=====================>........] - ETA: 3s - loss: 0.0366"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2664/2319657215.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Train LSTM for single time points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnet_lstm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnet_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\lukas\\Dokumente\\projects\\esinet\\tutorials\\..\\esinet\\net.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, optimizer, learning_rate, validation_split, epochs, metrics, device, false_positive_penalty, delta, batch_size, loss, sample_weight, return_history, dropout, patience, tensorboard, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             history = self.model.fit(x_scaled, y_scaled, \n\u001b[0m\u001b[0;32m    253\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100, 1284, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from esinet.losses import weighted_mse_loss\r\n",
    "import tensorflow as tf\r\n",
    "fun = weighted_mse_loss(weight=2.0)\r\n",
    "fun(ground_truths, predictions)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.00017742967>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "p=net_lstm.predict(sim_eval)\r\n",
    "predictions = np.stack([s.data for s in p], axis=0)\r\n",
    "ground_truths = np.stack([s.data for s in sim_eval.source_data], axis=0)\r\n",
    "\r\n",
    "predicitons = np.swapaxes(predictions, 1,2)\r\n",
    "predictions = predictions.reshape(2000, 1284)\r\n",
    "\r\n",
    "ground_truths = np.swapaxes(ground_truths, 1,2)\r\n",
    "ground_truths = ground_truths.reshape(2000, 1284)\r\n",
    "\r\n",
    "predictions = tf.cast(predictions, dtype=tf.float32)\r\n",
    "ground_truths = tf.cast(ground_truths, dtype=tf.float32)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2000, 1284), dtype=float32, numpy=\n",
       "array([[ 9.2233549e-10, -2.1166515e-09,  2.9879305e-10, ...,\n",
       "        -3.4170871e-11, -4.9712912e-10, -1.2248715e-09],\n",
       "       [-8.8395430e-10, -8.8119956e-11,  3.8926989e-10, ...,\n",
       "        -1.2773120e-09, -2.9352482e-10, -3.1089797e-10],\n",
       "       [ 1.6790618e-10,  4.0304060e-10,  6.0788219e-10, ...,\n",
       "         1.3933509e-10,  2.5180380e-10,  2.5817642e-10],\n",
       "       ...,\n",
       "       [ 1.7008616e-09,  1.6684041e-09,  1.4448674e-10, ...,\n",
       "        -3.5912759e-10, -2.4945682e-10, -4.1895312e-10],\n",
       "       [-2.8113362e-10, -4.4815146e-10, -4.4510864e-10, ...,\n",
       "        -6.0656014e-10, -9.1317853e-10, -5.7077520e-10],\n",
       "       [-5.6258942e-10, -6.3030475e-10, -7.5334294e-10, ...,\n",
       "         3.3599089e-11, -1.2047902e-10,  1.6030796e-09]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kwargs = dict(epochs=15, patience=10, return_history=True, tensorboard=True, learning_rate=0.001)\r\n",
    "# Train \r\n",
    "net_dense, hist_dense = Net(fwd, model_type='auto').fit(sim_dense, **kwargs)\r\n",
    "net_lstm, hist_lstm = Net(fwd, model_type='temporal').fit(sim_lstm, **kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Numeric Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "settings_eval = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "n_samples = 100\r\n",
    "sim_eval = Simulation(fwd, info, verbose=True, settings=settings_eval).simulate(n_samples=n_samples)\r\n",
    "\r\n",
    "# Evaluate the new simulations\r\n",
    "mse_dense = net_dense.evaluate_nmse(sim_eval)\r\n",
    "mse_lstm = net_lstm.evaluate_nmse(sim_eval)\r\n",
    "perc_median_diff = 100*(1-(np.median(mse_lstm) / np.median(mse_dense)))\r\n",
    "# Plot\r\n",
    "%matplotlib qt\r\n",
    "diff = mse_dense.flatten() - mse_lstm.flatten()\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm. \\n ({perc_median_diff:.1f}% better)'\r\n",
    "decim = 1\r\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\r\n",
    "ax.scatter(mse_dense[::decim], mse_lstm[::decim], s=0.5)\r\n",
    "ax.set_xlim([-np.percentile(mse_dense, 5), np.percentile(mse_dense, 99)])\r\n",
    "ax.set_ylim([-np.percentile(mse_dense, 5), np.percentile(mse_dense, 99)])\r\n",
    "ax.plot([0, 1], [0, 1], linewidth=2, color='black')\r\n",
    "ax.set_xlabel('Dense Errors')\r\n",
    "ax.set_ylabel('LSTM Errors')\r\n",
    "# ax.axis('equal')\r\n",
    "ax.set_title(title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate performance\r\n",
    "We can now evaluate the performance of our LSTM network using a newly simulated, thus unseen simulated sample."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt\r\n",
    "settings_eval = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "# Simulate new data\r\n",
    "sim_test = Simulation(fwd, info, settings=settings_eval).simulate(1)\r\n",
    "idx = 0\r\n",
    "# Predict sources\r\n",
    "prediction_dense = net_dense.predict(sim_test)\r\n",
    "prediction_lstm = net_lstm.predict(sim_test)\r\n",
    "\r\n",
    "\r\n",
    "# Plot True Source\r\n",
    "brain = sim_test.source_data[idx].plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title')\r\n",
    "\r\n",
    "# Plot True EEG\r\n",
    "evoked = sim_test.eeg_data[idx].average()\r\n",
    "evoked.plot()\r\n",
    "evoked.plot_topomap(title='Ground Truth')\r\n",
    "evoked = util.get_eeg_from_source(sim_test.source_data[idx], fwd, info, tmin=0.)\r\n",
    "evoked.plot_topomap(title='Ground Truth Noiseless')\r\n",
    "\r\n",
    "\r\n",
    "# Plot predicted source Dense\r\n",
    "brain = prediction_dense.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Dense', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_dense, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='Dense')\r\n",
    "\r\n",
    "# Plot predicted source LSTM\r\n",
    "brain = prediction_lstm.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_lstm, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='LSTM')\r\n",
    "\r\n",
    "error_dense = ((prediction_dense.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "error_lstm = ((prediction_lstm.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "dif = error_dense - error_lstm\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm'\r\n",
    "print(title)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)"
  },
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
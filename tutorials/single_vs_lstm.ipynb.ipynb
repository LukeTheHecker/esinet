{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 4: The temporal model\r\n",
    "In tutorials 1-3 we have used simple fully-connected neural networks to predict sources from single time instances of EEG data. To harness the full information within the EEG, however, we can also incorporate multiple time instances at once. \r\n",
    "\r\n",
    "For time-series data we can use recurrent neural networks (RNNs). A prominent RNN is the long-short-term memory (LSTM) network, which makes use of temporal information in a quite useful manner."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import mne\r\n",
    "import numpy as np\r\n",
    "from copy import deepcopy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys; sys.path.insert(0, '../')\r\n",
    "from esinet import util\r\n",
    "from esinet import Simulation\r\n",
    "from esinet import Net\r\n",
    "from esinet.forward import create_forward_model, get_info\r\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forward model\r\n",
    "To get started we just create some generic forward model using the esinet.forward module."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info = get_info()\r\n",
    "info['sfreq'] = 100\r\n",
    "fwd = create_forward_model(info=info)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation\r\n",
    "Next, we simulate our training data. In order to invoke the LSTM architecture we need to simulate data that have a temporal dimension. This is controlled via the *duration_of_trial* setting as shown below. We set the duration to 0.2 seconds, which together with our sampling rate of 100 Hz yields 20 time points:\r\n",
    "```\r\n",
    "100 Hz * 0.2 s = 20\r\n",
    "```\r\n",
    "\r\n",
    "Note, that for publication-ready inverse solutions you should increase the number of training samples to 100,000."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_samples = 10000\r\n",
    "settings = dict(duration_of_trial=0.5, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "sim_lstm = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=n_samples)\r\n",
    "sim_dense = util.convert_simulation_temporal_to_single(sim_lstm)\r\n",
    "\r\n",
    "sim_lstm_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=2000)\r\n",
    "sim_dense_test = util.convert_simulation_temporal_to_single(sim_lstm_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build & train LSTM network\r\n",
    "The neural network class *Net()* is intelligent and recognizes the temporal structure in the simulations.\r\n",
    "It will automatically build the LSTM network architecture without further specification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Train\r\n",
    "train_params = dict(epochs=200, patience=20, tensorboard=True, dropout=0.1, \r\n",
    "    loss='mse', optimizer='adam', return_history=True)\r\n",
    "model_params = dict(activation_function='relu', n_dense_layers=3, \r\n",
    "    n_dense_units=300)\r\n",
    "net_dense = Net(fwd, **model_params)\r\n",
    "_, history_dense = net_dense.fit(sim_dense, **train_params)\r\n",
    "\r\n",
    "\r\n",
    "# LSTM v2\r\n",
    "model_params = dict(activation_function='relu', n_lstm_layers=2, \r\n",
    "    n_lstm_units=75, model_type='v2')\r\n",
    "net_lstm = Net(fwd, **model_params)\r\n",
    "\r\n",
    "train_params = dict(epochs=200, patience=20, tensorboard=True, dropout=0.1, \r\n",
    "    loss='mse', optimizer=None, return_history=True, batch_size=8)\r\n",
    "_, history_lstm = net_lstm.fit(sim_lstm, **train_params)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Numeric Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "settings_eval = dict(duration_of_trial=0.5, target_snr=(0.5, 10))\r\n",
    "n_samples = 100\r\n",
    "sim_eval = Simulation(fwd, info, verbose=True, settings=settings_eval).simulate(n_samples=n_samples)\r\n",
    "sim_eval_dense = deepcopy(sim_eval).to_nontemporal()\r\n",
    "# Evaluate the new simulations\r\n",
    "mse_dense = net_dense.evaluate_nmse(sim_eval_dense)\r\n",
    "mse_lstm = net_lstm.evaluate_nmse(sim_eval)\r\n",
    "perc_median_diff = 100*(1-(np.median(mse_lstm) / np.median(mse_dense)))\r\n",
    "# Plot\r\n",
    "%matplotlib qt\r\n",
    "diff = mse_dense.flatten() - mse_lstm.flatten()\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm. \\n ({perc_median_diff:.1f}% better)'\r\n",
    "decim = 1\r\n",
    "import seaborn as sns; sns.set(style='whitegrid')\r\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\r\n",
    "ax.scatter(mse_dense[::decim], mse_lstm[::decim], s=0.5)\r\n",
    "ax.set_xlim([-np.percentile(mse_dense, 5), np.percentile(mse_dense, 99)])\r\n",
    "ax.set_ylim([-np.percentile(mse_dense, 5), np.percentile(mse_dense, 99)])\r\n",
    "ax.plot([0, 1], [0, 1], linewidth=2, color='black')\r\n",
    "ax.set_xlabel('Dense Errors')\r\n",
    "ax.set_ylabel('LSTM Errors')\r\n",
    "# ax.axis('equal')\r\n",
    "ax.set_title(title)\r\n",
    "# plt.savefig(r'C:\\Users\\lukas\\Desktop\\lstm.png', dpi=600)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Simulation' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6864/1679291687.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msettings_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration_of_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_snr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msim_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msim_eval_dense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_nontemporal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Evaluate the new simulations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Simulation' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visual Evaluation\r\n",
    "We can now evaluate the performance of our LSTM network using a newly simulated, thus unseen simulated sample."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt\r\n",
    "settings_eval = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "# Simulate new data\r\n",
    "sim_test = Simulation(fwd, info, settings=settings_eval).simulate(1)\r\n",
    "idx = 0\r\n",
    "# Predict sources\r\n",
    "prediction_dense = net_dense.predict(sim_test)\r\n",
    "prediction_lstm = net_lstm.predict(sim_test)\r\n",
    "\r\n",
    "\r\n",
    "# Plot True Source\r\n",
    "brain = sim_test.source_data[idx].plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title')\r\n",
    "\r\n",
    "# Plot True EEG\r\n",
    "evoked = sim_test.eeg_data[idx].average()\r\n",
    "evoked.plot()\r\n",
    "evoked.plot_topomap(title='Ground Truth')\r\n",
    "evoked = util.get_eeg_from_source(sim_test.source_data[idx], fwd, info, tmin=0.)\r\n",
    "evoked.plot_topomap(title='Ground Truth Noiseless')\r\n",
    "\r\n",
    "\r\n",
    "# Plot predicted source Dense\r\n",
    "brain = prediction_dense.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Dense', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_dense, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='Dense')\r\n",
    "\r\n",
    "# Plot predicted source LSTM\r\n",
    "brain = prediction_lstm.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_lstm, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='LSTM')\r\n",
    "\r\n",
    "error_dense = ((prediction_dense.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "error_lstm = ((prediction_lstm.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "\r\n",
    "diff = error_dense - error_lstm\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm'\r\n",
    "print(title)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Noise-loss Plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "durations_of_trials = [0, 0.2, 0.5, 1]\r\n",
    "target_snrs = [0.125, 0.25, 0.5, 1, 2, 4, 8, 16]\r\n",
    "\r\n",
    "result = [np.zeros((len(durations_of_trials), len(target_snrs))), \r\n",
    "    np.zeros((len(durations_of_trials), len(target_snrs)))]\r\n",
    "net_names = ['LSTM network', 'FC network']\r\n",
    "xlabel = 'SNR'\r\n",
    "ylabel = 'Mean Squared Error'\r\n",
    "n_samples_list = [1000, 50, 20, 10]\r\n",
    "for i, duration_of_trial in enumerate(durations_of_trials):\r\n",
    "    for j, target_snr in enumerate(target_snrs):\r\n",
    "        settings_eval = dict(duration_of_trial=duration_of_trial, target_snr=target_snr, )\r\n",
    "        print(settings_eval)\r\n",
    "        # Simulate new data\r\n",
    "        sim_test = Simulation(fwd, info, settings=settings_eval).simulate(n_samples_list[i])\r\n",
    "        # Predict\r\n",
    "        # Evaluate\r\n",
    "        error_lstm = np.median(net_lstm.evaluate_nmse(sim_test))\r\n",
    "        error_dense = np.median(net_dense.evaluate_nmse(sim_test))\r\n",
    "        \r\n",
    "        result[0][i,j] = error_lstm\r\n",
    "        result[1][i,j] = error_dense"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt\r\n",
    "t = target_snrs\r\n",
    "fig, ax = plt.subplots()\r\n",
    "for i, name in enumerate(net_names):\r\n",
    "    for j, duration_of_trial in enumerate(durations_of_trials):\r\n",
    "        ax.semilogx(t, result[i][j, :], label=f'{name} {duration_of_trial}')\r\n",
    "plt.legend()    \r\n",
    "plt.xticks(target_snrs, labels=target_snrs)\r\n",
    "plt.xlabel(xlabel)\r\n",
    "plt.ylabel(ylabel)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import wilcoxon, ttest_rel\r\n",
    "ttest_rel(result[1][0], result[1][-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)"
  },
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
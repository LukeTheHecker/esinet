{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 4: The temporal model\r\n",
    "In tutorials 1-3 we have used simple fully-connected neural networks to predict sources from single time instances of EEG data. To harness the full information within the EEG, however, we can also incorporate multiple time instances at once. \r\n",
    "\r\n",
    "For time-series data we can use recurrent neural networks (RNNs). A prominent RNN is the long-short-term memory (LSTM) network, which makes use of temporal information in a quite useful manner."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "import mne\r\n",
    "import numpy as np\r\n",
    "from copy import deepcopy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sys; sys.path.insert(0, '../')\r\n",
    "from esinet import util\r\n",
    "from esinet import Simulation\r\n",
    "from esinet import Net\r\n",
    "from esinet.forward import create_forward_model, get_info\r\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forward model\r\n",
    "To get started we just create some generic forward model using the esinet.forward module."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info = get_info()\r\n",
    "info['sfreq'] = 100\r\n",
    "fwd = create_forward_model(info=info)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation\r\n",
    "Next, we simulate our training data. In order to invoke the LSTM architecture we need to simulate data that have a temporal dimension. This is controlled via the *duration_of_trial* setting as shown below. We set the duration to 0.2 seconds, which together with our sampling rate of 100 Hz yields 20 time points:\r\n",
    "```\r\n",
    "100 Hz * 0.2 s = 20\r\n",
    "```\r\n",
    "\r\n",
    "Note, that for publication-ready inverse solutions you should increase the number of training samples to 100,000."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_samples = 10000\r\n",
    "settings = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "sim_lstm = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=n_samples)\r\n",
    "sim_dense = util.convert_simulation_temporal_to_single(sim_lstm)\r\n",
    "\r\n",
    "sim_lstm_test = Simulation(fwd, info, verbose=True, settings=settings).simulate(n_samples=2000)\r\n",
    "sim_dense_test = util.convert_simulation_temporal_to_single(sim_lstm_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build & train LSTM network\r\n",
    "The neural network class *Net()* is intelligent and recognizes the temporal structure in the simulations.\r\n",
    "It will automatically build the LSTM network architecture without further specification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_params = dict(epochs=200, patience=20, tensorboard=True, dropout=0, loss='mse', optimizer='adam')\r\n",
    "model_params = dict(n_lstm_layers=2, n_lstm_units=100, activation_function='relu')\r\n",
    "# Train \r\n",
    "# net_dense = Net(fwd, **model_params)\r\n",
    "# net_dense.fit(sim_dense, **train_params)\r\n",
    "\r\n",
    "# Train LSTM for single time points\r\n",
    "net_lstm = Net(fwd, **model_params)\r\n",
    "net_lstm.fit(sim_lstm, **train_params)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kwargs = dict(epochs=15, patience=10, return_history=True, tensorboard=True, learning_rate=0.001)\r\n",
    "# Train \r\n",
    "net_dense, hist_dense = Net(fwd, model_type='auto').fit(sim_dense, **kwargs)\r\n",
    "net_lstm, hist_lstm = Net(fwd, model_type='temporal').fit(sim_lstm, **kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Numeric Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "settings_eval = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "n_samples = 100\r\n",
    "sim_eval = Simulation(fwd, info, verbose=True, settings=settings_eval).simulate(n_samples=n_samples)\r\n",
    "\r\n",
    "# Evaluate the new simulations\r\n",
    "mse_dense = net_dense.evaluate_nmse(sim_eval)\r\n",
    "mse_lstm = net_lstm.evaluate_nmse(sim_eval)\r\n",
    "perc_median_diff = 100*(1-(np.median(mse_lstm) / np.median(mse_dense)))\r\n",
    "# Plot\r\n",
    "%matplotlib qt\r\n",
    "diff = mse_dense.flatten() - mse_lstm.flatten()\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm. \\n ({perc_median_diff:.1f}% better)'\r\n",
    "decim = 1\r\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\r\n",
    "ax.scatter(mse_dense[::decim], mse_lstm[::decim], s=0.5)\r\n",
    "ax.set_xlim([-np.percentile(mse_dense, 5), np.percentile(mse_dense, 99)])\r\n",
    "ax.set_ylim([-np.percentile(mse_dense, 5), np.percentile(mse_dense, 99)])\r\n",
    "ax.plot([0, 1], [0, 1], linewidth=2, color='black')\r\n",
    "ax.set_xlabel('Dense Errors')\r\n",
    "ax.set_ylabel('LSTM Errors')\r\n",
    "# ax.axis('equal')\r\n",
    "ax.set_title(title)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulate Source\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae2fcf8a36c54e568ade4be113e14012"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting Source Data to mne.SourceEstimate object\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2137f1648e1424ab666e8fa34f4cd37"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Project sources to EEG...\n",
      "\n",
      "Create EEG trials with noise...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bea432b25acd46589ba397995eebb385"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Convert EEG matrices to a single instance of mne.Epochs...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '93.6 % of samples were better with lstm. \\n (45.8% better)')"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate performance\r\n",
    "We can now evaluate the performance of our LSTM network using a newly simulated, thus unseen simulated sample."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib qt\r\n",
    "settings_eval = dict(duration_of_trial=0.2, target_snr=(0.5, 10))\r\n",
    "\r\n",
    "# Simulate new data\r\n",
    "sim_test = Simulation(fwd, info, settings=settings_eval).simulate(1)\r\n",
    "idx = 0\r\n",
    "# Predict sources\r\n",
    "prediction_dense = net_dense.predict(sim_test)\r\n",
    "prediction_lstm = net_lstm.predict(sim_test)\r\n",
    "\r\n",
    "\r\n",
    "# Plot True Source\r\n",
    "brain = sim_test.source_data[idx].plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth', 'title')\r\n",
    "\r\n",
    "# Plot True EEG\r\n",
    "evoked = sim_test.eeg_data[idx].average()\r\n",
    "evoked.plot()\r\n",
    "evoked.plot_topomap(title='Ground Truth')\r\n",
    "evoked = util.get_eeg_from_source(sim_test.source_data[idx], fwd, info, tmin=0.)\r\n",
    "evoked.plot_topomap(title='Ground Truth Noiseless')\r\n",
    "\r\n",
    "\r\n",
    "# Plot predicted source Dense\r\n",
    "brain = prediction_dense.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'Dense', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_dense, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='Dense')\r\n",
    "\r\n",
    "# Plot predicted source LSTM\r\n",
    "brain = prediction_lstm.plot(**plot_params)\r\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title')\r\n",
    "# Plot predicted EEG\r\n",
    "evoked_esi = util.get_eeg_from_source(prediction_lstm, fwd, info, tmin=0.)\r\n",
    "evoked_esi.plot()\r\n",
    "evoked_esi.plot_topomap(title='LSTM')\r\n",
    "\r\n",
    "error_dense = ((prediction_dense.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "error_lstm = ((prediction_lstm.data - sim_test.source_data[idx].data)**2).flatten()\r\n",
    "dif = error_dense - error_lstm\r\n",
    "relative_better_predictions = np.sum(diff>0)/ len(diff)\r\n",
    "title = f'{relative_better_predictions*100:.1f} % of samples were better with lstm'\r\n",
    "print(title)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('esienv': virtualenv)"
  },
  "interpreter": {
   "hash": "8292a7c1b71beb25883e5d3de4479593a27229e31834907607dc8a0d6e7b1899"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
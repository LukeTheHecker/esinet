{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "This the quick-start tutorial as shown in the README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    1.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 218.49it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 21333.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (324, 100) (324, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 106.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess data\n",
      "werks3\n",
      "Model: \"Contextualizer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, None, 61)]   0           []                               \n",
      "                                                                                                  \n",
      " FC1 (TimeDistributed)          (None, None, 200)    12400       ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 200)    0           ['FC1[0][0]']                    \n",
      "                                                                                                  \n",
      " LSTM1 (Bidirectional)          (None, None, 64)     44928       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " FC2 (TimeDistributed)          (None, None, 324)    65124       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Mask (TimeDistributed)         (None, None, 324)    21060       ['LSTM1[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 324)    0           ['FC2[0][0]',                    \n",
      "                                                                  'Mask[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,512\n",
      "Trainable params: 143,512\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "fit model\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 6s 20ms/step - loss: -0.1523 - mae: 0.1090 - val_loss: -0.2292 - val_mae: 0.1007\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 2s 15ms/step - loss: -0.2469 - mae: 0.0960 - val_loss: -0.2733 - val_mae: 0.0877\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.2836 - mae: 0.0870 - val_loss: -0.2918 - val_mae: 0.0827\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.3080 - mae: 0.0835 - val_loss: -0.3067 - val_mae: 0.0794\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.3302 - mae: 0.0819 - val_loss: -0.3191 - val_mae: 0.0830\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.3519 - mae: 0.0818 - val_loss: -0.3329 - val_mae: 0.0794\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.3706 - mae: 0.0794 - val_loss: -0.3430 - val_mae: 0.0767\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.3873 - mae: 0.0750 - val_loss: -0.3489 - val_mae: 0.0744\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.4042 - mae: 0.0680 - val_loss: -0.3584 - val_mae: 0.0659\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.4226 - mae: 0.0603 - val_loss: -0.3606 - val_mae: 0.0616\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.4366 - mae: 0.0536 - val_loss: -0.3609 - val_mae: 0.0506\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.4542 - mae: 0.0476 - val_loss: -0.3705 - val_mae: 0.0481\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.4696 - mae: 0.0419 - val_loss: -0.3780 - val_mae: 0.0395\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.4826 - mae: 0.0383 - val_loss: -0.3723 - val_mae: 0.0386\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.4961 - mae: 0.0347 - val_loss: -0.3796 - val_mae: 0.0352\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5101 - mae: 0.0328 - val_loss: -0.3831 - val_mae: 0.0320\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.5217 - mae: 0.0302 - val_loss: -0.3911 - val_mae: 0.0290\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.5325 - mae: 0.0285 - val_loss: -0.3856 - val_mae: 0.0298\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.5411 - mae: 0.0268 - val_loss: -0.3911 - val_mae: 0.0273\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5498 - mae: 0.0257 - val_loss: -0.3969 - val_mae: 0.0277\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5606 - mae: 0.0243 - val_loss: -0.3976 - val_mae: 0.0268\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5677 - mae: 0.0238 - val_loss: -0.4020 - val_mae: 0.0247\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 2s 14ms/step - loss: -0.5770 - mae: 0.0228 - val_loss: -0.3934 - val_mae: 0.0233\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5822 - mae: 0.0222 - val_loss: -0.3932 - val_mae: 0.0243\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5902 - mae: 0.0215 - val_loss: -0.3980 - val_mae: 0.0235\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.5952 - mae: 0.0208 - val_loss: -0.3955 - val_mae: 0.0233\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.6025 - mae: 0.0206 - val_loss: -0.4010 - val_mae: 0.0217\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.6081 - mae: 0.0199 - val_loss: -0.4000 - val_mae: 0.0219\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.6140 - mae: 0.0197 - val_loss: -0.4030 - val_mae: 0.0214\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 2s 13ms/step - loss: -0.6153 - mae: 0.0192 - val_loss: -0.4015 - val_mae: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:783: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Using control points [1.09717395e-08 2.62195667e-08 7.31789715e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n",
      "Using control points [3.19461285e-09 5.40810144e-09 5.65338635e-08]\n",
      "For automatic theme detection, \"darkdetect\" has to be installed! You can install it with `pip install darkdetect`\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with `pip install qdarkstyle`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x22ab5d5efa0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import Simulation, Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "\n",
    "# Create generic Forward Model\n",
    "info = get_info()\n",
    "fwd = create_forward_model(info=info, sampling='ico2')\n",
    "\n",
    "# Simulate M/EEG data\n",
    "settings = dict(duration_of_trial=0.1)\n",
    "sim = Simulation(fwd, info, settings=settings)\n",
    "sim.simulate(n_samples=1000)\n",
    "\n",
    "# Train neural network (LSTM) on the simulated data\n",
    "net = Net(fwd)\n",
    "net.fit(sim, epochs=30)\n",
    "\n",
    "# Plot\n",
    "stc = net.predict(sim.eeg_data[0])[0]\n",
    "sim.source_data[0].plot(surface=\"white\", hemi=\"both\")\n",
    "stc.plot(surface=\"white\", hemi=\"both\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9587d79750f5d7fc5c0560e15a7a8a49dff11015373bda407c2fe4ab31d0fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

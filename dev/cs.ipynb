{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    2.5s remaining:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(sfreq=100, kind=\"biosemi64\")\n",
    "fwd = create_forward_model(sampling=\"ico3\", info=info)\n",
    "_, pos = util.unpack_fwd(fwd)[1:3]\n",
    "leadfield = fwd[\"sol\"][\"data\"]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "import mne\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "adjacency = mne.spatial_src_adjacency(fwd['src']).toarray()\n",
    "laplace_operator = abs(laplacian(adjacency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X, y):\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 203.17it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 21446.29it/s]\n",
      "100%|██████████| 2000/2000 [00:37<00:00, 52.73it/s]\n"
     ]
    }
   ],
   "source": [
    "settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=1e99)\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_samples=2000)\n",
    "X = np.stack([eeg.average().data for eeg in sim.eeg_data], axis=0)\n",
    "y = np.stack([source.data for source in sim.source_data], axis=0)\n",
    "X, y = prep_data(X, y)\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "y = np.swapaxes(y, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Input, Lambda, LayerNormalization, GRU, multiply\n",
    "from tensorflow.keras.layers import Activation, Dropout, ActivityRegularization, TimeDistributed, Reshape, Permute, GaussianNoise, add\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "# import tensorflow_probability as tfp\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def data_loss(leadfield, lam_0=0.1):\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    def batch_data_loss(y_true, y_est):\n",
    "        def d_loss(y_true, y_est):\n",
    "            y_true_eeg = tf.transpose(tf.matmul(leadfield_, tf.transpose(y_true)))\n",
    "            y_est_eeg = tf.transpose(tf.matmul(leadfield_, tf.transpose(y_est)))\n",
    "            # print(\"y_true \", y_true)\n",
    "            # print(\"y_est \", y_est)\n",
    "            \n",
    "            # return K.mean(K.square(y_est - y_true))\n",
    "            error_source = tf.keras.losses.CosineSimilarity(name=\"Data_Cosine_Loss\")(y_est, y_true)\n",
    "            error_eeg = tf.keras.losses.CosineSimilarity(name=\"Data_Cosine_Loss\")(y_est_eeg, y_true_eeg)\n",
    "            return (error_source*lam_0 + error_eeg) / (1 + lam_0)\n",
    "        \n",
    "        \n",
    "\n",
    "        batched_losses = tf.map_fn(lambda x:\n",
    "            d_loss(x[0], x[1]), \n",
    "            (y_true, y_est), dtype=tf.float32)\n",
    "        return K.mean(batched_losses)\n",
    "\n",
    "\n",
    "    return batch_data_loss\n",
    "\n",
    "\n",
    "def consistency(x):\n",
    "    return K.mean(K.std(K.abs(x), axis=1))\n",
    "\n",
    "# def consistency(source):\n",
    "#     def c_loss(x):\n",
    "#         matrix = compute_cosine_distances(K.abs(x), K.abs(x))\n",
    "#         return K.mean(matrix)\n",
    "\n",
    "\n",
    "#     batched_losses = tf.map_fn(lambda x:\n",
    "#             c_loss(x), \n",
    "#             source, dtype=tf.float32)\n",
    "#     return K.mean(batched_losses)\n",
    "\n",
    "def c_loss(sources):\n",
    "    matrix = K.abs(compute_cosine_distances(K.abs(sources), K.abs(sources)))\n",
    "    return K.mean(matrix)\n",
    "\n",
    "\n",
    "def compute_cosine_distances(a, b):\n",
    "    # x shape is n_a * dim\n",
    "    # y shape is n_b * dim\n",
    "    # results shape is n_a * n_b\n",
    "\n",
    "    normalize_a = tf.nn.l2_normalize(a,-1)        \n",
    "    normalize_b = tf.nn.l2_normalize(b,-1)\n",
    "    distance = 1 - tf.matmul(normalize_a, normalize_b, transpose_b=True)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def l1_sparsity(x):\n",
    "    return K.mean(K.abs(x)) \n",
    "\n",
    "def get_model(name=\"Model\", n_dense_layers=2, hidden_units=200, learning_rate=0.001, lam_0=0.1, lam_1=1, lam_2=0.001, add_consistency=True):\n",
    "    input_shape = (None, n_chans)\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=name)\n",
    "    fc = TimeDistributed(Dense(hidden_units, activation=\"linear\", name=\"FC1\"))(inputs)\n",
    "\n",
    "    gru = GRU(64, return_sequences=True, name='GRU_Discriminator')(inputs)\n",
    "    source_time = TimeDistributed(Dense(n_dipoles, activation=\"sigmoid\", name=\"Mask\"))(gru)\n",
    "\n",
    "    source = TimeDistributed(Dense(n_dipoles, activation=\"linear\", name=\"Output_Final\"))(fc)\n",
    "\n",
    "    out = multiply([source_time, source])\n",
    "    print(out)\n",
    "    # out = Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans))(source)\n",
    "    # # out = TimeDistributed(Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans)))(source)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out, name='CS_Net')\n",
    "    \n",
    "    # Data Loss\n",
    "    # L1 Loss\n",
    "    model.add_loss(l1_sparsity(out)*lam_1)\n",
    "    \n",
    "    # Data consistency loss\n",
    "    if add_consistency:\n",
    "        model.add_loss(c_loss(out)*lam_2)\n",
    "    \n",
    "    model.compile(loss=data_loss(leadfield, lam_0=lam_0), optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 1284), dtype=tf.float32, name=None), name='multiply_5/mul:0', description=\"created by layer 'multiply_5'\")\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "lams_0 = [0.1, ]\n",
    "lams_1 = [1, ]\n",
    "lams_2 = [0.01, ]\n",
    "\n",
    "models = []\n",
    "for lam_0, lam_1, lam_2 in zip(lams_0, lams_1, lams_2):\n",
    "    model = get_model(lam_0=lam_0, lam_1=lam_1, lam_2=lam_2, name=f\"Lam {lam_2}\")\n",
    "    model.fit(X, y, epochs=20, batch_size=8, validation_split=0.1)\n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.61it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.4506545454545454  Corrs:  -0.013988784125806055  nMSE:  0.0002984057234285125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.02454895 0.04213159 0.11234727]\n",
      "Using control points [0.00000000e+00 0.00000000e+00 3.14025451e-08]\n",
      "Using control points [0.05798654 0.10227946 0.33669638]\n"
     ]
    }
   ],
   "source": [
    "from esinet.evaluate import eval_auc\n",
    "from scipy.stats import pearsonr\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=2)\n",
    "idx = 0\n",
    "stc = sim_test.source_data[idx].copy()\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "for mod in models:\n",
    "    src_hat = mod.predict(X)[idx]\n",
    "    stc_hat = stc.copy()\n",
    "    stc_hat.data = src_hat.T\n",
    "    stc_hat.plot(**plot_params)\n",
    "    auc = np.mean([np.mean(eval_auc(y_true_sample, y_pred_sample, pos)) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    corrs = np.mean([np.mean(pearsonr(y_true_sample, y_pred_sample)[0]) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    nmses = np.mean([np.mean((y_true_sample - y_pred_sample)**2) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    \n",
    "    print(\"AUC: \", auc, \" Corrs: \", corrs, \" nMSE: \", nmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 334.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2004.93it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS_Net  AUC:  0.9762000000000001  Corrs:  0.1828618053288864  nMSE:  0.006708810981980628 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from esinet.evaluate import eval_auc\n",
    "from scipy.stats import pearsonr\n",
    "# settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=1e99)\n",
    "settings = dict(duration_of_trial=0.25, extents=20, number_of_sources=1, target_snr=1e99)\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=2)\n",
    "\n",
    "X_test = np.stack([eeg.average().data for eeg in sim_test.eeg_data], axis=0)\n",
    "y_test = np.stack([source.data for source in sim_test.source_data], axis=0)\n",
    "X_test, y_test = prep_data(X_test, y_test)\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "y_test = np.swapaxes(y_test, 1, 2)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "stc = sim_test.source_data[idx].copy()\n",
    "stc.data /= np.max(abs(stc.data))\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "for model in models:\n",
    "    src_hat = model.predict(X_test)[idx]\n",
    "    stc_hat = stc.copy()\n",
    "    stc_hat.data = src_hat.T\n",
    "    stc_hat.data /= np.max(abs(stc_hat.data))\n",
    "    stc_hat.plot(**plot_params)\n",
    "    auc = np.mean([np.mean(eval_auc(y_true_sample, y_pred_sample, pos)) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    corrs = np.mean([np.mean(pearsonr(y_true_sample, y_pred_sample)[0]) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    nmses = np.mean([np.mean((y_true_sample - y_pred_sample)**2) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    \n",
    "    print(model.name, \" AUC: \", auc, \" Corrs: \", corrs, \" nMSE: \", nmses, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8.,   0.,   0.,   0., 312.,   0.,  85.,   0., 181.,  39.]),\n",
       " array([-2.22044605e-16, -1.66533454e-16, -1.11022302e-16, -5.55111512e-17,\n",
       "         0.00000000e+00,  5.55111512e-17,  1.11022302e-16,  1.66533454e-16,\n",
       "         2.22044605e-16,  2.77555756e-16,  3.33066907e-16]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [1.99267993e-08 1.85261041e-06 3.01261865e-02]\n",
      "Using control points [0.16313677 0.1865924  0.31465007]\n",
      "Using control points [0.28877792 0.36436045 0.82884548]\n",
      "Using control points [0.28877792 0.36436045 0.82884548]\n",
      "Using control points [1.99267993e-08 1.85261041e-06 3.01261865e-02]\n",
      "Using control points [0.16410797 0.2065051  0.46552234]\n",
      "Using control points [0.16410797 0.2065051  0.46552234]\n",
      "Using control points [0.30574767 0.38696716 0.87798761]\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(compute_cosine_distances(abs(stc_hat.data.T), abs(stc_hat.data.T)).numpy().flatten())\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(compute_cosine_distances(abs(stc.data.T), abs(stc.data.T)).numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16],\n",
       "       [ 2.22044605e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         2.22044605e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16,  2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16,  1.11022302e-16,  2.22044605e-16,\n",
       "         1.11022302e-16],\n",
       "       [ 1.11022302e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "         1.11022302e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16,  1.11022302e-16, -2.22044605e-16,\n",
       "        -2.22044605e-16, -2.22044605e-16,  1.11022302e-16,\n",
       "        -2.22044605e-16]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cosine_distances(abs(stc.data.T), abs(stc.data.T)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS_Net  AUC:  0.8378210112213429  Corrs:  0.7222753552536002  nMSE:  0.0006593505864149563 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.09355759 0.12046235 0.51585314]\n",
      "Using control points [0.09003848 0.10991064 0.52070489]\n",
      "Using control points [0.08965538 0.11320082 0.38877619]\n",
      "Using control points [0.0851066  0.09752246 0.21187828]\n",
      "Using control points [0.07968308 0.09179646 0.23420075]\n",
      "Using control points [0.12812387 0.17138633 0.88748322]\n",
      "Using control points [0.12812387 0.17138633 0.88748322]\n",
      "Using control points [0.11990799 0.16882805 0.88780172]\n",
      "Using control points [0.11927841 0.15267209 0.64830078]\n",
      "Using control points [0.00000000e+00 3.64393098e-09 5.85266263e-08]\n",
      "Using control points [0.         0.01178944 0.34447401]\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, '../../invert/')\n",
    "from invert.solvers.minimum_norm_estimates import SolverDynamicStatisticalParametricMapping, SolverMinimumNorm\n",
    "from invert.solvers.wrop import SolverLAURA\n",
    "from invert.solvers.empirical_bayes import SolverChampagne\n",
    "\n",
    "# solver = SolverLAURA().make_inverse_operator(fwd)\n",
    "solver = SolverChampagne().make_inverse_operator(fwd)\n",
    "# solver = SolverMinimumNorm().make_inverse_operator(fwd)\n",
    "\n",
    "stc_mne = solver.apply_inverse_operator(sim_test.eeg_data[0].average())\n",
    "stc_mne.data = stc_mne.data / np.max(abs(stc_mne.data))\n",
    "stc_mne.plot(**plot_params, brain_kwargs=dict(title=solver.name))\n",
    "auc = np.mean([np.mean(eval_auc(y_true_sample, y_pred_sample, pos)) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_mne.data.T)])\n",
    "corrs = np.mean([np.mean(pearsonr(y_true_sample, y_pred_sample)[0]) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_mne.data.T)])\n",
    "nmses = np.mean([np.mean((y_true_sample - y_pred_sample)**2) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_mne.data.T)])\n",
    "\n",
    "print(model.name, \" AUC: \", auc, \" Corrs: \", corrs, \" nMSE: \", nmses, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9587d79750f5d7fc5c0560e15a7a8a49dff11015373bda407c2fe4ab31d0fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

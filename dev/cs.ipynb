{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    2.5s remaining:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(sfreq=100, kind=\"biosemi64\")\n",
    "fwd = create_forward_model(sampling=\"ico3\", info=info)\n",
    "_, pos = util.unpack_fwd(fwd)[1:3]\n",
    "leadfield = fwd[\"sol\"][\"data\"]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "import mne\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "adjacency = mne.spatial_src_adjacency(fwd['src']).toarray()\n",
    "laplace_operator = abs(laplacian(adjacency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(X, y):\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 203.17it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 21446.29it/s]\n",
      "100%|██████████| 2000/2000 [00:37<00:00, 52.73it/s]\n"
     ]
    }
   ],
   "source": [
    "settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=1e99)\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_samples=2000)\n",
    "X = np.stack([eeg.average().data for eeg in sim.eeg_data], axis=0)\n",
    "y = np.stack([source.data for source in sim.source_data], axis=0)\n",
    "X, y = prep_data(X, y)\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "y = np.swapaxes(y, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Input, Lambda, LayerNormalization, GRU, multiply, Bidirectional\n",
    "from tensorflow.keras.layers import Activation, Dropout, ActivityRegularization, TimeDistributed, Reshape, Permute, GaussianNoise, add\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "# import tensorflow_probability as tfp\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def data_loss(leadfield, lam_0=0.1):\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    def batch_data_loss(y_true, y_est):\n",
    "        def d_loss(y_true, y_est):\n",
    "            y_true_eeg = tf.transpose(tf.matmul(leadfield_, tf.transpose(y_true)))\n",
    "            y_est_eeg = tf.transpose(tf.matmul(leadfield_, tf.transpose(y_est)))\n",
    "            # print(\"y_true \", y_true)\n",
    "            # print(\"y_est \", y_est)\n",
    "            \n",
    "            # return K.mean(K.square(y_est - y_true))\n",
    "            error_source = tf.keras.losses.CosineSimilarity(name=\"Data_Cosine_Loss\")(y_est, y_true)\n",
    "            error_eeg = tf.keras.losses.CosineSimilarity(name=\"Data_Cosine_Loss\")(y_est_eeg, y_true_eeg)\n",
    "            return (error_source*lam_0 + error_eeg) / (1 + lam_0)\n",
    "        \n",
    "        \n",
    "\n",
    "        batched_losses = tf.map_fn(lambda x:\n",
    "            d_loss(x[0], x[1]), \n",
    "            (y_true, y_est), dtype=tf.float32)\n",
    "        return K.mean(batched_losses)\n",
    "\n",
    "\n",
    "    return batch_data_loss\n",
    "\n",
    "\n",
    "def consistency(x):\n",
    "    return K.mean(K.std(K.abs(x), axis=1))\n",
    "\n",
    "# def consistency(source):\n",
    "#     def c_loss(x):\n",
    "#         matrix = compute_cosine_distances(K.abs(x), K.abs(x))\n",
    "#         return K.mean(matrix)\n",
    "\n",
    "\n",
    "#     batched_losses = tf.map_fn(lambda x:\n",
    "#             c_loss(x), \n",
    "#             source, dtype=tf.float32)\n",
    "#     return K.mean(batched_losses)\n",
    "\n",
    "def c_loss(sources):\n",
    "    matrix = K.abs(compute_cosine_distances(K.abs(sources), K.abs(sources)))\n",
    "    return K.mean(matrix)\n",
    "\n",
    "\n",
    "def compute_cosine_distances(a, b):\n",
    "    # x shape is n_a * dim\n",
    "    # y shape is n_b * dim\n",
    "    # results shape is n_a * n_b\n",
    "\n",
    "    normalize_a = tf.nn.l2_normalize(a,-1)        \n",
    "    normalize_b = tf.nn.l2_normalize(b,-1)\n",
    "    distance = 1 - tf.matmul(normalize_a, normalize_b, transpose_b=True)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def l1_sparsity(x):\n",
    "    return K.mean(K.abs(x)) \n",
    "    # return K.mean(K.pow(K.abs(x), 0.5))\n",
    "\n",
    "\n",
    "def get_model(name=\"Model\", n_dense_layers=2, n_lstm_units=128, hidden_units=200, learning_rate=0.001, lam_0=0.1, lam_1=1, lam_2=0.001, add_consistency=True):\n",
    "    input_shape = (None, n_chans)\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=name)\n",
    "    fc = TimeDistributed(Dense(hidden_units, activation=\"linear\", name=\"FC1\"))(inputs)\n",
    "\n",
    "    gru = Bidirectional(GRU(n_lstm_units, return_sequences=True, name='GRU_Discriminator'))(inputs)\n",
    "    source_time = TimeDistributed(Dense(n_dipoles, activation=\"sigmoid\", name=\"Mask\"))(gru)\n",
    "\n",
    "    source = TimeDistributed(Dense(n_dipoles, activation=\"linear\", name=\"Output_Final\"))(fc)\n",
    "\n",
    "    out = multiply([source_time, source])\n",
    "    # out = Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans))(source)\n",
    "    # # out = TimeDistributed(Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans)))(source)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out, name='CS_Net')\n",
    "    \n",
    "    # Data Loss\n",
    "    # L1 Loss\n",
    "    model.add_loss(l1_sparsity(out)*lam_1)\n",
    "    \n",
    "    # Data consistency loss\n",
    "    if add_consistency:\n",
    "        model.add_loss(c_loss(out)*lam_2)\n",
    "    \n",
    "    model.compile(loss=data_loss(leadfield, lam_0=lam_0), optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7071067811865476"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.5**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 14s 51ms/step - loss: 1539.0674 - val_loss: 10.1957\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 9s 41ms/step - loss: 5.6814 - val_loss: 3.6489\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 10s 43ms/step - loss: 2.2602 - val_loss: 1.6730\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 10s 43ms/step - loss: 1.0039 - val_loss: 0.7670\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 10s 44ms/step - loss: 0.3754 - val_loss: 0.2673\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 11s 47ms/step - loss: 0.0103 - val_loss: -0.0402\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 15s 68ms/step - loss: -0.2242 - val_loss: -0.2494\n",
      "Epoch 8/20\n",
      "225/225 [==============================] - 10s 44ms/step - loss: -0.3839 - val_loss: -0.3948\n",
      "Epoch 9/20\n",
      "225/225 [==============================] - 10s 44ms/step - loss: -0.4992 - val_loss: -0.4978\n",
      "Epoch 10/20\n",
      "  6/225 [..............................] - ETA: 17s - loss: -0.5303"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12092/1949267095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlam_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam_2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlams_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlams_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlams_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam_0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlam_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlam_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlam_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"Lam {lam_2}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lams_0 = [0.01, ]  # source-based\n",
    "lams_1 = [1, ]  # sparsity\n",
    "lams_2 = [0.0, ]  # context\n",
    "\n",
    "models = []\n",
    "for lam_0, lam_1, lam_2 in zip(lams_0, lams_1, lams_2):\n",
    "    model = get_model(lam_0=lam_0, lam_1=lam_1, lam_2=lam_2, name=f\"Lam {lam_2}\")\n",
    "    model.fit(X, y, epochs=20, batch_size=8, validation_split=0.1)\n",
    "    models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 12.61it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 55.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.4506545454545454  Corrs:  -0.013988784125806055  nMSE:  0.0002984057234285125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.02454895 0.04213159 0.11234727]\n",
      "Using control points [0.00000000e+00 0.00000000e+00 3.14025451e-08]\n",
      "Using control points [0.05798654 0.10227946 0.33669638]\n"
     ]
    }
   ],
   "source": [
    "from esinet.evaluate import eval_auc\n",
    "from scipy.stats import pearsonr\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=2)\n",
    "idx = 0\n",
    "stc = sim_test.source_data[idx].copy()\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "for mod in models:\n",
    "    src_hat = mod.predict(X)[idx]\n",
    "    stc_hat = stc.copy()\n",
    "    stc_hat.data = src_hat.T\n",
    "    stc_hat.plot(**plot_params)\n",
    "    auc = np.mean([np.mean(eval_auc(y_true_sample, y_pred_sample, pos)) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    corrs = np.mean([np.mean(pearsonr(y_true_sample, y_pred_sample)[0]) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    nmses = np.mean([np.mean((y_true_sample - y_pred_sample)**2) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    \n",
    "    print(\"AUC: \", auc, \" Corrs: \", corrs, \" nMSE: \", nmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 13.93it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 48.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS_Net  AUC:  0.5496798953643697  Corrs:  0.02745870083791779  nMSE:  0.004981103010030023 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from esinet.evaluate import eval_auc\n",
    "from scipy.stats import pearsonr\n",
    "# settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=1e99)\n",
    "settings = dict(duration_of_trial=0.25, extents=20, number_of_sources=6, target_snr=1e99)\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=2)\n",
    "\n",
    "X_test = np.stack([eeg.average().data for eeg in sim_test.eeg_data], axis=0)\n",
    "y_test = np.stack([source.data for source in sim_test.source_data], axis=0)\n",
    "X_test, y_test = prep_data(X_test, y_test)\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "y_test = np.swapaxes(y_test, 1, 2)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "stc = sim_test.source_data[idx].copy()\n",
    "stc.data /= np.max(abs(stc.data))\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "for model in models:\n",
    "    src_hat = model.predict(X_test)[idx]\n",
    "    stc_hat = stc.copy()\n",
    "    stc_hat.data = src_hat.T\n",
    "    stc_hat.data /= np.max(abs(stc_hat.data))\n",
    "    stc_hat.plot(**plot_params)\n",
    "    auc = np.mean([np.mean(eval_auc(y_true_sample, y_pred_sample, pos)) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    corrs = np.mean([np.mean(pearsonr(y_true_sample, y_pred_sample)[0]) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    nmses = np.mean([np.mean((y_true_sample - y_pred_sample)**2) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_hat.data.T)])\n",
    "    \n",
    "    print(model.name, \" AUC: \", auc, \" Corrs: \", corrs, \" nMSE: \", nmses, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([165., 116.,  64.,  68.,  54.,  50.,  48.,  32.,  24.,   4.]),\n",
       " array([-4.44089210e-16,  9.17119272e-02,  1.83423854e-01,  2.75135782e-01,\n",
       "         3.66847709e-01,  4.58559636e-01,  5.50271563e-01,  6.41983491e-01,\n",
       "         7.33695418e-01,  8.25407345e-01,  9.17119272e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(compute_cosine_distances(abs(stc_hat.data.T), abs(stc_hat.data.T)).numpy().flatten())\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(compute_cosine_distances(abs(stc.data.T), abs(stc.data.T)).numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS_Net  AUC:  0.6901205204081633  Corrs:  0.25001445685071416  nMSE:  0.0013093190564428994 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.2380896  0.26938491 0.61941261]\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, '../../invert/')\n",
    "from invert.solvers.minimum_norm_estimates import SolverDynamicStatisticalParametricMapping, SolverMinimumNorm\n",
    "from invert.solvers.wrop import SolverLAURA\n",
    "from invert.solvers.empirical_bayes import SolverChampagne\n",
    "\n",
    "# solver = SolverLAURA().make_inverse_operator(fwd)\n",
    "solver = SolverChampagne().make_inverse_operator(fwd)\n",
    "# solver = SolverMinimumNorm().make_inverse_operator(fwd)\n",
    "\n",
    "stc_mne = solver.apply_inverse_operator(sim_test.eeg_data[0].average())\n",
    "stc_mne.data = stc_mne.data / np.max(abs(stc_mne.data))\n",
    "stc_mne.plot(**plot_params, brain_kwargs=dict(title=solver.name))\n",
    "auc = np.mean([np.mean(eval_auc(y_true_sample, y_pred_sample, pos)) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_mne.data.T)])\n",
    "corrs = np.mean([np.mean(pearsonr(y_true_sample, y_pred_sample)[0]) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_mne.data.T)])\n",
    "nmses = np.mean([np.mean((y_true_sample - y_pred_sample)**2) for y_true_sample, y_pred_sample in zip(stc.data.T, stc_mne.data.T)])\n",
    "\n",
    "print(model.name, \" AUC: \", auc, \" Corrs: \", corrs, \" nMSE: \", nmses, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a54b85cbc80ea8362b8e45e33618627fd9167210ff2c52e6dbeaf85afe35b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

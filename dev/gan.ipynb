{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "# import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    1.6s remaining:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    1.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(sfreq=100)\n",
    "fwd = create_forward_model(sampling=\"ico3\", info=info)\n",
    "leadfield = fwd[\"sol\"][\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1284, 1284)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "adjacency = mne.spatial_src_adjacency(fwd['src']).toarray()\n",
    "laplace_operator = laplacian(adjacency)\n",
    "laplace_operator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (None, 61).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Input, Lambda, LayerNormalization\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import mne\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "adjacency = mne.spatial_src_adjacency(fwd['src']).toarray()\n",
    "laplace_operator = laplacian(adjacency)\n",
    "\n",
    "def custom_gan_loss(y_true, y_hat):\n",
    "    # error = -tf.keras.losses.CosineSimilarity()(y_hat[0], y_hat[1])\n",
    "    error = -tf.keras.losses.mean_squared_error(y_hat[0], y_hat[1])\n",
    "    # blur = tf.math.count_nonzero(y_hat[0], dtype=tf.float32) / tf.cast(tf.size(y_hat[0]), dtype=tf.float32)\n",
    "\n",
    "    return error # + blur\n",
    "\n",
    "def define_models(latent_dim, hidden_units=200):\n",
    "    n_chans, n_dipoles = leadfield.shape\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(latent_dim), name='Input_Generator')\n",
    "\n",
    "    # G MODEL\n",
    "    fc = Dense(latent_dim, name=\"HL_G\")(inputs)\n",
    "    gen_out = Dense(n_dipoles, name=\"Output_Generator\", activation=\"tanh\")(fc)\n",
    "    # gen_out = Lambda(lambda x: tf.cast(x>K.max(K.abs(x))*0.8, dtype=x.dtype) * x, output_shape=(None, n_dipoles))(gen_out)\n",
    "    g_model = tf.keras.Model(inputs=inputs, outputs=gen_out, name='Generator')\n",
    "    # g_model.build(input_shape=(latent_dim))\n",
    "    \n",
    "    # D MODEL\n",
    "    input_shape = (None, n_chans)\n",
    "    inputs2 = tf.keras.Input(shape=input_shape, name='Input_Discriminator')\n",
    "    fc2 = Dense(hidden_units, name=\"HL_D\")(inputs2)\n",
    "    out = Dense(n_dipoles, name=\"Output_Final\")(fc2)\n",
    "    d_model = tf.keras.Model(inputs=inputs2, outputs=out, name='Discriminator')\n",
    "    # d_model.build(input_shape=(latent_dim))\n",
    "    \n",
    "    lam = Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans))\n",
    "    inputs = tf.keras.Input(shape=(latent_dim), name='Input_Generator')\n",
    "    # d_model.trainable = False\n",
    "    output_1 = g_model(inputs)\n",
    "    eeg = lam(output_1)\n",
    "    eeg_normed = LayerNormalization()(eeg)\n",
    "    output_3 = d_model(eeg_normed)\n",
    "    gan_model = Model(inputs, [output_1, output_3])\n",
    "\n",
    "    g_model.compile(loss=custom_gan_loss, optimizer=\"adam\")\n",
    "    # d_model.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "    d_model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    \n",
    "    gan_model.compile(loss=custom_gan_loss, optimizer=\"adam\")\n",
    "    \n",
    "    return g_model, d_model, gan_model\n",
    "\n",
    "def prep_data(X, y):\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        X = np.expand_dims(X, axis=-1)\n",
    "        y = np.expand_dims(y, axis=-1)\n",
    "    X = np.swapaxes(X, 1,2)\n",
    "    y = np.swapaxes(y, 1,2)\n",
    "    return X, y\n",
    "\n",
    "def generate_samples(g_model, batch_size, latent_dim):\n",
    "    x_input = np.random.randn(batch_size, latent_dim)\n",
    "    sources = g_model.predict(x_input)\n",
    "    return sources\n",
    "\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 32\n",
    "batch_number = 10\n",
    "latent_dim = 100\n",
    "g_model, d_model, gan_model = define_models(latent_dim, hidden_units=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 61, 1284), dtype=tf.float32, name=None), name='lambda_89/transpose_1:0', description=\"created by layer 'lambda_89'\")\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='input_50'), name='input_50', description=\"created by layer 'input_50'\"), but it was called on an input with incompatible shape (None, 61, 1284).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer HL1 is incompatible with the layer: expected axis -1 of input shape to have value 61 but received input with shape (None, 61, 1284)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5328/1679269642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0md_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mg_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mgan_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5328/1679269642.py\u001b[0m in \u001b[0;36mdefine_gan\u001b[1;34m(g_model, d_model, latent_dim)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mlam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleadfield_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_chans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Contextualizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         training=training_mode):\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    249\u001b[0m           \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshape_as_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m    252\u001b[0m               \u001b[1;34m'Input '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' of layer '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m               \u001b[1;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer HL1 is incompatible with the layer: expected axis -1 of input shape to have value 61 but received input with shape (None, 61, 1284)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Input, Lambda\n",
    "import numpy as np\n",
    "\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "def define_generator(latent_dim):\n",
    "    g_model = tf.keras.Sequential()\n",
    "    input_shape = (None, latent_dim)\n",
    "    g_model.add(InputLayer(input_shape=input_shape))\n",
    "    g_model.add(Dense(latent_dim, name=\"HL1\"))\n",
    "    g_model.add(Dense(n_dipoles, name=\"Output\"))\n",
    "    # g_model.build()\n",
    "    # g_model.compile(optimizer='adam', loss=\"mse\")\n",
    "    # g_model.summary()\n",
    "    return g_model\n",
    "    \n",
    "def define_discriminator(hidden_units=100):\n",
    "    input_shape = (None, n_chans)\n",
    "    d_model = tf.keras.Sequential()\n",
    "    d_model.add(InputLayer(input_shape=input_shape))\n",
    "    d_model.add(Dense(hidden_units, name=\"HL1\"))\n",
    "    d_model.add(Dense(n_dipoles, name=\"Output\"))\n",
    "    d_model.build()\n",
    "    d_model.compile(optimizer='adam', loss=tf.keras.losses.CosineSimilarity())\n",
    "    # d_model.summary()\n",
    "    return d_model\n",
    "\n",
    "def define_gan(g_model, d_model, latent_dim):\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    d_model.trainable = False\n",
    "    \n",
    "    input_shape = (None, latent_dim)\n",
    "    \n",
    "    lam = Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans))(g_model.output)\n",
    "    print(lam)\n",
    "    discriminator = d_model(lam)\n",
    "    model = tf.keras.Model(inputs=g_model.input, outputs=[d_model.output, g_model.output], name='Contextualizer')\n",
    "\n",
    "\n",
    "    # model = tf.keras.Sequential()\n",
    "    # model.add(g_model)\n",
    "    # model.add(Lambda(lambda x: tf.linalg.matmul(leadfield_, x)))\n",
    "    # model.add(d_model)\n",
    "    # model.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "    return model\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (None, 61).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (32, 61).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (32, 61).\n",
      "disc-loss: 0.47, gan-loss: -0.83\n",
      "disc-loss: 0.50\n",
      "disc-loss: 0.42\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36, gan-loss: -0.77\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35, gan-loss: -0.83\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35, gan-loss: -0.89\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35, gan-loss: -0.79\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35, gan-loss: -0.86\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35, gan-loss: -0.86\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5328/1589355427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0md_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1819\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1821\u001b[1;33m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[0m\u001b[0;32m   1822\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m                                                     class_weight)\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[1;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m   \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1615\u001b[1;33m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1616\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    679\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \"\"\"\n\u001b[1;32m--> 681\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   3303\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3305\u001b[1;33m     variant_tensor = gen_dataset_ops.tensor_dataset(\n\u001b[0m\u001b[0;32m   3306\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m         output_shapes=structure.get_flat_tensor_shapes(self._structure))\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mtensor_dataset\u001b[1;34m(components, output_shapes, name)\u001b[0m\n\u001b[0;32m   7025\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7026\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7027\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   7028\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"TensorDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_shapes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7029\u001b[0m         output_shapes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10000\n",
    "batch_size = 32\n",
    "latent_dim = 1000\n",
    "g_model, d_model, gan_model = define_models(latent_dim, hidden_units=latent_dim)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    y = generate_samples(g_model, batch_size, latent_dim)\n",
    "    X = (leadfield @ y.T).T\n",
    "    X, y = prep_data(X,y)\n",
    "    d_model.trainable = True\n",
    "    d_loss = d_model.train_on_batch(X, y)\n",
    "    if i%100 == 0:    \n",
    "        x_input = np.random.randn(batch_size, latent_dim)\n",
    "        X = np.zeros((batch_size, n_dipoles))\n",
    "        d_model.trainable = False\n",
    "        gan_loss = gan_model.train_on_batch(x_input, X)[0]\n",
    "        print(f'disc-loss: {d_loss:.2f}, gan-loss: {gan_loss:.2f}')\n",
    "    else:\n",
    "        print(f'disc-loss: {d_loss:.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:00<00:00, 15.15it/s]\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n",
      "100%|| 2/2 [00:00<00:00, 181.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.16, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2\n",
    "# settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=(2, 15))\n",
    "settings = dict(duration_of_trial=0.1, extents=25, number_of_sources=1, target_snr=1e99)\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "def prep_data_sim(sim):\n",
    "    X = np.squeeze(np.stack([eeg.average().data for eeg in sim.eeg_data]))\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.squeeze(np.stack([src.data for src in sim.source_data]))\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        X = np.expand_dims(X, axis=-1)\n",
    "        y = np.expand_dims(y, axis=-1)\n",
    "    X = np.swapaxes(X, 1,2)\n",
    "    y = np.swapaxes(y, 1,2)\n",
    "    return X, y\n",
    "X, y = prep_data_sim(sim_test)\n",
    "\n",
    "y_hat = d_model.predict(X)\n",
    "y_hat.shape\n",
    "stc = sim_test.source_data[0]\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "stc_hat = stc.copy()\n",
    "stc_hat.data = y_hat[0].T\n",
    "stc_hat.plot(**plot_params)\n",
    "from scipy.stats import pearsonr\n",
    "r,p = pearsonr(stc.data.flatten(), stc_hat.data.flatten())\n",
    "print(f'r={r:.2f}, p={p:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FC\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, None, 61)]        0         \n",
      "                                                                 \n",
      " FC1 (TimeDistributed)       (None, None, 600)         37200     \n",
      "                                                                 \n",
      " FC2 (TimeDistributed)       (None, None, 1284)        771684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 808,884\n",
      "Trainable params: 808,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "399/399 [==============================] - 3s 7ms/step - loss: -0.2897 - val_loss: -0.3501\n",
      "Epoch 2/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3597 - val_loss: -0.3755\n",
      "Epoch 3/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3755 - val_loss: -0.3851\n",
      "Epoch 4/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3838 - val_loss: -0.3929\n",
      "Epoch 5/30\n",
      "399/399 [==============================] - 3s 7ms/step - loss: -0.3891 - val_loss: -0.3957\n",
      "Epoch 6/30\n",
      "399/399 [==============================] - 3s 9ms/step - loss: -0.3919 - val_loss: -0.3976\n",
      "Epoch 7/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3945 - val_loss: -0.4006\n",
      "Epoch 8/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3963 - val_loss: -0.4019\n",
      "Epoch 9/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3981 - val_loss: -0.4027\n",
      "Epoch 10/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3995 - val_loss: -0.4015\n",
      "Epoch 11/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4009 - val_loss: -0.4062\n",
      "Epoch 12/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4028 - val_loss: -0.4079\n",
      "Epoch 13/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4048 - val_loss: -0.4102\n",
      "Epoch 14/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4067 - val_loss: -0.4104\n",
      "Epoch 15/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4074 - val_loss: -0.4125\n",
      "Epoch 16/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4086 - val_loss: -0.4131\n",
      "Epoch 17/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4098 - val_loss: -0.4152\n",
      "Epoch 18/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4110 - val_loss: -0.4156\n",
      "Epoch 19/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4118 - val_loss: -0.4169\n",
      "Epoch 20/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4127 - val_loss: -0.4180\n",
      "Epoch 21/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4135 - val_loss: -0.4190\n",
      "Epoch 22/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4144 - val_loss: -0.4183\n",
      "Epoch 23/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4151 - val_loss: -0.4198\n",
      "Epoch 24/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4164 - val_loss: -0.4206\n",
      "Epoch 25/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4172 - val_loss: -0.4217\n",
      "Epoch 26/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4181 - val_loss: -0.4204\n",
      "Epoch 27/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4191 - val_loss: -0.4221\n",
      "Epoch 28/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4200 - val_loss: -0.4212\n",
      "Epoch 29/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4210 - val_loss: -0.4251\n",
      "Epoch 30/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4219 - val_loss: -0.4269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164150f4d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, GRU, multiply, Activation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from esinet.losses import nmae_loss\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, n_dipoles = leadfield.shape\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 600\n",
    "n_lstm_units = 30\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"linear\"),\n",
    "            name='FC2')(fc1)\n",
    "\n",
    "\n",
    "model3 = tf.keras.Model(inputs=inputs, outputs=direct_out, name='FC')\n",
    "\n",
    "\n",
    "model3.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "\n",
    "model3.summary()\n",
    "model3.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a54b85cbc80ea8362b8e45e33618627fd9167210ff2c52e6dbeaf85afe35b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

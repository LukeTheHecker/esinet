{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "# import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = get_info(sfreq=100)\n",
    "fwd = create_forward_model(sampling=\"ico3\", info=info)\n",
    "leadfield = fwd[\"sol\"][\"data\"]\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "import mne\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "adjacency = mne.spatial_src_adjacency(fwd['src']).toarray()\n",
    "laplace_operator = abs(laplacian(adjacency))\n",
    "laplace_operator = laplace_operator @ laplace_operator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- number of adjacent vertices : 1284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2401af83fd0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%matplotlib qt\n",
    "adjacency = mne.spatial_src_adjacency(fwd['src']).toarray()\n",
    "laplace_operator = laplacian(adjacency)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(adjacency)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(laplace_operator)\n",
    "plt.colorbar()\n",
    "\n",
    "laplace_operator = laplace_operator @ laplace_operator\n",
    "plt.figure()\n",
    "plt.imshow(laplace_operator)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (None, 61).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Input, Lambda, LayerNormalization, Activation\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def weightedLoss(w):\n",
    "    def loss(true, pred):\n",
    "        error = K.square(true - pred)\n",
    "        error = K.switch(K.equal(true, 0), w * error , error)\n",
    "        return error \n",
    "    return loss\n",
    "\n",
    "def custom_gan_loss(y_true, y_hat):\n",
    "    # error = -tf.keras.losses.CosineSimilarity()(y_hat[0], y_hat[1])\n",
    "    error = -tf.keras.losses.mean_squared_error(y_hat[0], y_hat[1])\n",
    "    # blur = tf.math.count_nonzero(y_hat[0], dtype=tf.float32) / tf.cast(tf.size(y_hat[0]), dtype=tf.float32)\n",
    "    blur = K.mean(K.abs(y_true))\n",
    "\n",
    "    return error + blur\n",
    "\n",
    "def define_models(latent_dim, hidden_units=200):\n",
    "    n_chans, n_dipoles = leadfield.shape\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    laplace_operator_ = tf.cast(laplace_operator, dtype=tf.float32)\n",
    "    \n",
    "    activation = \"tanh\"\n",
    "    inputs = tf.keras.Input(shape=(latent_dim), name='Input_Generator')\n",
    "    n_dense_layers = 4\n",
    "\n",
    "    # G MODEL\n",
    "    fc = Dense(latent_dim, name=\"HL_G\")(inputs)\n",
    "    gen_out = Dense(n_dipoles, name=\"Output_Generator\", activation=\"tanh\")(fc)\n",
    "\n",
    "    # Thresholding/ Sparsification\n",
    "    # gen_out = Lambda(lambda x: tf.cast(x>K.max(K.abs(x))*0.8, dtype=x.dtype) * x, output_shape=(None, n_dipoles))(gen_out)\n",
    "    \n",
    "    # Smoothing\n",
    "    gen_out = Lambda(lambda x: tf.transpose(tf.linalg.matmul(laplace_operator_, tf.transpose(x))), output_shape=(None, n_chans))(gen_out)\n",
    "    \n",
    "    # Scaling\n",
    "    gen_out = LayerNormalization()(gen_out)\n",
    "    gen_out = Activation(\"tanh\")(gen_out)\n",
    "    g_model = tf.keras.Model(inputs=inputs, outputs=gen_out, name='Generator')\n",
    "    # g_model.build(input_shape=(latent_dim))\n",
    "    \n",
    "    # D MODEL\n",
    "    input_shape = (None, n_chans)\n",
    "    inputs2 = tf.keras.Input(shape=input_shape, name='Input_Discriminator')\n",
    "    \n",
    "    fc2 = Dense(hidden_units, activation=activation, name=\"HL_D1\")(inputs2)\n",
    "    for i in range(n_dense_layers-1):\n",
    "        fc2 = Dense(hidden_units, activation=activation, name=f\"HL_D{i+2}\")(fc2)\n",
    "        \n",
    "    out = Dense(n_dipoles, activation=activation, name=\"Output_Final\")(fc2)\n",
    "    d_model = tf.keras.Model(inputs=inputs2, outputs=out, name='Discriminator')\n",
    "    # d_model.build(input_shape=(latent_dim))\n",
    "    \n",
    "    lam = Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans))\n",
    "    inputs = tf.keras.Input(shape=(latent_dim), name='Input_Generator')\n",
    "    # d_model.trainable = False\n",
    "    output_1 = g_model(inputs)\n",
    "    eeg = lam(output_1)\n",
    "    eeg_normed = LayerNormalization()(eeg)\n",
    "    output_3 = d_model(eeg_normed)\n",
    "    gan_model = Model(inputs, [output_1, output_3])\n",
    "\n",
    "    g_model.compile(loss=custom_gan_loss, optimizer=\"adam\")\n",
    "    # d_model.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "    d_model.compile(loss=weightedLoss(10), optimizer=\"adam\")\n",
    "    \n",
    "    gan_model.compile(loss=custom_gan_loss, optimizer=\"adam\")\n",
    "    \n",
    "    return g_model, d_model, gan_model\n",
    "\n",
    "def prep_data(X, y):\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        X = np.expand_dims(X, axis=-1)\n",
    "        y = np.expand_dims(y, axis=-1)\n",
    "    X = np.swapaxes(X, 1,2)\n",
    "    y = np.swapaxes(y, 1,2)\n",
    "    return X, y\n",
    "\n",
    "def generate_samples(g_model, batch_size, latent_dim):\n",
    "    x_input = np.random.randn(batch_size, latent_dim)\n",
    "    sources = g_model.predict(x_input)\n",
    "    return sources\n",
    "\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 32\n",
    "batch_number = 10\n",
    "latent_dim = 100\n",
    "g_model, d_model, gan_model = define_models(latent_dim, hidden_units=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 61, 1284), dtype=tf.float32, name=None), name='lambda_89/transpose_1:0', description=\"created by layer 'lambda_89'\")\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='input_50'), name='input_50', description=\"created by layer 'input_50'\"), but it was called on an input with incompatible shape (None, 61, 1284).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer HL1 is incompatible with the layer: expected axis -1 of input shape to have value 61 but received input with shape (None, 61, 1284)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5328/1679269642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0md_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mg_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mgan_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5328/1679269642.py\u001b[0m in \u001b[0;36mdefine_gan\u001b[1;34m(g_model, d_model, latent_dim)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mlam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleadfield_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_chans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Contextualizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1105\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         training=training_mode):\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    249\u001b[0m           \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshape_as_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m    252\u001b[0m               \u001b[1;34m'Input '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' of layer '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m               \u001b[1;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer HL1 is incompatible with the layer: expected axis -1 of input shape to have value 61 but received input with shape (None, 61, 1284)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Input, Lambda\n",
    "import numpy as np\n",
    "\n",
    "n_chans, n_dipoles = leadfield.shape\n",
    "\n",
    "def define_generator(latent_dim):\n",
    "    g_model = tf.keras.Sequential()\n",
    "    input_shape = (None, latent_dim)\n",
    "    g_model.add(InputLayer(input_shape=input_shape))\n",
    "    g_model.add(Dense(latent_dim, name=\"HL1\"))\n",
    "    g_model.add(Dense(n_dipoles, name=\"Output\"))\n",
    "    # g_model.build()\n",
    "    # g_model.compile(optimizer='adam', loss=\"mse\")\n",
    "    # g_model.summary()\n",
    "    return g_model\n",
    "    \n",
    "def define_discriminator(hidden_units=100):\n",
    "    input_shape = (None, n_chans)\n",
    "    d_model = tf.keras.Sequential()\n",
    "    d_model.add(InputLayer(input_shape=input_shape))\n",
    "    d_model.add(Dense(hidden_units, name=\"HL1\"))\n",
    "    d_model.add(Dense(n_dipoles, name=\"Output\"))\n",
    "    d_model.build()\n",
    "    d_model.compile(optimizer='adam', loss=tf.keras.losses.CosineSimilarity())\n",
    "    # d_model.summary()\n",
    "    return d_model\n",
    "\n",
    "def define_gan(g_model, d_model, latent_dim):\n",
    "    leadfield_ = tf.cast(leadfield, dtype=tf.float32)\n",
    "    d_model.trainable = False\n",
    "    \n",
    "    input_shape = (None, latent_dim)\n",
    "    \n",
    "    lam = Lambda(lambda x: tf.transpose(tf.linalg.matmul(leadfield_, tf.transpose(x))), output_shape=(None, n_chans))(g_model.output)\n",
    "    print(lam)\n",
    "    discriminator = d_model(lam)\n",
    "    model = tf.keras.Model(inputs=g_model.input, outputs=[d_model.output, g_model.output], name='Contextualizer')\n",
    "\n",
    "\n",
    "    # model = tf.keras.Sequential()\n",
    "    # model.add(g_model)\n",
    "    # model.add(Lambda(lambda x: tf.linalg.matmul(leadfield_, x)))\n",
    "    # model.add(d_model)\n",
    "    # model.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "\n",
    "    return model\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (None, 61).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c282032b6d434b12b0470787ef0931d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (2048, 61).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 61) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input_Discriminator'), name='Input_Discriminator', description=\"created by layer 'Input_Discriminator'\"), but it was called on an input with incompatible shape (2048, 61).\n",
      "disc-loss: 0.45, gan-loss: -0.88\n",
      "disc-loss: 0.46\n",
      "disc-loss: 0.43\n",
      "disc-loss: 0.42, gan-loss: -0.81\n",
      "disc-loss: 0.42\n",
      "disc-loss: 0.41\n",
      "disc-loss: 0.41, gan-loss: -0.85\n",
      "disc-loss: 0.41\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.40, gan-loss: -0.97\n",
      "disc-loss: 0.40\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.39, gan-loss: -0.87\n",
      "disc-loss: 0.39\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.38, gan-loss: -0.86\n",
      "disc-loss: 0.38\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37, gan-loss: -0.81\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37\n",
      "disc-loss: 0.37, gan-loss: -0.90\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.36, gan-loss: -0.91\n",
      "disc-loss: 0.36\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35, gan-loss: -0.95\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35\n",
      "disc-loss: 0.35, gan-loss: -1.07\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34, gan-loss: -0.97\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.34\n",
      "disc-loss: 0.33, gan-loss: -1.27\n",
      "disc-loss: 0.33\n",
      "disc-loss: 0.33\n",
      "disc-loss: 0.33, gan-loss: -0.96\n",
      "disc-loss: 0.33\n",
      "disc-loss: 0.33\n",
      "disc-loss: 0.33, gan-loss: -0.81\n",
      "disc-loss: 0.32\n",
      "disc-loss: 0.32\n",
      "disc-loss: 0.32, gan-loss: -1.07\n",
      "disc-loss: 0.32\n",
      "disc-loss: 0.32\n",
      "disc-loss: 0.31, gan-loss: -1.16\n",
      "disc-loss: 0.31\n",
      "disc-loss: 0.31\n",
      "disc-loss: 0.31, gan-loss: -1.00\n",
      "disc-loss: 0.31\n",
      "disc-loss: 0.31\n",
      "disc-loss: 0.30, gan-loss: -0.90\n",
      "disc-loss: 0.30\n",
      "disc-loss: 0.30\n",
      "disc-loss: 0.30, gan-loss: -0.97\n",
      "disc-loss: 0.30\n",
      "disc-loss: 0.30\n",
      "disc-loss: 0.30, gan-loss: -1.01\n",
      "disc-loss: 0.30\n",
      "disc-loss: 0.29\n",
      "disc-loss: 0.29, gan-loss: -1.02\n",
      "disc-loss: 0.29\n",
      "disc-loss: 0.29\n",
      "disc-loss: 0.29, gan-loss: -1.12\n",
      "disc-loss: 0.29\n",
      "disc-loss: 0.29\n",
      "disc-loss: 0.29, gan-loss: -1.10\n",
      "disc-loss: 0.29\n",
      "disc-loss: 0.28\n",
      "disc-loss: 0.28, gan-loss: -1.15\n",
      "disc-loss: 0.28\n",
      "disc-loss: 0.28\n",
      "disc-loss: 0.28, gan-loss: -1.00\n",
      "disc-loss: 0.28\n",
      "disc-loss: 0.28\n",
      "disc-loss: 0.28, gan-loss: -0.98\n",
      "disc-loss: 0.28\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.28, gan-loss: -0.98\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.27, gan-loss: -1.30\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.27, gan-loss: -1.00\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.27\n",
      "disc-loss: 0.27, gan-loss: -1.14\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26, gan-loss: -0.97\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26, gan-loss: -1.21\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26, gan-loss: -0.98\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.26, gan-loss: -0.91\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.25, gan-loss: -1.22\n",
      "disc-loss: 0.26\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.26, gan-loss: -1.09\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.25, gan-loss: -1.29\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.25, gan-loss: -1.09\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.25, gan-loss: -1.14\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24, gan-loss: -1.18\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24, gan-loss: -1.01\n",
      "disc-loss: 0.25\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.25, gan-loss: -1.44\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24, gan-loss: -0.90\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24, gan-loss: -1.19\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.24\n",
      "disc-loss: 0.23, gan-loss: -0.93\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23, gan-loss: -1.18\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23, gan-loss: -1.06\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23, gan-loss: -1.45\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23, gan-loss: -0.84\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.23, gan-loss: -1.17\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.23, gan-loss: -1.43\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22, gan-loss: -1.22\n",
      "disc-loss: 0.23\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22, gan-loss: -1.60\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22, gan-loss: -1.69\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22, gan-loss: -0.94\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.22, gan-loss: -1.74\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21, gan-loss: -0.92\n",
      "disc-loss: 0.22\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21, gan-loss: -1.13\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21, gan-loss: -1.31\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21, gan-loss: -0.66\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.20, gan-loss: -1.65\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -1.02\n",
      "disc-loss: 0.21\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -0.56\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -0.99\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -1.77\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -1.30\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -1.30\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20, gan-loss: -1.61\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.19, gan-loss: -1.26\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.20, gan-loss: -1.20\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19, gan-loss: -1.45\n",
      "disc-loss: 0.20\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19, gan-loss: -1.50\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19, gan-loss: -0.99\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19, gan-loss: -1.36\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19, gan-loss: -0.68\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.19, gan-loss: -0.87\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.18\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.56\n",
      "disc-loss: 0.19\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.11\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -0.95\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.31\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -0.98\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.31\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.63\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.46\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.18, gan-loss: -1.76\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.18, gan-loss: -0.82\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.18, gan-loss: -1.27\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.41\n",
      "disc-loss: 0.18\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.19\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.55\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.21\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.10\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.65\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.58\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.17, gan-loss: -1.14\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -2.05\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.17, gan-loss: -1.79\n",
      "disc-loss: 0.17\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -1.72\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -1.80\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -1.29\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -1.18\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -0.99\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -1.39\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.16, gan-loss: -2.01\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.16, gan-loss: -0.66\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -2.14\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.88\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.16, gan-loss: -1.39\n",
      "disc-loss: 0.16\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.24\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.00\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.55\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.83\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.09\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.50\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.13\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15, gan-loss: -1.83\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -1.31\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.14, gan-loss: -1.31\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.88\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.86\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.96\n",
      "disc-loss: 0.15\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.15, gan-loss: -1.00\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.54\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.65\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -2.05\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.76\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.69\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -1.26\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -0.93\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -1.04\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -1.74\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.14, gan-loss: -0.89\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -2.57\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.14, gan-loss: -1.76\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -2.09\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.14, gan-loss: -1.21\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.14, gan-loss: -1.98\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.13\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.14, gan-loss: -1.25\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.14, gan-loss: -1.28\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.80\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.31\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.16\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -2.72\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.16\n",
      "disc-loss: 0.14\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -2.51\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -2.42\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.49\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.48\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -2.35\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -2.56\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -2.59\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.28\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.13, gan-loss: -1.30\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.12\n",
      "disc-loss: 0.13, gan-loss: -2.33\n",
      "disc-loss: 0.13\n",
      "disc-loss: 0.12\n",
      "disc-loss: 0.13, gan-loss: -2.82\n",
      "disc-loss: 0.13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3884/43395854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mleadfield\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3884/1692472461.py\u001b[0m in \u001b[0;36mgenerate_samples\u001b[1;34m(g_model, batch_size, latent_dim)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mx_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0msources\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msources\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1976\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1978\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1979\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1980\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[1;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m             \"not be specified.\")\n\u001b[1;32m--> 755\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m         \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3313\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3314\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3315\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3316\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "n_epochs = 1000\n",
    "batch_size = 2048\n",
    "latent_dim = 300\n",
    "hidden_units = 300\n",
    "\n",
    "gen_mod = 3\n",
    "g_model, d_model, gan_model = define_models(latent_dim, hidden_units=hidden_units)\n",
    "\n",
    "for i in tqdm(range(n_epochs)):\n",
    "    y = generate_samples(g_model, batch_size, latent_dim)\n",
    "    X = (leadfield @ y.T).T\n",
    "    X, y = prep_data(X,y)\n",
    "    d_model.trainable = True\n",
    "    d_loss = d_model.train_on_batch(X, y)\n",
    "    if i % gen_mod == 0:    \n",
    "        x_input = np.random.randn(batch_size, latent_dim)\n",
    "        X = np.zeros((batch_size, n_dipoles))\n",
    "        d_model.trainable = False\n",
    "        gan_loss = gan_model.train_on_batch(x_input, X)[0]\n",
    "        print(f'disc-loss: {d_loss:.2f}, gan-loss: {gan_loss:.2f}')\n",
    "    else:\n",
    "        print(f'disc-loss: {d_loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 11.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2005.88it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 111.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.26, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2\n",
    "# settings = dict(duration_of_trial=0.1, extents=(1,40), number_of_sources=(1,15), target_snr=(2, 15))\n",
    "settings = dict(duration_of_trial=0.1, extents=25, number_of_sources=20, target_snr=1e99)\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "def prep_data_sim(sim):\n",
    "    X = np.squeeze(np.stack([eeg.average().data for eeg in sim.eeg_data]))\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.squeeze(np.stack([src.data for src in sim.source_data]))\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        X = np.expand_dims(X, axis=-1)\n",
    "        y = np.expand_dims(y, axis=-1)\n",
    "    X = np.swapaxes(X, 1,2)\n",
    "    y = np.swapaxes(y, 1,2)\n",
    "    return X, y\n",
    "X, y = prep_data_sim(sim_test)\n",
    "\n",
    "y_hat = d_model.predict(X)\n",
    "y_hat.shape\n",
    "stc = sim_test.source_data[0]\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "stc_hat = stc.copy()\n",
    "stc_hat.data = y_hat[0].T\n",
    "stc_hat.plot(**plot_params)\n",
    "from scipy.stats import pearsonr\n",
    "r,p = pearsonr(stc.data.flatten(), stc_hat.data.flatten())\n",
    "print(f'r={r:.2f}, p={p:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=0.86, p=0.0000\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "\n",
    "# generated data:\n",
    "y = generate_samples(g_model, batch_size, latent_dim).T\n",
    "\n",
    "\n",
    "\n",
    "X = (leadfield @ y).T\n",
    "X, y = prep_data(X,y)\n",
    "\n",
    "stc_hat.data = y[:, 0, :]\n",
    "stc_hat.plot(**plot_params)\n",
    "\n",
    "y_hat = d_model.predict(X)\n",
    "\n",
    "stc_hat.data = y_hat[:, 0, :].T\n",
    "stc_hat.plot(**plot_params)\n",
    "\n",
    "r,p = pearsonr(y[:, 0, :].flatten(), y_hat[:, 0, :].T.flatten())\n",
    "print(f'r={r:.2f}, p={p:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FC\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, None, 61)]        0         \n",
      "                                                                 \n",
      " FC1 (TimeDistributed)       (None, None, 600)         37200     \n",
      "                                                                 \n",
      " FC2 (TimeDistributed)       (None, None, 1284)        771684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 808,884\n",
      "Trainable params: 808,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "399/399 [==============================] - 3s 7ms/step - loss: -0.2897 - val_loss: -0.3501\n",
      "Epoch 2/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3597 - val_loss: -0.3755\n",
      "Epoch 3/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3755 - val_loss: -0.3851\n",
      "Epoch 4/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3838 - val_loss: -0.3929\n",
      "Epoch 5/30\n",
      "399/399 [==============================] - 3s 7ms/step - loss: -0.3891 - val_loss: -0.3957\n",
      "Epoch 6/30\n",
      "399/399 [==============================] - 3s 9ms/step - loss: -0.3919 - val_loss: -0.3976\n",
      "Epoch 7/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3945 - val_loss: -0.4006\n",
      "Epoch 8/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3963 - val_loss: -0.4019\n",
      "Epoch 9/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3981 - val_loss: -0.4027\n",
      "Epoch 10/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3995 - val_loss: -0.4015\n",
      "Epoch 11/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4009 - val_loss: -0.4062\n",
      "Epoch 12/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4028 - val_loss: -0.4079\n",
      "Epoch 13/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4048 - val_loss: -0.4102\n",
      "Epoch 14/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4067 - val_loss: -0.4104\n",
      "Epoch 15/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4074 - val_loss: -0.4125\n",
      "Epoch 16/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4086 - val_loss: -0.4131\n",
      "Epoch 17/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4098 - val_loss: -0.4152\n",
      "Epoch 18/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4110 - val_loss: -0.4156\n",
      "Epoch 19/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4118 - val_loss: -0.4169\n",
      "Epoch 20/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4127 - val_loss: -0.4180\n",
      "Epoch 21/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4135 - val_loss: -0.4190\n",
      "Epoch 22/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4144 - val_loss: -0.4183\n",
      "Epoch 23/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4151 - val_loss: -0.4198\n",
      "Epoch 24/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4164 - val_loss: -0.4206\n",
      "Epoch 25/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4172 - val_loss: -0.4217\n",
      "Epoch 26/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4181 - val_loss: -0.4204\n",
      "Epoch 27/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4191 - val_loss: -0.4221\n",
      "Epoch 28/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4200 - val_loss: -0.4212\n",
      "Epoch 29/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4210 - val_loss: -0.4251\n",
      "Epoch 30/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4219 - val_loss: -0.4269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164150f4d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, GRU, multiply, Activation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from esinet.losses import nmae_loss\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, n_dipoles = leadfield.shape\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 600\n",
    "n_lstm_units = 30\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"linear\"),\n",
    "            name='FC2')(fc1)\n",
    "\n",
    "\n",
    "model3 = tf.keras.Model(inputs=inputs, outputs=direct_out, name='FC')\n",
    "\n",
    "\n",
    "model3.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "\n",
    "model3.summary()\n",
    "model3.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a54b85cbc80ea8362b8e45e33618627fd9167210ff2c52e6dbeaf85afe35b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

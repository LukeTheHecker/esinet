{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: How simulations define your predictions\n",
    "The inverse problem has no unique solution as it is ill-posed. In order to solve it we need to constraint the space of possible solutions. While inverse solutions like minimum-norm estimates have an explicit constraint of minimum-energy, the constraints with esinet are implicit and mostly shaped by the simulations.\n",
    "\n",
    "This tutorial aims the relation between simulation parameters and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)\n",
    "norm_inequality = lambda x: np.linalg.norm(x) / np.mean(abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C:\\Users\\Lukas\\Documents\\teaching\\python_eeg\\data\\Faces_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 242919  =      0.000 ...   242.919 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp/ipykernel_2008/1065152922.py:3: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.01 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.01\n",
      "- Lower transition bandwidth: 0.01 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 330001 samples (330.001 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp/ipykernel_2008/1065152922.py:4: RuntimeWarning: filter_length (330001) is longer than the signal (242920), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  raw.filter(0.01, 45)\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# info = get_info(sfreq=100)\n",
    "path = r\"C:\\Users\\Lukas\\Documents\\teaching\\python_eeg\\data\\Faces_01.vhdr\"\n",
    "raw = mne.io.read_raw_brainvision(path, preload=True)\n",
    "raw.filter(0.01, 45)\n",
    "info = raw.info\n",
    "fwd = create_forward_model(sampling=\"ico3\", info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:42<00:00, 47.13it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 22531.97it/s]\n",
      "100%|██████████| 2000/2000 [00:02<00:00, 695.68it/s]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2000\n",
    "settings = dict(duration_of_trial=0., number_of_sources=(1, 200), extents=(1, 50), method=\"standard\", source_number_weighting=False)\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62268915, 0.66332587, 0.69202343, 0.14276345, 0.81043617,\n",
       "       0.10908636, 0.88111399, 0.91159316, 0.85061939, 0.87805348])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.squeeze(np.stack([eeg.average().data for eeg in sim.eeg_data]))\n",
    "X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "# y = np.array([extent[0] for extent in sim.simulation_info.extents.values])\n",
    "# y = np.array([extent for extent in sim.simulation_info.beta_source.values])\n",
    "y = np.array([norm_inequality(stc.data[:, 0]) for stc in sim.source_data])\n",
    "y = 1/y**2\n",
    "scaler_value = y.max()\n",
    "y /= scaler_value\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot extreme samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1ed1aed8c70>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.     0.     0.3585]\n"
     ]
    }
   ],
   "source": [
    "number_of_sources = sim.simulation_info.number_of_sources.values\n",
    "\n",
    "idx = np.argmin(y)\n",
    "stc = sim.source_data[idx].copy()\n",
    "stc.data /= abs(stc.data[:, 0]).max()\n",
    "stc.plot(**plot_params, brain_kwargs=dict(title=\"Sparsest\"))\n",
    "\n",
    "idx = np.argmax(y)\n",
    "stc = sim.source_data[idx].copy()\n",
    "stc.data /= abs(stc.data[:, 0]).max()\n",
    "stc.plot(**plot_params, brain_kwargs=dict(title=\"Non-Sparsest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, None, 300)         9600      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, None, 300)         90300     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, None, 1)           301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,201\n",
      "Trainable params: 100,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 31), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 31).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 31), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 31).\n",
      "44/54 [=======================>......] - ETA: 0s - loss: 0.2989WARNING:tensorflow:Model was constructed with shape (None, None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 31), dtype=tf.float32, name='dense_15_input'), name='dense_15_input', description=\"created by layer 'dense_15_input'\"), but it was called on an input with incompatible shape (None, 31).\n",
      "54/54 [==============================] - 2s 8ms/step - loss: 0.2584 - val_loss: 0.0753\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0664 - val_loss: 0.0896\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0821 - val_loss: 0.0939\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0804 - val_loss: 0.0771\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0719 - val_loss: 0.0757\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0723 - val_loss: 0.0837\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0651 - val_loss: 0.0645\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0669 - val_loss: 0.1254\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0802 - val_loss: 0.0811\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0632 - val_loss: 0.0690\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0605 - val_loss: 0.0678\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0624 - val_loss: 0.0788\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0653 - val_loss: 0.0780\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0610 - val_loss: 0.0609\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0596 - val_loss: 0.0605\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0560 - val_loss: 0.0689\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0563 - val_loss: 0.0633\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0554 - val_loss: 0.0660\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0561 - val_loss: 0.0564\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0569 - val_loss: 0.0573\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0543 - val_loss: 0.0594\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0532 - val_loss: 0.0715\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0592 - val_loss: 0.0579\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0525 - val_loss: 0.0716\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0523 - val_loss: 0.0598\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0545 - val_loss: 0.0587\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0498 - val_loss: 0.0629\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0474 - val_loss: 0.0664\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0531 - val_loss: 0.0609\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0513 - val_loss: 0.0603\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0517 - val_loss: 0.0586\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0470 - val_loss: 0.0636\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0483 - val_loss: 0.0588\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0498 - val_loss: 0.0622\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0482 - val_loss: 0.0584\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.0614\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0449 - val_loss: 0.0654\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0458 - val_loss: 0.0615\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0463 - val_loss: 0.0643\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0454 - val_loss: 0.0664\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0446 - val_loss: 0.0650\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0456 - val_loss: 0.0653\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0428 - val_loss: 0.0636\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0421 - val_loss: 0.0617\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0410 - val_loss: 0.0632\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0424 - val_loss: 0.0654\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0423 - val_loss: 0.0626\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0393 - val_loss: 0.0617\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0401 - val_loss: 0.0619\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0385 - val_loss: 0.0569\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0373 - val_loss: 0.0660\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.0376 - val_loss: 0.0636\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0404 - val_loss: 0.0654\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0380 - val_loss: 0.0638\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0370 - val_loss: 0.0659\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0373 - val_loss: 0.0641\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0711\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0388 - val_loss: 0.0646\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0349 - val_loss: 0.0622\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0352 - val_loss: 0.0659\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0340 - val_loss: 0.0654\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0335 - val_loss: 0.0655\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0623\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0308 - val_loss: 0.0617\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0325 - val_loss: 0.0695\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0311 - val_loss: 0.0632\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0292 - val_loss: 0.0632\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0291 - val_loss: 0.0658\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0340 - val_loss: 0.0684\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0645\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0640\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0630\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0271 - val_loss: 0.0702\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0648\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0257 - val_loss: 0.0682\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0257 - val_loss: 0.0709\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0260 - val_loss: 0.0739\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0711\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0224 - val_loss: 0.0762\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0230 - val_loss: 0.0691\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.0687\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0690\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.0690\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0210 - val_loss: 0.0713\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0712\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0776\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.0749\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0749\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0752\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0778\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0771\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0747\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0788\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0760\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0783\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0809\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.0141 - val_loss: 0.0795\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0871\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0804\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed7b416fd0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, n_dipoles = leadfield.shape\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 300\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(units=n_dense_units, activation=activation_function))\n",
    "model.add(Dense(units=n_dense_units, activation=activation_function))\n",
    "# model.add(Dense(units=n_dense_units, activation=activation_function))\n",
    "\n",
    "# Add output layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Build model with input layer\n",
    "model.build(input_shape=input_shape)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'r=0.16, p=0.1086')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 100\n",
    "# settings = dict(duration_of_trial=0., number_of_sources=1, method=\"noise\")\n",
    "# settings = dict(duration_of_trial=0., method=\"standard\")\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "\n",
    "X_test = np.squeeze(np.stack([eeg.average().data for eeg in sim_test.eeg_data]))\n",
    "X_test = np.stack([(x - np.mean(x)) / np.std(x) for x in X_test], axis=0)\n",
    "y_test = np.array([norm_inequality(stc.data[:, 0]) for stc in sim_test.source_data])\n",
    "y_test = np.log(y_test)\n",
    "# y_test = np.array([extent for extent in sim_test.simulation_info.beta_source.values])\n",
    "# y_test = np.array([extent[0] for extent in sim_test.simulation_info.extents.values])\n",
    "# y_test = np.array([extent for extent in sim_test.simulation_info.number_of_sources.values])\n",
    "\n",
    "y_pred = model.predict(X_test)[:, 0]\n",
    "y_pred = 1/y_pred**2\n",
    "\n",
    "%matplotlib qt\n",
    "import seaborn as sns\n",
    "plt.figure()\n",
    "# plt.scatter(y_test, y_pred)\n",
    "sns.regplot(x=y_test, y=y_pred*5)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "# plt.ylim(-0.3, 1)\n",
    "# plt.xlim(-0.3, 1)\n",
    "r, p = pearsonr(y_test, y_pred)\n",
    "plt.title(f\"r={r:.2f}, p={p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 0.69, sd = 0.30\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "X_eval = raw._data\n",
    "X_eval = np.stack([(xx-xx.mean()) / xx.std() for xx in X_eval.T], axis=0)\n",
    "y_pred = model.predict(X_eval)\n",
    "\n",
    "# m = y_pred.mean()\n",
    "m = np.median(y_pred)\n",
    "\n",
    "sd = y_pred.std()\n",
    "\n",
    "sns.displot(data=y_pred[:1000])\n",
    "print(f\"m = {m:.2f}, sd = {sd:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 14', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "m = 0.65, sd = 0.22\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "events = mne.events_from_annotations(raw)[0]\n",
    "epochs = mne.Epochs(raw, events, event_id=13)\n",
    "evoked = epochs.average()\n",
    "evoked.plot_joint()\n",
    "\n",
    "X_eval = evoked.data\n",
    "X_eval = np.stack([(xx-xx.mean()) / xx.std() for xx in X_eval.T], axis=0)\n",
    "y_pred = model.predict(X_eval)\n",
    "# y_pred = 1/y_pred**2\n",
    "\n",
    "# m = y_pred.mean()\n",
    "m = np.median(y_pred)\n",
    "\n",
    "sd = y_pred.std()\n",
    "sns.displot(data=y, label=\"Training Data\")\n",
    "sns.displot(data=y_pred, label=\"Obs. Data\")\n",
    "plt.legend()\n",
    "print(f\"m = {m:.2f}, sd = {sd:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval sim evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 250.67it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Value: 0.9310\n",
      "m = 0.64, sd = 0.17\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2\n",
    "# settings = dict(duration_of_trial=0., number_of_sources=1, method=\"noise\")\n",
    "# settings = dict(duration_of_trial=0., method=\"standard\")\n",
    "settings = dict(duration_of_trial=1., number_of_sources=200, extents=50, method=\"standard\", target_snr=1e99)\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "# true_value = 1/norm_inequality()**2\n",
    "true_values = 1/np.array([norm_inequality(src) for src in sim_test.source_data[0].data.T])**2\n",
    "true_value = np.median(true_values / scaler_value)\n",
    "X_test = sim_test.eeg_data[0].average().data\n",
    "X_test = np.stack([(xx-xx.mean()) / xx.std() for xx in X_test.T], axis=0)\n",
    "\n",
    "y_pred = model.predict(X_test)[:, 0]\n",
    "\n",
    "m = np.median(y_pred)\n",
    "\n",
    "sd = y_pred.std()\n",
    "\n",
    "sns.displot(data=y_pred)\n",
    "print(f\"True Value: {true_value:.4f}\")\n",
    "print(f\"m = {m:.2f}, sd = {sd:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1ed4aa86070>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.37777106 0.40138    0.69409963]\n"
     ]
    }
   ],
   "source": [
    "stc = sim_test.source_data[0]\n",
    "stc.data /= abs(stc.data).max()\n",
    "stc.plot(**plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9587d79750f5d7fc5c0560e15a7a8a49dff11015373bda407c2fe4ab31d0fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: How simulations define your predictions\n",
    "The inverse problem has no unique solution as it is ill-posed. In order to solve it we need to constraint the space of possible solutions. While inverse solutions like minimum-norm estimates have an explicit constraint of minimum-energy, the constraints with esinet are implicit and mostly shaped by the simulations.\n",
    "\n",
    "This tutorial aims the relation between simulation parameters and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "# import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    1.1s remaining:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(sfreq=100)\n",
    "fwd = create_forward_model(info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate\n",
    "Next, we simulate two types of data: \n",
    "1. Data containing small sources with 15-25 mm in diameter.\n",
    "2. Data containing large sources with 35-45 mm in diameter.\n",
    "\n",
    "Note, that for publication-ready inverse solutions you should increase the number of training samples to 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:38<00:00, 101.84it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4746.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 50) (1284, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:44<00:00, 95.33it/s]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "settings = dict(duration_of_trial=0.5)\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visualize the two types of simulations\n",
    "The two brain plots should now look quite different, as one contains large and extended sources while the other contains tiny point-like sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "brain = sim.source_data[idx].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Sample', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train individual neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess data\n",
      "werks3\n",
      "Model: \"Contextualizer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, None, 61)]   0           []                               \n",
      "                                                                                                  \n",
      " FC1 (TimeDistributed)          (None, None, 200)    12400       ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, None, 200)    0           ['FC1[0][0]']                    \n",
      "                                                                                                  \n",
      " LSTM1 (Bidirectional)          (None, None, 64)     44928       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " FC2 (TimeDistributed)          (None, None, 1284)   258084      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " Mask (TimeDistributed)         (None, None, 1284)   83460       ['LSTM1[0][0]']                  \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, None, 1284)   0           ['FC2[0][0]',                    \n",
      "                                                                  'Mask[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 398,872\n",
      "Trainable params: 398,872\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "fit model\n",
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 26s 17ms/step - loss: -0.3652 - mae: 0.0658 - val_loss: -0.4228 - val_mae: 0.0677\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 19s 14ms/step - loss: -0.4513 - mae: 0.0623 - val_loss: -0.4637 - val_mae: 0.0523\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 20s 14ms/step - loss: -0.4879 - mae: 0.0463 - val_loss: -0.4873 - val_mae: 0.0394\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 20s 13ms/step - loss: -0.5067 - mae: 0.0412 - val_loss: -0.4963 - val_mae: 0.0378\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 20s 13ms/step - loss: -0.5190 - mae: 0.0391 - val_loss: -0.5068 - val_mae: 0.0368\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 20s 14ms/step - loss: -0.5270 - mae: 0.0381 - val_loss: -0.5068 - val_mae: 0.0410\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 20s 14ms/step - loss: -0.5335 - mae: 0.0377 - val_loss: -0.5112 - val_mae: 0.0349\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 20s 13ms/step - loss: -0.5387 - mae: 0.0369 - val_loss: -0.5135 - val_mae: 0.0352\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 21s 14ms/step - loss: -0.5428 - mae: 0.0370 - val_loss: -0.5135 - val_mae: 0.0349\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 25s 18ms/step - loss: -0.5470 - mae: 0.0362 - val_loss: -0.5163 - val_mae: 0.0324\n",
      "preprocess data\n",
      "wrks4\n",
      "Model: \"FC-model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " FC_0 (TimeDistributed)      (None, None, 200)         12400     \n",
      "                                                                 \n",
      " Drop_0 (Dropout)            (None, None, 200)         0         \n",
      "                                                                 \n",
      " FC_Out (TimeDistributed)    (None, None, 1284)        258084    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,484\n",
      "Trainable params: 270,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fit model\n",
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 15s 11ms/step - loss: -0.3482 - mae: 0.1132 - val_loss: -0.3795 - val_mae: 0.1125\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 16s 8ms/step - loss: -0.3837 - mae: 0.1282 - val_loss: -0.3855 - val_mae: 0.1319\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 13s 7ms/step - loss: -0.3879 - mae: 0.1500 - val_loss: -0.3867 - val_mae: 0.1533\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 16s 9ms/step - loss: -0.3895 - mae: 0.1718 - val_loss: -0.3880 - val_mae: 0.1760\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 13s 7ms/step - loss: -0.3907 - mae: 0.1948 - val_loss: -0.3894 - val_mae: 0.1944\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 13s 7ms/step - loss: -0.3914 - mae: 0.2178 - val_loss: -0.3884 - val_mae: 0.2169\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 13s 7ms/step - loss: -0.3917 - mae: 0.2402 - val_loss: -0.3906 - val_mae: 0.2407\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 13s 6ms/step - loss: -0.3922 - mae: 0.2635 - val_loss: -0.3904 - val_mae: 0.2617\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 13s 6ms/step - loss: -0.3924 - mae: 0.2870 - val_loss: -0.3906 - val_mae: 0.2872\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 13s 7ms/step - loss: -0.3930 - mae: 0.3095 - val_loss: -0.3907 - val_mae: 0.3085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<esinet.net.Net at 0x1bd8558c430>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'LSTM'  # can be 'LSTM' or 'ConvDip', too\n",
    "net = Net(fwd, verbose=True, model_type=model_type)\n",
    "net.fit(sim, epochs=10)\n",
    "\n",
    "model_type = 'FC'  # can be 'LSTM' or 'ConvDip', too\n",
    "net_fc = Net(fwd, verbose=True, model_type=model_type)\n",
    "net_fc.fit(sim, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have simulated two different types of source & eeg data and build two neural networks that each was trained on one of these simulations. Lets see how they perform within their own simulation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on 1/f noise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 14.28it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 334.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 50) (1284, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 19.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan sources\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lukas\\Envs\\esienv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:783: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1280 is out of bounds for axis 0 with size 1280",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11776/482575757.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_fwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstc_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"AUC = {auc:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11776/482575757.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_fwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstc_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"AUC = {auc:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Documents\\projects\\esinet\\dev\\..\\esinet\\evaluate\\evaluate.py\u001b[0m in \u001b[0;36meval_auc\u001b[1;34m(y_true, y_est, pos, n_redraw, epsilon, plot_me)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;31m# print(f'\\tprep took {1000*(t_prep-t_start):.1f} ms')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m     \u001b[0mdistSortedIndices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_indices_close_to_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;31m# t_prep2 = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lukas\\Documents\\projects\\esinet\\dev\\..\\esinet\\evaluate\\evaluate.py\u001b[0m in \u001b[0;36mfind_indices_close_to_source\u001b[1;34m(source_mask, pos)\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[0mnumberOfNans\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m             \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msourceIndices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m             \u001b[0mmin_distance_to_source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1280 is out of bounds for axis 0 with size 1280"
     ]
    }
   ],
   "source": [
    "# Simulate some new, unseen test data    \n",
    "n_test_samples = 2\n",
    "settings[\"target_snr\"] = 50\n",
    "settings[\"extents\"] = (1,40)\n",
    "settings[\"number_of_sources\"] = 3\n",
    "settings[\"method\"] = \"noise\"\n",
    "settings[\"beta\"] = 5\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_test_samples)\n",
    "n = sim_test.simulation_info[\"number_of_sources\"].values[0]\n",
    "print(f\"{n} sources\")\n",
    "\n",
    "stc = sim_test.source_data[0]\n",
    "brain = stc.plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth of small data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "stc_hat = net.predict(sim_test)[0]\n",
    "brain = stc_hat.plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title',\n",
    "               font_size=14)\n",
    "from esinet.evaluate import eval_auc\n",
    "import numpy as np\n",
    "pos = util.unpack_fwd(fwd)[3]\n",
    "auc = np.mean([eval_auc(y_true, y_est, pos) for y_true, y_est in zip(stc.data.T, stc_hat.data.T)])\n",
    "print(f\"AUC = {auc:.2f}\")\n",
    "\n",
    "stc_hat = net_fc.predict(sim_test)[0]\n",
    "brain = stc_hat.plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title',\n",
    "               font_size=14)\n",
    "from esinet.evaluate import eval_auc\n",
    "import numpy as np\n",
    "pos = util.unpack_fwd(fwd)[3]\n",
    "auc = np.mean([eval_auc(y_true, y_est, pos) for y_true, y_est in zip(stc.data.T, stc_hat.data.T)])\n",
    "print(f\"AUC = {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the large-net to predict the small simulation and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = sim_test_small.source_data[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth of small data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "\n",
    "brain = net_large.predict(sim_test_small)[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Large-Net on small data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "\n",
    "\n",
    "brain = sim_test_large.source_data[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth of large data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "\n",
    "brain = net_small.predict(sim_test_large)[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Small-Net on large data', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find that the Net which was trained on large simulations always tends to find large sources - even when confronted with data in which small sources were active. \n",
    "\n",
    "Conversely, the Net which was trained on simulations that contain small sources finds sparse sources when confronted with data containing large-source activity.\n",
    "\n",
    "This demonstrates that our simulation settings function like priors. Further, it emphasizes the importance to state your priors and to motivate your choice.\n",
    "\n",
    "In many cases we can't make a choice and we want to make as few assumptions into our models as possible. In this case we propose that you use large ranges in your settings to maximize the diversity of your training data.\n",
    "\n",
    "A sample of a diverse setting is given in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'number_of_sources': (1, 20),  # The range of simultaneously active sources.\n",
    "    'extents': (1, 50),  # The range of source diameters in mm \n",
    "    'amplitudes': (1, 100),  # Defines the range of amplitudes (in arbitrary units)\n",
    "    'shapes': 'both',  # Simulate both gaussian-shaped and flat sources\n",
    "    'beta': (0, 3),  # Defines the distribution of the noise in terms of 1/f**beta\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9587d79750f5d7fc5c0560e15a7a8a49dff11015373bda407c2fe4ab31d0fe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

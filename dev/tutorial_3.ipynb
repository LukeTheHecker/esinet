{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: How simulations define your predictions\n",
    "The inverse problem has no unique solution as it is ill-posed. In order to solve it we need to constraint the space of possible solutions. While inverse solutions like minimum-norm estimates have an explicit constraint of minimum-energy, the constraints with esinet are implicit and mostly shaped by the simulations.\n",
    "\n",
    "This tutorial aims the relation between simulation parameters and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "# import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    1.5s remaining:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    1.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(sfreq=100)\n",
    "fwd = create_forward_model(info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate\n",
    "Next, we simulate two types of data: \n",
    "1. Data containing small sources with 15-25 mm in diameter.\n",
    "2. Data containing large sources with 35-45 mm in diameter.\n",
    "\n",
    "Note, that for publication-ready inverse solutions you should increase the number of training samples to 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:49<00:00, 200.97it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 16941.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 25) (1284, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:29<00:00, 336.13it/s]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "settings = dict(duration_of_trial=0.25)\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visualize the two types of simulations\n",
    "The two brain plots should now look quite different, as one contains large and extended sources while the other contains tiny point-like sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "brain = sim.source_data[idx].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Sample', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train individual neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess data\n",
      "werks3\n",
      "Model: \"Contextualizer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FC1 (TimeDistributed)           (None, None, 200)    12400       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 200)    0           FC1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (Bidirectional)           (None, None, 64)     44928       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FC2 (TimeDistributed)           (None, None, 1284)   258084      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Mask (TimeDistributed)          (None, None, 1284)   83460       LSTM1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 1284)   0           FC2[0][0]                        \n",
      "                                                                 Mask[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 398,872\n",
      "Trainable params: 398,872\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "fit model\n",
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 49s 39ms/step - loss: -0.3659 - mae: 0.0658 - val_loss: -0.4363 - val_mae: 0.0645\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 45s 39ms/step - loss: -0.4556 - mae: 0.0573 - val_loss: -0.4759 - val_mae: 0.0444\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 43s 37ms/step - loss: -0.4871 - mae: 0.0451 - val_loss: -0.4900 - val_mae: 0.0460\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 43s 37ms/step - loss: -0.5028 - mae: 0.0412 - val_loss: -0.5006 - val_mae: 0.0416\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 40s 34ms/step - loss: -0.5128 - mae: 0.0399 - val_loss: -0.5068 - val_mae: 0.0361\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 42s 37ms/step - loss: -0.5207 - mae: 0.0388 - val_loss: -0.5135 - val_mae: 0.0419\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 41s 35ms/step - loss: -0.5267 - mae: 0.0381 - val_loss: -0.5122 - val_mae: 0.0371\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 43s 37ms/step - loss: -0.5319 - mae: 0.0367 - val_loss: -0.5192 - val_mae: 0.0364\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 42s 36ms/step - loss: -0.5360 - mae: 0.0363 - val_loss: -0.5195 - val_mae: 0.0398\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 44s 38ms/step - loss: -0.5399 - mae: 0.0359 - val_loss: -0.5205 - val_mae: 0.0349\n",
      "preprocess data\n",
      "wrks4\n",
      "Model: \"FC-model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "FC_0 (TimeDistributed)       (None, None, 200)         12400     \n",
      "_________________________________________________________________\n",
      "Drop_0 (Dropout)             (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "FC_Out (TimeDistributed)     (None, None, 1284)        258084    \n",
      "=================================================================\n",
      "Total params: 270,484\n",
      "Trainable params: 270,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "fit model\n",
      "Epoch 1/10\n",
      "1125/1125 [==============================] - 20s 17ms/step - loss: -0.3414 - mae: 0.1161 - val_loss: -0.3820 - val_mae: 0.1162\n",
      "Epoch 2/10\n",
      "1125/1125 [==============================] - 24s 20ms/step - loss: -0.3780 - mae: 0.1313 - val_loss: -0.3887 - val_mae: 0.1344\n",
      "Epoch 3/10\n",
      "1125/1125 [==============================] - 23s 18ms/step - loss: -0.3820 - mae: 0.1530 - val_loss: -0.3910 - val_mae: 0.1585\n",
      "Epoch 4/10\n",
      "1125/1125 [==============================] - 26s 21ms/step - loss: -0.3839 - mae: 0.1756 - val_loss: -0.3931 - val_mae: 0.1757\n",
      "Epoch 5/10\n",
      "1125/1125 [==============================] - 26s 21ms/step - loss: -0.3848 - mae: 0.1981 - val_loss: -0.3922 - val_mae: 0.2024\n",
      "Epoch 6/10\n",
      "1125/1125 [==============================] - 24s 19ms/step - loss: -0.3855 - mae: 0.2213 - val_loss: -0.3915 - val_mae: 0.2231\n",
      "Epoch 7/10\n",
      "1125/1125 [==============================] - 22s 18ms/step - loss: -0.3862 - mae: 0.2446 - val_loss: -0.3926 - val_mae: 0.2516\n",
      "Epoch 8/10\n",
      "1125/1125 [==============================] - 25s 20ms/step - loss: -0.3867 - mae: 0.2685 - val_loss: -0.3945 - val_mae: 0.2700\n",
      "Epoch 9/10\n",
      "1125/1125 [==============================] - 23s 18ms/step - loss: -0.3870 - mae: 0.2920 - val_loss: -0.3950 - val_mae: 0.2868\n",
      "Epoch 10/10\n",
      "1125/1125 [==============================] - 23s 18ms/step - loss: -0.3873 - mae: 0.3147 - val_loss: -0.3947 - val_mae: 0.3158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<esinet.net.Net at 0x1d1ed6f8880>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'LSTM'  # can be 'LSTM' or 'ConvDip', too\n",
    "net = Net(fwd, verbose=True, model_type=model_type)\n",
    "net.fit(sim, epochs=10)\n",
    "\n",
    "model_type = 'FC'  # can be 'LSTM' or 'ConvDip', too\n",
    "net_fc = Net(fwd, verbose=True, model_type=model_type)\n",
    "net_fc.fit(sim, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have simulated two different types of source & eeg data and build two neural networks that each was trained on one of these simulations. Lets see how they perform within their own simulation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.77it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1001.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 25) (1284, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 222.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 sources\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:783: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n",
      "c:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:783: RuntimeWarning: Method 'bounded' does not support relative tolerance in x; defaulting to absolute tolerance.\n",
      "  warn(\"Method 'bounded' does not support relative tolerance in x; \"\n"
     ]
    }
   ],
   "source": [
    "# Simulate some new, unseen test data    \n",
    "n_test_samples = 2\n",
    "# settings[\"target_snr\"] = 50\n",
    "# settings[\"extents\"] = (1,40)\n",
    "# settings[\"number_of_sources\"] = 3\n",
    "# settings[\"method\"] = \"noise\"\n",
    "# settings[\"beta\"] = 5\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_test_samples)\n",
    "n = sim_test.simulation_info[\"number_of_sources\"].values[0]\n",
    "print(f\"{n} sources\")\n",
    "\n",
    "stc = sim_test.source_data[0]\n",
    "brain = stc.plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth of small data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "stc_hat = net.predict(sim_test)[0]\n",
    "stc_hat.data /= np.max(abs(stc_hat.data))\n",
    "brain = stc_hat.plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'LSTM', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "stc_hat = net_fc.predict(sim_test)[0]\n",
    "stc_hat.data /= np.max(abs(stc_hat.data))\n",
    "brain = stc_hat.plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'FC', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "# from esinet.evaluate import eval_auc\n",
    "# import numpy as np\n",
    "# pos = util.unpack_fwd(fwd)[3]\n",
    "# auc = np.mean([eval_auc(y_true, y_est, pos) for y_true, y_est in zip(stc.data.T, stc_hat.data.T)])\n",
    "# print(f\"AUC = {auc:.2f}\")\n",
    "\n",
    "# stc_hat = net_fc.predict(sim_test)[0]\n",
    "# brain = stc_hat.plot(**plot_params)\n",
    "# brain.add_text(0.1, 0.9, 'LSTM', 'title',\n",
    "#                font_size=14)\n",
    "# from esinet.evaluate import eval_auc\n",
    "# import numpy as np\n",
    "# pos = util.unpack_fwd(fwd)[3]\n",
    "# auc = np.mean([eval_auc(y_true, y_est, pos) for y_true, y_est in zip(stc.data.T, stc_hat.data.T)])\n",
    "# print(f\"AUC = {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the large-net to predict the small simulation and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = sim_test_small.source_data[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth of small data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "\n",
    "brain = net_large.predict(sim_test_small)[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Large-Net on small data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "\n",
    "\n",
    "brain = sim_test_large.source_data[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Ground Truth of large data', 'title',\n",
    "               font_size=14)\n",
    "\n",
    "\n",
    "brain = net_small.predict(sim_test_large)[0].plot(**plot_params)\n",
    "brain.add_text(0.1, 0.9, 'Small-Net on large data', 'title',\n",
    "               font_size=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now find that the Net which was trained on large simulations always tends to find large sources - even when confronted with data in which small sources were active. \n",
    "\n",
    "Conversely, the Net which was trained on simulations that contain small sources finds sparse sources when confronted with data containing large-source activity.\n",
    "\n",
    "This demonstrates that our simulation settings function like priors. Further, it emphasizes the importance to state your priors and to motivate your choice.\n",
    "\n",
    "In many cases we can't make a choice and we want to make as few assumptions into our models as possible. In this case we propose that you use large ranges in your settings to maximize the diversity of your training data.\n",
    "\n",
    "A sample of a diverse setting is given in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'number_of_sources': (1, 20),  # The range of simultaneously active sources.\n",
    "    'extents': (1, 50),  # The range of source diameters in mm \n",
    "    'amplitudes': (1, 100),  # Defines the range of amplitudes (in arbitrary units)\n",
    "    'shapes': 'both',  # Simulate both gaussian-shaped and flat sources\n",
    "    'beta': (0, 3),  # Defines the distribution of the noise in terms of 1/f**beta\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a54b85cbc80ea8362b8e45e33618627fd9167210ff2c52e6dbeaf85afe35b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: How simulations define your predictions\n",
    "The inverse problem has no unique solution as it is ill-posed. In order to solve it we need to constraint the space of possible solutions. While inverse solutions like minimum-norm estimates have an explicit constraint of minimum-energy, the constraints with esinet are implicit and mostly shaped by the simulations.\n",
    "\n",
    "This tutorial aims the relation between simulation parameters and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import mne\n",
    "# import numpy as np\n",
    "# from copy import deepcopy\n",
    "# import matplotlib.pyplot as plt\n",
    "import sys; sys.path.insert(0, '../')\n",
    "from esinet import util\n",
    "from esinet import Simulation\n",
    "from esinet import Net\n",
    "from esinet.forward import create_forward_model, get_info\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot as plt\n",
    "plot_params = dict(surface='white', hemi='both', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Forward model\n",
    "First we create a template forward model which comes with the esinet package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    1.9s remaining:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    1.9s remaining:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "info = get_info(sfreq=100)\n",
    "fwd = create_forward_model(sampling=\"ico3\", info=info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mne\n",
    "def prep_data(sim):\n",
    "    X = np.squeeze(np.stack([eeg.average().data for eeg in sim.eeg_data]))\n",
    "    X = np.stack([(x - np.mean(x)) / np.std(x) for x in X], axis=0)\n",
    "    y = np.squeeze(np.stack([src.data for src in sim.source_data]))\n",
    "    y = np.stack([(x / np.max(abs(x))) for x in y], axis=0)\n",
    "\n",
    "    if len(X.shape) == 2:\n",
    "        X = np.expand_dims(X, axis=-1)\n",
    "        y = np.expand_dims(y, axis=-1)\n",
    "    X = np.swapaxes(X, 1,2)\n",
    "    y = np.swapaxes(y, 1,2)\n",
    "    return X, y\n",
    "\n",
    "def sparsity(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred)) / K.max(K.square(y_pred))\n",
    "def custom_loss():\n",
    "    def loss(y_true, y_pred):\n",
    "        loss1 = tf.keras.losses.CosineSimilarity()(y_true, y_pred)\n",
    "        loss2 = sparsity(None, y_pred)\n",
    "        return loss1 + loss2 * 1e-3\n",
    "    return loss\n",
    "\n",
    "from esinet.evaluate import auc_metric, eval_auc, eval_nmse, eval_mean_localization_error\n",
    "\n",
    "def eval(y_true, y_hat):\n",
    "    n_samples = y_true.shape[0]\n",
    "    n_time = y_true.shape[1]\n",
    "    aucs = np.zeros((n_samples, n_time))\n",
    "    mles = np.zeros((n_samples, n_time))\n",
    "    nmses = np.zeros((n_samples, n_time))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_time):\n",
    "            aucs[i,j] = np.mean(eval_auc(y_true[i,j], y_hat[i,j], pos))\n",
    "            nmses[i,j] = eval_nmse(y_true[i,j], y_hat[i,j])\n",
    "            mles[i,j] = eval_mean_localization_error(y_true[i,j], y_hat[i,j], pos)\n",
    "\n",
    "    return aucs, nmses, mles\n",
    "\n",
    "def threshold_activation(x):\n",
    "    return tf.cast(x > 0.5, dtype=tf.float32)\n",
    "\n",
    "class Compressor:\n",
    "    ''' Compression using Graph Fourier Transform\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, fwd, k=600):\n",
    "        A = mne.spatial_src_adjacency(fwd[\"src\"], verbose=0).toarray()\n",
    "        D = np.diag(A.sum(axis=0))\n",
    "        L = D-A\n",
    "        U, s, V = np.linalg.svd(L)\n",
    "\n",
    "        self.U = U[:, -k:]\n",
    "        self.s = s[-k:]\n",
    "        self.V = V[:, -k:]\n",
    "        return self\n",
    "        \n",
    "    def encode(self, X):\n",
    "        ''' Encodes a true signal X\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray\n",
    "            True signal\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        X_comp : numpy.ndarray\n",
    "            Compressed signal\n",
    "        '''\n",
    "        X_comp = self.U.T @ X\n",
    "\n",
    "        return X_comp\n",
    "\n",
    "    def decode(self, X_comp):\n",
    "        ''' Decodes a compressed signal X\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.ndarray\n",
    "            Compressed signal\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        X_unfold : numpy.ndarray\n",
    "            Decoded signal\n",
    "        '''\n",
    "        X_unfold = self.U @ X_comp\n",
    "        return X_unfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:20<00:00, 243.63it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 15924.88it/s]\n",
      "100%|██████████| 5000/5000 [01:01<00:00, 81.52it/s]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 5000\n",
    "settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=(2, 15))\n",
    "sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "X, y = prep_data(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp = Compressor()\n",
    "# comp.fit(fwd)\n",
    "# y_comp = np.stack([comp.encode(yy.T).T for yy in y], axis=0)\n",
    "\n",
    "y_comp = y\n",
    "\n",
    "# %matplotlib qt\n",
    "# plt.figure()\n",
    "# plt.imshow(y[0], aspect=y[0].shape[1] / y[0].shape[0])\n",
    "# plt.figure()\n",
    "# plt.imshow(y_comp[0], aspect=y_comp[0].shape[1] / y_comp[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim.eeg_data[0].ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Functional model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"Contextualizer\" was not an Input tensor, it was generated by layer dropout_9.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: dropout_9/Identity:0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input'), name='Input', description=\"created by layer 'Input'\") at layer \"dropout_9\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/3017300113.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m             name='Mask')(lstm1)\n\u001b[0;32m     41\u001b[0m \u001b[0mmulti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdirect_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"multiply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Contextualizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[0;32m    199\u001b[0m         self.inputs, self.outputs)\n\u001b[0;32m    200\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             raise ValueError('Graph disconnected: '\n\u001b[0m\u001b[0;32m    986\u001b[0m                              \u001b[1;34m'cannot obtain value for tensor '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m                              \u001b[1;34m' at layer \"'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\". '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, None, 61), dtype=tf.float32, name='Input'), name='Input', description=\"created by layer 'Input'\") at layer \"dropout_9\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, GRU, multiply, add, Activation, Dropout\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from esinet.losses import nmse_loss, nmae_loss\n",
    "\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, _ = leadfield.shape\n",
    "n_dipoles = y_comp.shape[-1]\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 61\n",
    "n_lstm_units = 32\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.2\n",
    "input_dropout = 0.1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "fc1 = Dropout(dropout)(fc1)\n",
    "\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"linear\"),\n",
    "            name='FC2')(fc1)\n",
    "\n",
    "lstm1 = Bidirectional(GRU(n_lstm_units, return_sequences=True, \n",
    "            input_shape=(None, n_dense_units), dropout=dropout), \n",
    "            name='LSTM1')(fc1)\n",
    "# lstm1 = Bidirectional(GRU(n_lstm_units, return_sequences=True, \n",
    "#             input_shape=(None, n_dense_units), dropout=dropout), \n",
    "#             name='LSTM2')(lstm1)\n",
    "mask = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"sigmoid\"), \n",
    "            name='Mask')(lstm1)\n",
    "multi = multiply([direct_out, mask], name=\"multiply\")\n",
    "model = tf.keras.Model(inputs=inputs, outputs=multi, name='Contextualizer')\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "# model.compile(loss=tf.keras.losses.Huber(), optimizer=\"adam\", metrics=[tf.keras.losses.CosineSimilarity()])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "for _ in range(5):\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)\n",
    "    n_samples = 5000\n",
    "    settings = dict(duration_of_trial=0.25, extents=(1,40), number_of_sources=(1,15), target_snr=(2, 15))\n",
    "    sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "    X, y = prep_data(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Contextualizer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              [(None, None, 61)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FC1 (TimeDistributed)           (None, None, 256)    15872       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (Bidirectional)           (None, None, 128)    48768       Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, None, 256)    0           FC1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Mask1 (TimeDistributed)         (None, None, 256)    33024       LSTM1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply1 (Multiply)            (None, None, 256)    0           dropout_17[0][0]                 \n",
      "                                                                 Mask1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "LSTM2 (Bidirectional)           (None, None, 128)    123648      multiply1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "FC2 (TimeDistributed)           (None, None, 1284)   329988      multiply1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Mask2 (TimeDistributed)         (None, None, 1284)   165636      LSTM2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply2 (Multiply)            (None, None, 1284)   0           FC2[0][0]                        \n",
      "                                                                 Mask2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 716,936\n",
      "Trainable params: 716,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [01:23<00:00, 179.73it/s]\n",
      "100%|██████████| 15000/15000 [00:02<00:00, 7037.83it/s] \n",
      "100%|██████████| 15000/15000 [00:23<00:00, 631.75it/s]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis2: axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/366167717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0msettings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration_of_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mduration_of_trials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_sources\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_snr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/2024711847.py\u001b[0m in \u001b[0;36mprep_data\u001b[1;34m(sim)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mswapaxes\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mswapaxes\u001b[1;34m(a, axis1, axis2)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \"\"\"\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'swapaxes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis2: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, GRU, multiply, add, Activation, Dropout\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from esinet.losses import nmse_loss, nmae_loss\n",
    "\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, _ = leadfield.shape\n",
    "n_dipoles = y_comp.shape[-1]\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 256\n",
    "n_lstm_units = 64\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.2\n",
    "input_dropout = 0.1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "fc1 = Dropout(dropout)(fc1)\n",
    "\n",
    "lstm1 = Bidirectional(GRU(64, return_sequences=True, \n",
    "            input_shape=(None, n_dense_units), dropout=dropout), \n",
    "            name='LSTM1')(inputs)\n",
    "mask1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=\"sigmoid\"), \n",
    "            name='Mask1')(lstm1)\n",
    "\n",
    "multi = multiply([fc1, mask1], name=\"multiply1\")\n",
    "\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"linear\"),\n",
    "            name='FC2')(multi)\n",
    "\n",
    "lstm2 = Bidirectional(GRU(n_lstm_units, return_sequences=True, \n",
    "            input_shape=(None, n_dense_units), dropout=dropout), \n",
    "            name='LSTM2')(multi)\n",
    "# lstm2 = Bidirectional(GRU(n_lstm_units, return_sequences=True, \n",
    "#             input_shape=(None, n_dense_units), dropout=dropout), \n",
    "#             name='LSTM3')(lstm2)\n",
    "mask2 = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"sigmoid\"), \n",
    "            name='Mask2')(lstm2)\n",
    "multi = multiply([direct_out, mask2], name=\"multiply2\")\n",
    "model = tf.keras.Model(inputs=inputs, outputs=multi, name='Contextualizer')\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "# model.compile(loss=tf.keras.losses.Huber(), optimizer=\"adam\", metrics=[tf.keras.losses.CosineSimilarity()])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "n = 10\n",
    "duration_of_trials = np.linspace(0,25,num=n)\n",
    "n_samples = 15000\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    settings = dict(duration_of_trial=duration_of_trials[i], extents=(1,40), number_of_sources=(1,15), target_snr=(2, 15))\n",
    "    sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "    X, y = prep_data(sim)\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)\n",
    "    n_samples = 5000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "399/399 [==============================] - 17s 31ms/step - loss: -0.2490 - val_loss: -0.3134\n",
      "Epoch 2/30\n",
      "399/399 [==============================] - 11s 28ms/step - loss: -0.3348 - val_loss: -0.3631\n",
      "Epoch 3/30\n",
      "399/399 [==============================] - 11s 27ms/step - loss: -0.3850 - val_loss: -0.3997\n",
      "Epoch 4/30\n",
      "399/399 [==============================] - 11s 28ms/step - loss: -0.4267 - val_loss: -0.4304\n",
      "Epoch 5/30\n",
      "399/399 [==============================] - 11s 27ms/step - loss: -0.4620 - val_loss: -0.4484\n",
      "Epoch 6/30\n",
      "399/399 [==============================] - 11s 27ms/step - loss: -0.4883 - val_loss: -0.4573\n",
      "Epoch 7/30\n",
      "399/399 [==============================] - 11s 26ms/step - loss: -0.5078 - val_loss: -0.4637\n",
      "Epoch 8/30\n",
      "399/399 [==============================] - 11s 26ms/step - loss: -0.5257 - val_loss: -0.4688\n",
      "Epoch 9/30\n",
      "128/399 [========>.....................] - ETA: 6s - loss: -0.5512"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6496/63485645.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#     sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lukas\\virtualenvs\\esienv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# settings = dict(duration_of_trial=duration_of_trials[i], extents=(1,40), number_of_sources=(1,15), target_snr=(2, 15))\n",
    "#     sim = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "X, y = prep_data(sim)\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)\n",
    "n_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.10it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x1c054289ca0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 2\n",
    "settings = dict(duration_of_trial=0.25, extents=(1,2), number_of_sources=6, target_snr=(2, 15))\n",
    "\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "print(sim_test.simulation_info.number_of_sources.values[0])\n",
    "X_test, y_test = prep_data(sim_test)\n",
    "\n",
    "y_hat = model.predict(X_test)[0]\n",
    "\n",
    "stc = sim_test.source_data[0]\n",
    "stc.plot(**plot_params)\n",
    "\n",
    "stc_hat = stc.copy()\n",
    "# stc_hat.data = comp.decode(y_hat.T)\n",
    "stc_hat.data = y_hat.T\n",
    "\n",
    "stc_hat.plot(**plot_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM_Old\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, None, 61)]        0         \n",
      "                                                                 \n",
      " FC1 (TimeDistributed)       (None, None, 300)         18600     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 300)         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 256)        330240    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " FC2 (TimeDistributed)       (None, None, 1284)        329988    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 678,828\n",
      "Trainable params: 678,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "399/399 [==============================] - 8s 14ms/step - loss: -0.2572 - val_loss: -0.3302\n",
      "Epoch 2/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.3372 - val_loss: -0.3648\n",
      "Epoch 3/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.3620 - val_loss: -0.3874\n",
      "Epoch 4/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.3784 - val_loss: -0.4001\n",
      "Epoch 5/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.3898 - val_loss: -0.4097\n",
      "Epoch 6/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.3997 - val_loss: -0.4205\n",
      "Epoch 7/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4089 - val_loss: -0.4283\n",
      "Epoch 8/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4172 - val_loss: -0.4351\n",
      "Epoch 9/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4252 - val_loss: -0.4429\n",
      "Epoch 10/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4333 - val_loss: -0.4492\n",
      "Epoch 11/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4409 - val_loss: -0.4565\n",
      "Epoch 12/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4475 - val_loss: -0.4622\n",
      "Epoch 13/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4534 - val_loss: -0.4666\n",
      "Epoch 14/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4593 - val_loss: -0.4713\n",
      "Epoch 15/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4639 - val_loss: -0.4761\n",
      "Epoch 16/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4683 - val_loss: -0.4784\n",
      "Epoch 17/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4716 - val_loss: -0.4835\n",
      "Epoch 18/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4749 - val_loss: -0.4860\n",
      "Epoch 19/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4776 - val_loss: -0.4885\n",
      "Epoch 20/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4803 - val_loss: -0.4878\n",
      "Epoch 21/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4825 - val_loss: -0.4902\n",
      "Epoch 22/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4847 - val_loss: -0.4930\n",
      "Epoch 23/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4864 - val_loss: -0.4951\n",
      "Epoch 24/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4880 - val_loss: -0.4974\n",
      "Epoch 25/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4894 - val_loss: -0.4977\n",
      "Epoch 26/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4910 - val_loss: -0.4972\n",
      "Epoch 27/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4922 - val_loss: -0.5008\n",
      "Epoch 28/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4937 - val_loss: -0.5023\n",
      "Epoch 29/30\n",
      "399/399 [==============================] - 4s 10ms/step - loss: -0.4946 - val_loss: -0.5028\n",
      "Epoch 30/30\n",
      "399/399 [==============================] - 4s 11ms/step - loss: -0.4959 - val_loss: -0.5026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1641455b040>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, GRU, multiply, Activation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from esinet.losses import nmae_loss\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, n_dipoles = leadfield.shape\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 300\n",
    "n_lstm_units = 128\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.2\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "fc1 = Dropout(dropout)(fc1)\n",
    "lstm1 = Bidirectional(GRU(n_lstm_units, return_sequences=True, name='LSTM1'))(fc1)\n",
    "\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"linear\"),\n",
    "            name='FC2')(lstm1)\n",
    "\n",
    "\n",
    "model2 = tf.keras.Model(inputs=inputs, outputs=direct_out, name='LSTM_Old')\n",
    "\n",
    "\n",
    "model2.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "model2.summary()\n",
    "model2.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FC\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, None, 61)]        0         \n",
      "                                                                 \n",
      " FC1 (TimeDistributed)       (None, None, 600)         37200     \n",
      "                                                                 \n",
      " FC2 (TimeDistributed)       (None, None, 1284)        771684    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 808,884\n",
      "Trainable params: 808,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "399/399 [==============================] - 3s 7ms/step - loss: -0.2897 - val_loss: -0.3501\n",
      "Epoch 2/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3597 - val_loss: -0.3755\n",
      "Epoch 3/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3755 - val_loss: -0.3851\n",
      "Epoch 4/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.3838 - val_loss: -0.3929\n",
      "Epoch 5/30\n",
      "399/399 [==============================] - 3s 7ms/step - loss: -0.3891 - val_loss: -0.3957\n",
      "Epoch 6/30\n",
      "399/399 [==============================] - 3s 9ms/step - loss: -0.3919 - val_loss: -0.3976\n",
      "Epoch 7/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3945 - val_loss: -0.4006\n",
      "Epoch 8/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3963 - val_loss: -0.4019\n",
      "Epoch 9/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3981 - val_loss: -0.4027\n",
      "Epoch 10/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.3995 - val_loss: -0.4015\n",
      "Epoch 11/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4009 - val_loss: -0.4062\n",
      "Epoch 12/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4028 - val_loss: -0.4079\n",
      "Epoch 13/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4048 - val_loss: -0.4102\n",
      "Epoch 14/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4067 - val_loss: -0.4104\n",
      "Epoch 15/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4074 - val_loss: -0.4125\n",
      "Epoch 16/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4086 - val_loss: -0.4131\n",
      "Epoch 17/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4098 - val_loss: -0.4152\n",
      "Epoch 18/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4110 - val_loss: -0.4156\n",
      "Epoch 19/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4118 - val_loss: -0.4169\n",
      "Epoch 20/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4127 - val_loss: -0.4180\n",
      "Epoch 21/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4135 - val_loss: -0.4190\n",
      "Epoch 22/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4144 - val_loss: -0.4183\n",
      "Epoch 23/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4151 - val_loss: -0.4198\n",
      "Epoch 24/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4164 - val_loss: -0.4206\n",
      "Epoch 25/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4172 - val_loss: -0.4217\n",
      "Epoch 26/30\n",
      "399/399 [==============================] - 2s 6ms/step - loss: -0.4181 - val_loss: -0.4204\n",
      "Epoch 27/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4191 - val_loss: -0.4221\n",
      "Epoch 28/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4200 - val_loss: -0.4212\n",
      "Epoch 29/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4210 - val_loss: -0.4251\n",
      "Epoch 30/30\n",
      "399/399 [==============================] - 2s 5ms/step - loss: -0.4219 - val_loss: -0.4269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164150f4d60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Bidirectional, LSTM, GRU, multiply, Activation\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from esinet.losses import nmae_loss\n",
    "leadfield, pos = util.unpack_fwd(fwd)[1:3]\n",
    "n_channels, n_dipoles = leadfield.shape\n",
    "input_shape = (None, None, n_channels)\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "n_dense_units = 600\n",
    "n_lstm_units = 30\n",
    "activation_function = \"tanh\"\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "dropout = 0.1\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None, n_channels), name='Input')\n",
    "fc1 = TimeDistributed(Dense(n_dense_units, \n",
    "            activation=activation_function), \n",
    "            name='FC1')(inputs)\n",
    "direct_out = TimeDistributed(Dense(n_dipoles, \n",
    "            activation=\"linear\"),\n",
    "            name='FC2')(fc1)\n",
    "\n",
    "\n",
    "model3 = tf.keras.Model(inputs=inputs, outputs=direct_out, name='FC')\n",
    "\n",
    "\n",
    "model3.compile(loss=tf.keras.losses.CosineSimilarity(), optimizer=\"adam\")\n",
    "\n",
    "model3.summary()\n",
    "model3.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating data based on sparse patches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 73.13it/s] \n",
      "100%|██████████| 50/50 [00:00<00:00, 25082.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source data shape:  (1284, 25) (1284, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 323.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 sources\n",
      "Contextualizer: r=0.46\n",
      "LSTM_Old: r=0.46\n",
      "FC: r=0.37\n",
      "Champagne: r=-0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import tqdm\n",
    "import sys; sys.path.insert(0, '../../invert/')\n",
    "from invert.solvers.empirical_bayes import SolverChampagne\n",
    "\n",
    "solver = SolverChampagne()\n",
    "solver.make_inverse_operator(fwd)\n",
    "n_samples = 50\n",
    "settings = dict(duration_of_trial=0.25, number_of_sources=(1,10), extents=(1,40))\n",
    "# settings = dict(duration_of_trial=0.25, number_of_sources=5, extents=(1,2))\n",
    "\n",
    "sim_test = Simulation(fwd, info, settings=settings).simulate(n_samples=n_samples)\n",
    "X_test, y_test = prep_data(sim_test)\n",
    "\n",
    "# models = [model, model2, model3]\n",
    "# aucs = []\n",
    "# mles = []\n",
    "# nmses = []\n",
    "# for net in models:\n",
    "#     y_hat = net.predict(X_test)\n",
    "#     auc, nmse, mle = eval(y_test, y_hat)\n",
    "#     aucs.append( auc )\n",
    "#     nmses.append( nmse )\n",
    "#     mles.append( mle )\n",
    "#     print(f\"{net.name}: \\n\\t{np.nanmedian(aucs[-1])} AUC \\n\\t{np.nanmedian(mles[-1])} mm \\n\\t{np.nanmedian(nmses[-1])} nMSE\")\n",
    "\n",
    "# y_hat = np.stack([solver.apply_inverse_operator(epochs.average()).data for epochs in tqdm(sim_test.eeg_data)], axis=0)\n",
    "# y_hat = np.swapaxes(y_hat, 1, 2)\n",
    "# auc, nmse, mle = eval(y_test, y_hat)\n",
    "# aucs.append( auc )\n",
    "# nmses.append( nmse )\n",
    "# mles.append( mle )\n",
    "\n",
    "# models.append(solver)\n",
    "# print(f\"{solver.name}: \\n\\t{np.nanmedian(aucs[-1])} AUC \\n\\t{np.nanmedian(mles[-1])} mm \\n\\t{np.nanmedian(nmses[-1])} nMSE\")\n",
    "\n",
    "idx = 0\n",
    "n = sim_test.simulation_info[\"number_of_sources\"].values[idx]\n",
    "print(f\"{n} sources\")\n",
    "\n",
    "# PLOTTING BRAINS\n",
    "stc = sim_test.source_data[idx]\n",
    "stc.plot(**plot_params, brain_kwargs=dict(title=\"Ground Truth\"))\n",
    "\n",
    "stc_hat = stc.copy()\n",
    "y_hat = model.predict(X_test)[idx]\n",
    "stc_hat.data = y_hat.T\n",
    "stc_hat.plot(**plot_params, brain_kwargs=dict(title=model.name))\n",
    "r = pearsonr(y_hat.flatten(), y_test[idx].flatten())[0]\n",
    "print(f\"{model.name}: r={r:.2f}\")\n",
    "\n",
    "\n",
    "y_hat = model2.predict(X_test)[idx]\n",
    "stc_hat = stc.copy()\n",
    "stc_hat.data = y_hat.T\n",
    "stc_hat.plot(**plot_params, brain_kwargs=dict(title=model2.name))\n",
    "r = pearsonr(y_hat.flatten(), y_test[idx].flatten())[0]\n",
    "print(f\"{model2.name}: r={r:.2f}\")\n",
    "\n",
    "y_hat = model3.predict(X_test)[idx]\n",
    "stc_hat = stc.copy()\n",
    "stc_hat.data = y_hat.T\n",
    "stc_hat.plot(**plot_params, brain_kwargs=dict(title=model3.name))\n",
    "r = pearsonr(y_hat.flatten(), y_test[idx].flatten())[0]\n",
    "print(f\"{model3.name}: r={r:.2f}\")\n",
    "\n",
    "\n",
    "evoked = sim_test.eeg_data[idx].average()\n",
    "stc_hat = solver.apply_inverse_operator(evoked)\n",
    "stc_hat.plot(**plot_params, brain_kwargs=dict(title=solver.name))\n",
    "y_hat = stc_hat.data\n",
    "r = pearsonr(y_hat.flatten(), y_test[idx].flatten())[0]\n",
    "print(f\"{solver.name}: r={r:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukas\\AppData\\Local\\Temp/ipykernel_4228/3452833000.py:6: RuntimeWarning: Mean of empty slice\n",
      "  sns.boxplot(data=np.nanmean(aucs,axis=-1).T)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Temp/ipykernel_4228/3452833000.py:12: RuntimeWarning: Mean of empty slice\n",
      "  sns.boxplot(data=np.nanmean(mles,axis=-1).T)\n",
      "C:\\Users\\Lukas\\AppData\\Local\\Temp/ipykernel_4228/3452833000.py:18: RuntimeWarning: Mean of empty slice\n",
      "  sns.boxplot(data=np.nanmean(nmses,axis=-1).T)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'NMSE')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "names = [m.name for m in models]\n",
    "xticks = (np.arange(len(models)), names)\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=np.nanmean(aucs,axis=-1).T)\n",
    "plt.xticks(*xticks)\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.title(\"AUC\")\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=np.nanmean(mles,axis=-1).T)\n",
    "plt.xticks(*xticks)\n",
    "plt.xlabel(\"MLE\")\n",
    "plt.title(\"MLE\")\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(data=np.nanmean(nmses,axis=-1).T)\n",
    "plt.xticks(*xticks)\n",
    "plt.xlabel(\"NMSE\")\n",
    "plt.title(\"NMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('esienv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a54b85cbc80ea8362b8e45e33618627fd9167210ff2c52e6dbeaf85afe35b874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
